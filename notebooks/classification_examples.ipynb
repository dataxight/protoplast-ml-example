{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Classification Models for Single-Cell Data with PROTOplast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a8f1a",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use PROTOplast to train different classification models in PyTorch with the `h5ad` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713b010",
   "metadata": {},
   "source": [
    "**Download the Tahoe-100M `h5ad` files**\n",
    "- The Tahoe-100M dataset can be downloaded in `h5ad` format from the **Arc Institute Google Cloud Storage**.\n",
    "- For step-by-step instructions, see the [official tutorial](https://github.com/ArcInstitute/arc-virtual-cell-atlas/blob/main/tahoe-100M/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "**Setup**  \n",
    "- Configure the training environment for single-cell RNA sequencing (scRNA-seq) data using **PROTOplast** in combination with **PyTorch Lightning** and **Ray**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5aca0a-5b9b-496e-9e00-66689c2869aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Logging initialized. Current level is: INFO\n"
     ]
    }
   ],
   "source": [
    "import protoplast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebc7278-de44-477b-8c0a-1c529a86c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(version(\"protoplast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bkHC",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 372 ms, sys: 96.8 ms, total: 469 ms\n",
      "Wall time: 474 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import anndata\n",
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "# models\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedCellLineAnnDataset as Dcl\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner\n",
    "from ray.train.lightning import RayDDPStrategy\n",
    "from scsims.model import SIMSClassifier\n",
    "\n",
    "# scvi training plan\n",
    "## install scvi-tools if needed:\n",
    "## uv add scvi-tools\n",
    "from scvi.module import Classifier\n",
    "from scvi.train import ClassifierTrainingPlan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011fb16",
   "metadata": {},
   "source": [
    "## 1. Load the Tahoe 100-M Dataset (`h5ad`)\n",
    "- `file_paths`: Plate 12 from Tahoe-100M (The largest file: 35 GB) is used as a demo. To add more plates, append their `.h5ad` file paths to the list, separated by commas\n",
    "- `batch_size`: number of samples per training batch\n",
    "- `test_size`: fraction of data reserved for testing (use `0.0` if no test set is needed)\n",
    "- `val_size`: fraction of data reserved for validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Xref",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 Î¼s, sys: 1e+03 ns, total: 11 Î¼s\n",
      "Wall time: 20.7 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [\"/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
    "batch_size = 2000\n",
    "test_size = 0.0\n",
    "val_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "## 2. Simple Classifier\n",
    "\n",
    "This example illustrates how to configure a training runner with **PROTOplast** and **Ray**.\n",
    "\n",
    "- `LinearClassifier`: a simple baseline model that can be swapped with a custom implementation\n",
    "- `Dcl`: the dataset object for training, imported from `protoplast.scrna.anndata.torch_dataloader`\n",
    "  - Defined as a subclass of `DistributedAnnDataset`, customized for cell line classification tasks\n",
    "- `[\"num_genes\", \"num_classes\"]`: arguments that specify the modelâ€™s input and output dimensions\n",
    "- `cell_line_metadata_cb`: a callback function that attaches dataset-specific metadata, such as cell line labels and class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "BYtC",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 06:50:14,623\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-11-04 06:50:14,647\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example/notebooks'.\n",
      "2025-11-04 06:50:14,665\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_eea06cd8e8481dee.zip' (3.11MiB) to Ray cluster...\n",
      "2025-11-04 06:50:14,685\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_eea06cd8e8481dee.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 284 ms, sys: 337 ms, total: 622 ms\n",
      "Wall time: 9.26 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LinearClassifier_trainer = RayTrainRunner(\n",
    "    LinearClassifier,  # replace with your own model\n",
    "    Dcl,  # replace with your own Dataset\n",
    "    [\"num_genes\", \"num_classes\"],  # change according to what you need for your model\n",
    "    cell_line_metadata_cb,  # include data you need for your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2c38b",
   "metadata": {},
   "source": [
    "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12 GiB)**, **96 CPUs**, and **125 GiB RAM**, running `LinearClassifier_trainer.train()` completed in approximately **8 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "RGSE",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "protoplast.scrna.anndata.trainer - INFO - Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "protoplast.scrna.anndata.trainer - INFO - Using 1 workers where each worker uses: {'CPU': 4, 'GPU': 1}\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of val_split: 65 length of test_split: 0, length of train_split: 262\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of after dropping remainder val_split: 65, length of test_split: 0, length of train_split: 262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1052917)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainController pid=1052917)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1052917)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1052917)\u001b[0m Attempting to start training worker group of size 1 with the following resources: [{'CPU': 4, 'GPU': 1}] * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1052917)\u001b[0m Started training worker group of size 1: \n",
      "\u001b[36m(TrainController pid=1052917)\u001b[0m - (ip=192.168.1.226, pid=1053233) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   return _C._get_float32_matmul_precision()\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.11it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.28it/s]\n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 1/4192 [00:26<31:03:41,  0.04it/s, v_num=0, train_loss=4.110]\n",
      "...\n",
      "...\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4170/4192 [05:12<00:01, 13.34it/s, v_num=0, train_loss=0.0547]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4175/4192 [05:12<00:01, 13.36it/s, v_num=0, train_loss=0.0602]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4176/4192 [05:12<00:01, 13.36it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4182/4192 [05:12<00:00, 13.37it/s, v_num=0, train_loss=0.108]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4188/4192 [05:12<00:00, 13.39it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4189/4192 [05:12<00:00, 13.39it/s, v_num=0, train_loss=0.055]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [05:12<00:00, 13.40it/s, v_num=0, train_loss=0.157] \n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1040 [00:00<?, ?it/s]\u001b[A\n",
      "...\n",
      "...\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1040/1040 [01:17<00:00, 13.48it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:56<00:00, 10.05it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:57<00:00, 10.03it/s, v_num=0, train_loss=0.157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_06-50-37/checkpoint_2025-11-04_06-58-22.072518)\n",
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_06-50-37/checkpoint_2025-11-04_06-58-22.072518), metrics={'train_loss': 0.15701858699321747, 'val_acc': 0.9862620234489441, 'epoch': 0, 'step': 4192}, validation_spec=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:58<00:00, 10.02it/s, v_num=0, train_loss=0.157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1053233)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 3.7 s, total: 25.5 s\n",
      "Wall time: 8min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LinearClassifier_trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 2000\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.2\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {},
   "source": [
    "## 3. SIMS: Scalable, Interpretable Models for Cell Annotation of large scale single-cell RNA-seq data\n",
    "**SIMS** is a pipeline designed to build interpretable and accurate classifiers for identifying any target in single-cell RNA sequencing (scRNA-seq) data.  \n",
    "- The core SIMS model is based on a **sequential transformer**, a specialized transformer architecture built for large-scale tabular datasets. \n",
    "- SIMS provides a framework for **cell type annotation**: it trains on labeled single-cell data and predicts cell type labels for new, unlabeled cells. \n",
    "- It leverages the **TabNet** deep learning model, which automatically selects the most informative genes for each prediction, ensuring results that are both **accurate** and **interpretable**.  \n",
    "For implementation details and source code, see the [SIMS GitHub repository](https://github.com/braingeneers/SIMS/tree/main)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {},
   "source": [
    "### SIMS Metadata Callback\n",
    "This callback (`sims_metadata_cb`) extracts key information from the AnnData object to configure the SIMS model.\n",
    "- `input_dim`: the number of genes (features) in the dataset.\n",
    "- `cell_lines`: list of unique cell line categories.\n",
    "- `output_dim`: the number of distinct classes (cell lines) to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sims_metadata_cb(ad: anndata.AnnData, metadata: dict):\n",
    "    metadata[\"num_genes\"] = ad.var.shape[0]\n",
    "    metadata[\"input_dim\"] = metadata[\"num_genes\"]\n",
    "    metadata[\"cell_lines\"] = ad.obs[\"cell_line\"].cat.categories.to_list()\n",
    "    metadata[\"num_classes\"] = len(metadata[\"cell_lines\"])\n",
    "    metadata[\"output_dim\"] = metadata[\"num_classes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {},
   "source": [
    "### Training the SIMS Classifier\n",
    "\n",
    "- The **SIMSClassifier** model is initialized with the dataset (`Dcl`), while essential arguments (`input_dim`, `output_dim`) are supplied through the `sims_metadata_cb` callback \n",
    "- Training is distributed using **RayDDPStrategy**, with `find_unused_parameters=True` enabled to ensure proper handling of layers that may not be active in every forward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iLit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 06:58:51,891\tERROR services.py:1360 -- Failed to start the dashboard \n",
      "2025-11-04 06:58:51,896\tERROR services.py:1385 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-11-04 06:58:51,898\tERROR services.py:1429 -- \n",
      "The last 20 lines of /tmp/ray/session_2025-11-04_06-58-29_922337_1042730/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "2025-11-04 06:58:53,184\tINFO worker.py:2012 -- Started a local Ray instance.\n",
      "2025-11-04 06:58:53,410\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example/notebooks'.\n",
      "2025-11-04 06:58:53,420\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_2df2b05812cc5858.zip' (0.92MiB) to Ray cluster...\n",
      "2025-11-04 06:58:53,428\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_2df2b05812cc5858.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 303 ms, sys: 321 ms, total: 624 ms\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sims_trainer = RayTrainRunner(\n",
    "    SIMSClassifier,\n",
    "    Dcl,\n",
    "    [\"input_dim\", \"output_dim\"],  # maps to SIMSClassifier(input_dim, output_dim)\n",
    "    sims_metadata_cb,\n",
    "    ray_trainer_strategy=RayDDPStrategy(find_unused_parameters=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d58ff",
   "metadata": {},
   "source": [
    "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12 GiB)**, **96 CPUs**, and **125 GiB RAM**, running `sims_trainer.train()` completed in about **14 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ZHCJ",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "protoplast.scrna.anndata.trainer - INFO - Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "protoplast.scrna.anndata.trainer - INFO - Using 1 workers where each worker uses: {'CPU': 4, 'GPU': 1}\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of val_split: 65 length of test_split: 0, length of train_split: 262\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of after dropping remainder val_split: 65, length of test_split: 0, length of train_split: 262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1072383)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainController pid=1072383)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1072383)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1072383)\u001b[0m Attempting to start training worker group of size 1 with the following resources: [{'CPU': 4, 'GPU': 1}] * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1072383)\u001b[0m Started training worker group of size 1: \n",
      "\u001b[36m(TrainController pid=1072383)\u001b[0m - (ip=192.168.1.226, pid=1073355) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   return _C._get_float32_matmul_precision()\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   | Name          | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m -----------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 0 | network       | TabNet           | 2.3 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 1 | train_metrics | MetricCollection | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 2 | val_metrics   | MetricCollection | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   | other params  | n/a              | 1      | n/a  \n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m -----------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 2.3 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 2.3 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 9.054     Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 119       Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  0.56it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]\n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/f1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/macro_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/micro_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/precision', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/recall', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/specificity', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/weighted_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 1/4192 [00:26<31:02:06,  0.04it/s, v_num=0, train/loss_step=4.940]\n",
      "...\n",
      "...\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4190/4192 [11:06<00:00,  6.29it/s, v_num=0, train/loss_step=0.400]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4191/4192 [11:06<00:00,  6.29it/s, v_num=0, train/loss_step=0.456]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [11:06<00:00,  6.29it/s, v_num=0, train/loss_step=0.480]\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "...\n",
      "...\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1036/1040 [01:33<00:00, 11.11it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1037/1040 [01:33<00:00, 11.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1038/1040 [01:33<00:00, 11.12it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1039/1040 [01:33<00:00, 11.13it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1040/1040 [01:33<00:00, 11.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [13:02<00:00,  5.36it/s, v_num=0, train/loss_step=0.480, val/loss=0.596, val/f1=0.820, val/macro_acc=0.814, val/micro_acc=0.921, val/precision=0.833, val/recall=0.814, val/specificity=0.998, val/weighted_acc=0.921]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_06-59-17/checkpoint_2025-11-04_07-15-15.179172)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_06-59-17/checkpoint_2025-11-04_07-15-15.179172), metrics={'train/loss': 0.48666849732398987, 'train/loss_step': 0.479697585105896, 'val/loss': 0.5956600904464722, 'val/f1': 0.8201902508735657, 'val/macro_acc': 0.813599705696106, 'val/micro_acc': 0.9213297963142395, 'val/precision': 0.8329737782478333, 'val/recall': 0.813599705696106, 'val/specificity': 0.9983789920806885, 'val/weighted_acc': 0.9213297963142395, 'train/loss_epoch': 0.48666849732398987, 'epoch': 0, 'step': 4192}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/f1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/macro_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/micro_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/precision', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/recall', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/specificity', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/weighted_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[36m(RayTrainWorker pid=1073355)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [13:02<00:00,  5.35it/s, v_num=0, train/loss_step=0.480, val/loss=0.596, val/f1=0.820, val/macro_acc=0.814, val/micro_acc=0.921, val/precision=0.833, val/recall=0.814, val/specificity=0.998, val/weighted_acc=0.921, train/loss_epoch=0.487]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [13:03<00:00,  5.35it/s, v_num=0, train/loss_step=0.480, val/loss=0.596, val/f1=0.820, val/macro_acc=0.814, val/micro_acc=0.921, val/precision=0.833, val/recall=0.814, val/specificity=0.998, val/weighted_acc=0.921, train/loss_epoch=0.487]\n",
      "CPU times: user 28.1 s, sys: 5.54 s, total: 33.7 s\n",
      "Wall time: 16min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sims_trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 2000\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.2\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {},
   "source": [
    "## 4. Autoencoder\n",
    "- An **autoencoder** is an unsupervised neural network consisting of three main components:  \n",
    "  - **Encoder**: compresses the input into a lower-dimensional representation.  \n",
    "  - **Bottleneck**: stores the compressed features.  \n",
    "  - **Decoder**: reconstructs the input from the bottleneck representation.  \n",
    "- In this setup, separate encoders process **gene** and **protein** data. Their outputs are concatenated, passed through an additional encoder to form the bottleneck, and then decoded back to the original input.  \n",
    "- Since **Tahoe-100M** does not include protein data, the protein input is set to `0`, and the source code was adapted to ensure compatibility with datasets lacking protein features.\n",
    "- For testing purposes, we temporarily set mid = 128, which reduces the hidden layer size and simplifies the model architecture. For implementation details, see the [CITE-seq autoencoder source code](https://github.com/naity/citeseq_autoencoder/blob/main/autoencoder_citeseq_saturn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fed382e-57ce-4209-8d44-9304f686aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group linear, batchnorm, and dropout layers. This module was from citeseq_autoencoder notebook\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "class LinBnDrop(nn.Sequential):\n",
    "    \"\"\"Module grouping `BatchNorm1d`, `Dropout` and `Linear` layers, adapted from fastai.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_out, bn=True, p=0.0, act=None, lin_first=True):\n",
    "        layers = [nn.BatchNorm1d(n_out if lin_first else n_in)] if bn else []\n",
    "        if p != 0:\n",
    "            layers.append(nn.Dropout(p))\n",
    "        lin = [nn.Linear(n_in, n_out, bias=not bn)]\n",
    "        if act is not None:\n",
    "            lin.append(act)\n",
    "        layers = lin + layers if lin_first else layers + lin\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34de981-1801-4843-bb78-094f5f69435d",
   "metadata": {},
   "source": [
    "We implement an encoder that processes RNA features through a two-layer MLP (`nfeatures_rna` â†’ `mid=128` â†’ `hidden_rna`, with `mid=2` set for testing). The source code is from [CITE-seq autoencoder source code](https://github.com/naity/citeseq_autoencoder/blob/main/autoencoder_citeseq_saturn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5caadfbd-c2f0-423e-9a96-f9b6dd59baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder for CITE-seq data\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, nfeatures_rna: int, nfeatures_pro: int, hidden_rna: int, hidden_pro: int, latent_dim: int, p: float = 0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nfeatures_rna = nfeatures_rna\n",
    "        self.nfeatures_pro = nfeatures_pro\n",
    "\n",
    "        if nfeatures_rna > 0:\n",
    "            mid = 128  # 128 is for testing the code\n",
    "            self.encoder_rna = nn.Sequential(\n",
    "                LinBnDrop(nfeatures_rna, mid, p=p, act=nn.LeakyReLU()),\n",
    "                LinBnDrop(mid, hidden_rna, act=nn.LeakyReLU()),\n",
    "            )\n",
    "\n",
    "        if nfeatures_pro > 0:\n",
    "            self.encoder_protein = LinBnDrop(nfeatures_pro, hidden_pro, p=p, act=nn.LeakyReLU())\n",
    "\n",
    "        # make sure hidden_rna and hidden_pro are set correctly\n",
    "        hidden_rna = 0 if nfeatures_rna == 0 else hidden_rna\n",
    "        hidden_pro = 0 if nfeatures_pro == 0 else hidden_pro\n",
    "\n",
    "        hidden_dim = hidden_rna + hidden_pro\n",
    "\n",
    "        self.encoder = LinBnDrop(hidden_dim, latent_dim, act=nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.nfeatures_rna > 0 and self.nfeatures_pro > 0:\n",
    "            x_rna = self.encoder_rna(x[:, : self.nfeatures_rna])\n",
    "            x_pro = self.encoder_protein(x[:, self.nfeatures_rna :])\n",
    "            x = torch.cat([x_rna, x_pro], 1)\n",
    "        elif self.nfeatures_rna > 0 and self.nfeatures_pro == 0:\n",
    "            x = self.encoder_rna(x)\n",
    "        elif self.nfeatures_rna == 0 and self.nfeatures_pro > 0:\n",
    "            x = self.encoder_protein(x)\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503455d4-dc3e-43e8-85cc-9f60377fa8a7",
   "metadata": {},
   "source": [
    "We implement a decoder that maps the latent vector to the RNA feature space by first expanding it to `hidden_rna`, passing it through a small intermediate layer (`mid_out` = `128`, used for testing), and finally projecting it to the RNA output dimension. The source code is from [CITE-seq autoencoder source code](https://github.com/naity/citeseq_autoencoder/blob/main/autoencoder_citeseq_saturn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2d627b-fe57-4419-926f-14b371ad083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder for CITE-seq data\"\"\"\n",
    "\n",
    "    def __init__(self, nfeatures_rna: int, nfeatures_pro: int, hidden_rna: int, hidden_pro: int, latent_dim: int):\n",
    "        super().__init__()\n",
    "        # make sure hidden_rna and hidden_pro are set correctly\n",
    "        hidden_rna = 0 if nfeatures_rna == 0 else hidden_rna\n",
    "        hidden_pro = 0 if nfeatures_pro == 0 else hidden_pro\n",
    "\n",
    "        hidden_dim = hidden_rna + hidden_pro\n",
    "        out_dim = nfeatures_rna + nfeatures_pro\n",
    "        mid_out = 128  # 128 is for testing the code\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            LinBnDrop(latent_dim, hidden_dim, act=nn.LeakyReLU()),\n",
    "            LinBnDrop(hidden_dim, mid_out, act=nn.LeakyReLU()),\n",
    "            LinBnDrop(mid_out, out_dim, bn=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00e509-8a29-4026-92a5-fa3a3213ff1f",
   "metadata": {},
   "source": [
    "The encoder and decoder are assembled into an autoencoder, which is defined as a PyTorch Lightning Module to simplify the training process. The source code is from [CITE-seq autoencoder source code](https://github.com/naity/citeseq_autoencoder/blob/main/autoencoder_citeseq_saturn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78797222-d09b-4456-97aa-565cebf017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteAutoencoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nfeatures_rna: int,\n",
    "        nfeatures_pro: int,\n",
    "        hidden_rna: int,\n",
    "        hidden_pro: int,\n",
    "        latent_dim: int,\n",
    "        p: float = 0,\n",
    "        lr: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"Autoencoder for citeseq data\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = Encoder(nfeatures_rna, nfeatures_pro, hidden_rna, hidden_pro, latent_dim, p)\n",
    "        self.decoder = Decoder(nfeatures_rna, nfeatures_pro, hidden_rna, hidden_pro, latent_dim)\n",
    "\n",
    "        # example input array for visualizing network graph\n",
    "        self.example_input_array = torch.zeros(256, nfeatures_rna + nfeatures_pro)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # extract latent embeddings\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def _get_reconstruction_loss(self, batch):\n",
    "        \"\"\"Calculate MSE loss for a given batch.\"\"\"\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        # MSE loss\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {},
   "source": [
    "### Autoencoder Metadata Callback\n",
    "- The `ae_metadata_cb` function extends `cell_line_metadata_cb` and configures the metadata required for training the autoencoder. It sets up cell line information, defines feature counts, and specifies key model hyperparameters such as hidden dimensions, latent space size, dropout, and learning rate\n",
    "\n",
    "**Note (for testing):**  \n",
    "In `ae_metadata_cb`, both the hidden RNA dimension (`hidden_rna=128`) and the latent dimension (`latent_dim=16`) are intentionally set to very small values. This configuration is used for quick testing and validation, not for full-scale training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_metadata_cb(ad, metadata):\n",
    "    cell_line_metadata_cb(ad, metadata)\n",
    "    metadata[\"cell_lines\"] = np.sort(np.unique(ad.obs[\"cell_line\"].to_numpy()))\n",
    "    metadata[\"nfeatures_rna\"] = metadata[\"num_genes\"]\n",
    "    metadata[\"nfeatures_pro\"] = 0\n",
    "    metadata[\"hidden_rna\"] = 128\n",
    "    metadata[\"hidden_pro\"] = 0\n",
    "    metadata[\"latent_dim\"] = 16\n",
    "    metadata[\"p\"] = 0.1\n",
    "    metadata[\"lr\"] = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {},
   "source": [
    "### Training the CiteAutoencoder model\n",
    "- The dataset (`Dcl`) is provided along with key model parameters such as RNA/protein feature counts, hidden layer sizes, latent dimension, dropout p, and learning rate lr, all supplied through the `ae_metadata_cb` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "DnEU",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 07:15:31,804\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2025-11-04 07:15:31,824\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example/notebooks'.\n",
      "2025-11-04 07:15:31,834\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_0a9329e6e0c18e86.zip' (1.38MiB) to Ray cluster...\n",
      "2025-11-04 07:15:31,846\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_0a9329e6e0c18e86.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 203 ms, sys: 316 ms, total: 519 ms\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder_trainer = RayTrainRunner(\n",
    "    CiteAutoencoder,\n",
    "    Dcl,\n",
    "    [\"nfeatures_rna\", \"nfeatures_pro\", \"hidden_rna\", \"hidden_pro\", \"latent_dim\", \"p\", \"lr\"],\n",
    "    metadata_cb=ae_metadata_cb,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd758cb8",
   "metadata": {},
   "source": [
    "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12GiB) + 96 CPUs + 125GiB RAM**, `autoencoder_trainer()` finished in **8 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ulZA",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "protoplast.scrna.anndata.trainer - INFO - Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "protoplast.scrna.anndata.trainer - INFO - Using 1 workers where each worker uses: {'CPU': 4, 'GPU': 1}\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of val_split: 65 length of test_split: 0, length of train_split: 262\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of after dropping remainder val_split: 65, length of test_split: 0, length of train_split: 262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1097366)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainController pid=1097366)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1097366)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1097366)\u001b[0m Attempting to start training worker group of size 1 with the following resources: [{'CPU': 4, 'GPU': 1}] * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1097366)\u001b[0m Started training worker group of size 1: \n",
      "\u001b[36m(TrainController pid=1097366)\u001b[0m - (ip=192.168.1.226, pid=1098099) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   return _C._get_float32_matmul_precision()\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   | Name    | Type    | Params | Mode  | In sizes     | Out sizes\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m -----------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 0 | encoder | Encoder | 8.0 M  | train | [256, 62710] | [256, 16]\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 1 | decoder | Decoder | 8.1 M  | train | ?            | ?        \n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m -----------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 16.2 M    Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 16.2 M    Total params\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 64.618    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 27        Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.45it/s]\n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 1/4192 [00:29<34:47:22,  0.03it/s, v_num=0]\n",
      "...\n",
      "...\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4186/4192 [06:55<00:00, 10.08it/s, v_num=0]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4189/4192 [06:55<00:00, 10.09it/s, v_num=0]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:55<00:00, 10.09it/s, v_num=0]\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "...\n",
      "...\n",
      "Validation DataLoader 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1034/1040 [01:09<00:00, 14.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1035/1040 [01:09<00:00, 14.95it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1036/1040 [01:09<00:00, 14.96it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1037/1040 [01:09<00:00, 14.97it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1038/1040 [01:09<00:00, 14.98it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1039/1040 [01:09<00:00, 14.99it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1040/1040 [01:09<00:00, 15.00it/s]\u001b[A\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [08:29<00:00,  8.23it/s, v_num=0]       \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_07-16-01/checkpoint_2025-11-04_07-25-25.031792)\n",
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_07-16-01/checkpoint_2025-11-04_07-25-25.031792), metrics={'train_loss': 0.21229848265647888, 'val_loss': 0.07657571136951447, 'epoch': 0, 'step': 4192}, validation_spec=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [08:30<00:00,  8.22it/s, v_num=0]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [08:30<00:00,  8.21it/s, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1098099)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 3.68 s, total: 33 s\n",
      "Wall time: 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder_trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 2000\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.2\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3ce28-2f5f-43f1-ba00-465612f9925f",
   "metadata": {},
   "source": [
    "## 5. DistributedClassifierTrainingPlan\n",
    "- **ClassifierTrainingPlan** (from `scvi-tools`) is not a model itself, but a training plan.  \n",
    "  Its purpose is to coordinate the entire training workflow of an scvi-tools classifier, including optimization, scheduling, and evaluation.  \n",
    "- For details, see the [source code](https://github.com/scverse/scvi-tools/blob/main/src/scvi/train/_trainingplans.py#L1479)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314d4b8-d322-4b92-97b8-8daa97889182",
   "metadata": {},
   "source": [
    "### Classifier Training metadata callback\n",
    "Calls `cell_line_metadata_cb` to extract `num_genes` and `num_classes` from the input AnnData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9555c00c-483e-46fd-8188-4318392a8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_metadata_cb(ad, metadata):\n",
    "    # Populate num_genes / num_classes from the AnnData file\n",
    "    cell_line_metadata_cb(ad, metadata)\n",
    "\n",
    "    # Create the classifier instance and attach it to metadata\n",
    "    metadata[\"classifier\"] = Classifier(\n",
    "        n_input=metadata[\"num_genes\"],\n",
    "        n_labels=metadata[\"num_classes\"],\n",
    "        logits=True,  # ClassifierTrainingPlan requirement that the module returns logits\n",
    "    )\n",
    "    metadata[\"lr\"] = 1e-3\n",
    "    metadata[\"weight_decay\"] = 1e-6\n",
    "    metadata[\"eps\"] = 0.01\n",
    "    metadata[\"optimizer\"] = \"Adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2242850-ae97-4df4-9f84-761faee01690",
   "metadata": {},
   "source": [
    "The `DistributedClassifierTrainingPlan` subclass extends `ClassifierTrainingPlan` by explicitly defining its own `training_step` and `validation_step`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d597c453-0ec2-409a-b7dd-198b891fdd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedClassifierTrainingPlan(ClassifierTrainingPlan):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step for classifier training.\"\"\"\n",
    "        x, y = batch\n",
    "        soft_prediction = self.forward(x)\n",
    "        loss = self.loss_fn(soft_prediction, y.view(-1).long())\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step for classifier training.\"\"\"\n",
    "        x, y = batch\n",
    "        soft_prediction = self.forward(x)\n",
    "        loss = self.loss_fn(soft_prediction, y.view(-1).long())\n",
    "        self.log(\"validation_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc5d5b-1707-493d-a388-a1a3380c1853",
   "metadata": {},
   "source": [
    "### Executing ClassifierTrainingPlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "507c8f51-7e90-45b5-b455-0ba5ddbf033f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 07:25:36,178\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-11-04 07:25:36,221\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example/notebooks'.\n",
      "2025-11-04 07:25:36,231\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_073c9cf1e7e22cdb.zip' (1.94MiB) to Ray cluster...\n",
      "2025-11-04 07:25:36,246\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_073c9cf1e7e22cdb.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 317 ms, total: 505 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ClassifierTrainingPlan_trainer = RayTrainRunner(\n",
    "    Model=DistributedClassifierTrainingPlan,\n",
    "    Ds=Dcl,\n",
    "    model_keys=[\"classifier\", \"lr\", \"weight_decay\", \"eps\", \"optimizer\"],\n",
    "    metadata_cb=clf_metadata_cb,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbfa49-e971-4ccf-ac3a-0cfdf9064274",
   "metadata": {},
   "source": [
    "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12GiB) + 96 CPUs + 125GiB RAM**, `ClassifierTrainingPlan_trainer()` finished in **8 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffde478a-93ef-43b8-a7d9-03c9efd36ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "protoplast.scrna.anndata.trainer - INFO - Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "protoplast.scrna.anndata.trainer - INFO - Using 1 workers where each worker uses: {'CPU': 4, 'GPU': 1}\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of val_split: 65 length of test_split: 0, length of train_split: 262\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of after dropping remainder val_split: 65, length of test_split: 0, length of train_split: 262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1116077)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainController pid=1116077)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=1116077)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=1116077)\u001b[0m Attempting to start training worker group of size 1 with the following resources: [{'CPU': 4, 'GPU': 1}] * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TrainController pid=1116077)\u001b[0m Started training worker group of size 1: \n",
      "\u001b[36m(TrainController pid=1116077)\u001b[0m - (ip=192.168.1.226, pid=1116630) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   return _C._get_float32_matmul_precision()\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 0 | module  | Classifier       | 8.0 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 8.0 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 8.0 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 32.135    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.23it/s]\n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('validation_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 1/4192 [00:29<34:24:10,  0.03it/s, v_num=0, train_loss_step=3.990]\n",
      "...\n",
      "...\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4187/4192 [05:36<00:00, 12.45it/s, v_num=0, train_loss_step=0.0984]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4190/4192 [05:36<00:00, 12.46it/s, v_num=0, train_loss_step=0.0704]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [05:36<00:00, 12.46it/s, v_num=0, train_loss_step=0.153] \n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1040 [00:00<?, ?it/s]\u001b[A\n",
      "...\n",
      "...\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1037/1040 [01:02<00:00, 16.51it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1038/1040 [01:02<00:00, 16.52it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1039/1040 [01:02<00:00, 16.53it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1040/1040 [01:02<00:00, 16.54it/s]\u001b[A\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [07:04<00:00,  9.88it/s, v_num=0, train_loss_step=0.153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [07:04<00:00,  9.87it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_07-25-59/checkpoint_2025-11-04_07-33-57.004318)\n",
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-04_07-25-59/checkpoint_2025-11-04_07-33-57.004318), metrics={'train_loss': 0.1795438826084137, 'train_loss_step': 0.15308770537376404, 'validation_loss': 0.11337331682443619, 'train_loss_epoch': 0.1795438826084137, 'epoch': 0, 'step': 4192}, validation_spec=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [07:04<00:00,  9.87it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1116630)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.9 s, sys: 3.47 s, total: 25.4 s\n",
      "Wall time: 8min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ClassifierTrainingPlan_trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 2000\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.2\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e3313-beac-4d4f-8eb9-38a3033e2eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6fd89-00cb-4960-a21f-b7702a592fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
