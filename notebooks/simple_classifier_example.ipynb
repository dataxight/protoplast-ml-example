{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Simple Classifier Model for Single-Cell Data with PROTOplast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a8f1a",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use PROTOplast to train a simple classification model in PyTorch with the `h5ad` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "**Setup**  \n",
    "- Configure the training environment for single-cell RNA sequencing (scRNA-seq) data using **PROTOplast** in combination with **PyTorch Lightning** and **Ray**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bkHC",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "CPU times: user 18.7 s, sys: 1.91 s, total: 20.6 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import ray\n",
    "import protoplast\n",
    "import glob\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedCellLineAnnDataset as Dcl\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "## Simple Classifier\n",
    "\n",
    "This example illustrates how to configure a training runner with **PROTOplast** and **Ray**.\n",
    "\n",
    "- `LinearClassifier`: a simple baseline model that can be swapped with a custom implementation\n",
    "- `Dcl`: the dataset object for training, imported from `protoplast.scrna.anndata.torch_dataloader`\n",
    "  - Defined as a subclass of `DistributedAnnDataset`, customized for cell line classification tasks\n",
    "- `[\"num_genes\", \"num_classes\"]`: arguments that specify the modelâ€™s input and output dimensions\n",
    "- `cell_line_metadata_cb`: a callback function that attaches dataset-specific metadata, such as cell line labels and class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "BYtC",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 12:33:20,673\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "2025-09-29 12:33:23,058\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example'.\n",
      "2025-09-29 12:33:23,201\tWARNING packaging.py:430 -- File /mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack is very large (34.70MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack']})`\n",
      "2025-09-29 12:33:23,448\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_5a587d83feb1136c.zip' (69.28MiB) to Ray cluster...\n",
      "2025-09-29 12:33:23,931\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_5a587d83feb1136c.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 918 ms, sys: 833 ms, total: 1.75 s\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Using CPython \u001b[36m3.11.13\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[2mInstalled \u001b[1m296 packages\u001b[0m \u001b[2min 407ms\u001b[0m\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=3232244)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainTrainable pid=3232244)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=3232244)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=3232244)\u001b[0m - (node_id=6090e6db35961bd68520f85638e41d21a6a20d06c51b719a5a02951f, ip=192.168.1.226, pid=3233388) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m =========Starting the training on 0 with num threads: 4=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  6.50it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.51it/s]\n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4160 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/runtime_resources/working_dir_files/_ray_pkg_5a587d83feb1136c/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 4/4160 [00:23<6:42:21,  0.17it/s, v_num=0, train_loss=2.430] \n",
      "Epoch 0:   0%|          | 9/4160 [00:23<2:59:26,  0.39it/s, v_num=0, train_loss=1.450]\n",
      "Epoch 0:   0%|          | 14/4160 [00:23<1:55:46,  0.60it/s, v_num=0, train_loss=0.564]\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4143/4160 [04:44<00:01, 14.59it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4148/4160 [04:44<00:00, 14.60it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4149/4160 [04:44<00:00, 14.60it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4154/4160 [04:44<00:00, 14.61it/s, v_num=0, train_loss=0.0889]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4155/4160 [04:44<00:00, 14.61it/s, v_num=0, train_loss=0.048] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4160/4160 [04:44<00:00, 14.63it/s, v_num=0, train_loss=0.130] \n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m \n",
      "Validation:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
      ".\n",
      ".\n",
      ".\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1019/1024 [01:00<00:00, 16.72it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1020/1024 [01:00<00:00, 16.73it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1021/1024 [01:00<00:00, 16.74it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1022/1024 [01:01<00:00, 16.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1023/1024 [01:01<00:00, 16.76it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [01:01<00:00, 16.77it/s]\u001b[A\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4160/4160 [06:10<00:00, 11.24it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4160/4160 [06:10<00:00, 11.24it/s, v_num=0, train_loss=0.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-09-29_12-33-50/TorchTrainer_8d4a2_00000_0_2025-09-29_12-33-50/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4160/4160 [06:10<00:00, 11.23it/s, v_num=0, train_loss=0.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3233388)\u001b[0m [rank0]:[W929 12:41:02.159725436 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,  # replace with your own model\n",
    "    Dcl,  # replace with your own Dataset\n",
    "    [\"num_genes\", \"num_classes\"],  # change according to what you need for your model\n",
    "    cell_line_metadata_cb,  # include data you need for your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2c38b",
   "metadata": {},
   "source": [
    "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12 GiB)**, **96 CPUs**, and **125 GiB RAM**, running `train()` completed in approximately **11 minutes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396588aa-3b3b-4c6c-b562-0747b9a856c7",
   "metadata": {},
   "source": [
    "- `file_paths`: Plate 12 from Tahoe-100M (The largest file: 35 GB) is used as a demo. To add more plates, append their `.h5ad` file paths to the list, separated by commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "RGSE",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "Using 1 workers with {'CPU': 4} each\n",
      "=========Length of val_split 65 length of test_split 0 length of train_split 262\n",
      "=========Length of after dropping remainder val_split 64 length of test_split 0 length of train_split 260\n",
      "Data splitting time: 22.06 seconds\n",
      "Spawning Ray worker and initiating distributed training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 12:33:50,287\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:50 (running for 00:00:00.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/artifacts/2025-09-29_12-33-50/TorchTrainer_2025-09-29_12-33-50/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:58 (running for 00:07:07.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/artifacts/2025-09-29_12-33-50/TorchTrainer_2025-09-29_12-33-50/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 12:41:01,331\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/dtran/protoplast_results/TorchTrainer_2025-09-29_12-33-50' in 0.0099s.\n",
      "2025-09-29 12:41:01,335\tINFO tune.py:1041 -- Total run time: 431.05 seconds (430.65 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:01 (running for 00:07:10.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_12-33-16_154841_3224373/artifacts/2025-09-29_12-33-50/TorchTrainer_2025-09-29_12-33-50/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "CPU times: user 24.9 s, sys: 3.91 s, total: 28.8 s\n",
      "Wall time: 7min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 0.13011327385902405, 'val_acc': 0.9862006902694702, 'epoch': 0, 'step': 4160},\n",
       "  path='/home/dtran/protoplast_results/TorchTrainer_2025-09-29_12-33-50/TorchTrainer_8d4a2_00000_0_2025-09-29_12-33-50',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-09-29_12-33-50/TorchTrainer_8d4a2_00000_0_2025-09-29_12-33-50/checkpoint_000000)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [\"/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
    "trainer.train(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b148890-0153-4c8b-9d85-992eee52d8f4",
   "metadata": {},
   "source": [
    "- `batch_size`: number of samples per training batch. The default value is `2000`\n",
    "- `test_size`: fraction of data reserved for testing. The default value is `0.0`\n",
    "- `val_size`: fraction of data reserved for validation. The default value is `0.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac8856-4118-42bc-b23b-dcfbbf1871fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
