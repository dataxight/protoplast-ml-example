{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Simple Classifier Model for Single-Cell Data with PROTOplast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a8f1a",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use PROTOplast to train a simple classification model in PyTorch with the `h5ad` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "**Setup**  \n",
    "- Configure the training environment for single-cell RNA sequencing (scRNA-seq) data using **PROTOplast** in combination with **PyTorch Lightning** and **Ray**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bkHC",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Logging initialized. Current level is: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 1.29 s, total: 20 s\n",
      "Wall time: 7.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import ray\n",
    "import protoplast\n",
    "import glob\n",
    "import os\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedCellLineAnnDataset as Dcl\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f6a639-da4c-43d8-88e4-acec1ed84c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(version(\"protoplast\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "## Simple Classifier\n",
    "\n",
    "This example illustrates how to configure a training runner with **PROTOplast** and **Ray**.\n",
    "\n",
    "- `LinearClassifier`: a simple baseline model that can be swapped with a custom implementation\n",
    "- `Dcl`: the dataset object for training, imported from `protoplast.scrna.anndata.torch_dataloader`\n",
    "  - Defined as a subclass of `DistributedAnnDataset`, customized for cell line classification tasks\n",
    "- `[\"num_genes\", \"num_classes\"]`: arguments that specify the modelâ€™s input and output dimensions\n",
    "- `cell_line_metadata_cb`: a callback function that attaches dataset-specific metadata, such as cell line labels and class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "BYtC",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 06:08:44,275\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-11-07 06:08:44,357\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example/notebooks'.\n",
      "2025-11-07 06:08:44,372\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_beaf74cebfeabf4e.zip' (3.25MiB) to Ray cluster...\n",
      "2025-11-07 06:08:44,390\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_beaf74cebfeabf4e.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 263 ms, sys: 352 ms, total: 615 ms\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,  # replace with your own model\n",
    "    Dcl,  # replace with your own Dataset\n",
    "    [\"num_genes\", \"num_classes\"],  # change according to what you need for your model\n",
    "    cell_line_metadata_cb,  # include data you need for your dataset\n",
    "    runtime_env_config = {\"working_dir\": os.getcwd()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2c38b",
   "metadata": {},
   "source": [
    "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12 GiB)**, **96 CPUs**, and **125 GiB RAM**, running `train()` completed in approximately **7 minutes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396588aa-3b3b-4c6c-b562-0747b9a856c7",
   "metadata": {},
   "source": [
    "- `file_paths`: Plate 12 from Tahoe-100M (The largest file: 35 GB) is used as a demo. To add more plates, append their `.h5ad` file paths to the list, separated by commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "RGSE",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "protoplast.scrna.anndata.trainer - INFO - Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "protoplast.scrna.anndata.trainer - INFO - Using 1 workers where each worker uses: {'CPU': 4, 'GPU': 1}\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of val_split: 65 length of test_split: 0, length of train_split: 262\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of after dropping remainder val_split: 65, length of test_split: 0, length of train_split: 262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=2998691)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainController pid=2998691)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=2998691)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=2998691)\u001b[0m Attempting to start training worker group of size 1 with the following resources: [{'CPU': 4, 'GPU': 1}] * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=2998691)\u001b[0m Started training worker group of size 1: \n",
      "\u001b[36m(TrainController pid=2998691)\u001b[0m - (ip=192.168.1.226, pid=2998964) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   return _C._get_float32_matmul_precision()\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.13it/s]\n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 3/4192 [00:24<9:22:42,  0.12it/s, v_num=0, train_loss=2.920] \n",
      "Epoch 0:   0%|          | 4/4192 [00:24<7:02:19,  0.17it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 0:   0%|          | 9/4192 [00:24<3:08:20,  0.37it/s, v_num=0, train_loss=1.230]\n",
      "...\n",
      "...\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4186/4192 [04:35<00:00, 15.19it/s, v_num=0, train_loss=0.0745]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4191/4192 [04:35<00:00, 15.20it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [04:35<00:00, 15.20it/s, v_num=0, train_loss=0.157]\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1040 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 1/1040 [00:00<00:25, 40.46it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "Validation DataLoader 0:   0%|          | 2/1040 [00:00<08:11,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 3/1040 [00:00<05:34,  3.10it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "Validation DataLoader 0:   0%|          | 4/1040 [00:01<06:38,  2.60it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "...\n",
      "...\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1035/1040 [01:05<00:00, 15.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1036/1040 [01:05<00:00, 15.92it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1037/1040 [01:05<00:00, 15.93it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1038/1040 [01:05<00:00, 15.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1039/1040 [01:05<00:00, 15.95it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1040/1040 [01:05<00:00, 15.96it/s]\u001b[A\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:03<00:00, 11.53it/s, v_num=0, train_loss=0.157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-07_06-09-09/checkpoint_2025-11-07_06-16-00.959916)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-07_06-09-09/checkpoint_2025-11-07_06-16-00.959916), metrics={'train_loss': 0.15666209161281586, 'val_acc': 0.9862812757492065, 'epoch': 0, 'step': 4192}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=2998964)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:03<00:00, 11.52it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4192/4192 [06:04<00:00, 11.52it/s, v_num=0, train_loss=0.157]\n",
      "CPU times: user 21.4 s, sys: 3.69 s, total: 25 s\n",
      "Wall time: 7min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(metrics={'train_loss': 0.15666209161281586, 'val_acc': 0.9862812757492065, 'epoch': 0, 'step': 4192}, checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-07_06-09-09/checkpoint_2025-11-07_06-16-00.959916), error=None, path='/home/dtran/protoplast_results/ray_train_run-2025-11-07_06-09-09', metrics_dataframe=   train_loss   val_acc  epoch  step\n",
       "0    0.156662  0.986281      0  4192, best_checkpoints=[(Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-07_06-09-09/checkpoint_2025-11-07_06-16-00.959916), {'train_loss': 0.15666209161281586, 'val_acc': 0.9862812757492065, 'epoch': 0, 'step': 4192})], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7ccac5760570>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [\"/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
    "trainer.train(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b148890-0153-4c8b-9d85-992eee52d8f4",
   "metadata": {},
   "source": [
    "- `batch_size`: number of samples per training batch. The default value is `2000`\n",
    "- `test_size`: fraction of data reserved for testing. The default value is `0.0`\n",
    "- `val_size`: fraction of data reserved for validation. The default value is `0.2`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
