{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafea7f0-d2e6-45e3-8f95-6ab4c2775eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import protoplast as pt\n",
    "import ray\n",
    "import torch\n",
    "\n",
    "from anndata.experimental import AnnCollection\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedAnnDataset\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb, DistributedCellLineAnnDataset\n",
    "\n",
    "from ray.train import Checkpoint\n",
    "from ray.train.lightning import RayDDPStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2805ec-0a19-422c-9c31-e477e2fc3ca0",
   "metadata": {},
   "source": [
    "## Training Set Overview\n",
    "To start, we load the dataset used to train the example gene perturbation model featured in this notebook. This dataset will also serve as the basis for filtering non-targeting controls in the final prediction set, which we'll submit to the Virtual Cell Challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6de799-c988-409a-866a-20829759c8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_gene</th>\n",
       "      <th>guide_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>batch_var</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACAAGCAACCTTGTACTTTAGG-Flex_1_01</th>\n",
       "      <td>CHMP3</td>\n",
       "      <td>CHMP3_P1P2_A|CHMP3_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAAGCATTGCCGCACTTTAGG-Flex_1_01</th>\n",
       "      <td>AKT2</td>\n",
       "      <td>AKT2_P1P2_A|AKT2_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCAATCAATGTTCACTTTAGG-Flex_1_01</th>\n",
       "      <td>SHPRH</td>\n",
       "      <td>SHPRH_P1P2_A|SHPRH_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCAATCCCTCGCTACTTTAGG-Flex_1_01</th>\n",
       "      <td>TMSB4X</td>\n",
       "      <td>TMSB4X_P1_A|TMSB4X_P1_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCAATCTAAATCCACTTTAGG-Flex_1_01</th>\n",
       "      <td>KLF10</td>\n",
       "      <td>KLF10_P2_A|KLF10_P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   target_gene                   guide_id  \\\n",
       "AAACAAGCAACCTTGTACTTTAGG-Flex_1_01       CHMP3  CHMP3_P1P2_A|CHMP3_P1P2_B   \n",
       "AAACAAGCATTGCCGCACTTTAGG-Flex_1_01        AKT2    AKT2_P1P2_A|AKT2_P1P2_B   \n",
       "AAACCAATCAATGTTCACTTTAGG-Flex_1_01       SHPRH  SHPRH_P1P2_A|SHPRH_P1P2_B   \n",
       "AAACCAATCCCTCGCTACTTTAGG-Flex_1_01      TMSB4X    TMSB4X_P1_A|TMSB4X_P1_B   \n",
       "AAACCAATCTAAATCCACTTTAGG-Flex_1_01       KLF10      KLF10_P2_A|KLF10_P2_B   \n",
       "\n",
       "                                        batch  batch_var cell_type  \n",
       "AAACAAGCAACCTTGTACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AAACAAGCATTGCCGCACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AAACCAATCAATGTTCACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AAACCAATCCCTCGCTACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AAACCAATCTAAATCCACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = [\"/mnt/hdd2/tan/competition_support_set/competition_train.h5\"]\n",
    "adata = anndata.read_h5ad(file_paths[0], backed = \"r\")\n",
    "adata.obs.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ff28e-950b-4c8e-ae54-ab9d05ec6363",
   "metadata": {},
   "source": [
    "## Define example perturbation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbfc2cd-2d12-4182-b5ed-7401e0ca0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ExampleModel(pl.LightningModule):\n",
    "    def __init__(self, num_genes, num_classes, control_pert, pert_names):\n",
    "        super().__init__()\n",
    "        self.control_pert = control_pert\n",
    "        self.pert_names = pert_names\n",
    "        self.embedding = nn.Embedding(num_embeddings = len(pert_names), embedding_dim = num_genes)\n",
    "        self.output = nn.Linear(num_genes, num_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        embed = self.embedding(batch)\n",
    "        out = self.output(embed).squeeze(1)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \n",
    "        \n",
    "        batch_pert_cell_counts = batch[\"pert_cell_counts\"]\n",
    "        X = batch_pert_cell_counts\n",
    "\n",
    "        batch_pert_names = np.array(batch[\"pert_name\"])\n",
    "        sorted_idx = np.argsort(self.pert_names)\n",
    "        pos = np.searchsorted(self.pert_names[sorted_idx], batch_pert_names)\n",
    "        indices = torch.tensor(sorted_idx[pos]).unsqueeze(1).to(device)\n",
    "\n",
    "        out = self(indices)\n",
    "        mse_loss_fn = nn.MSELoss()\n",
    "        loss = mse_loss_fn(out, X)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ca827a-053d-469b-a424-68cbb669495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbAnnDataset(DistributedAnnDataset):\n",
    "    def transform(self, start: int, end: int):\n",
    "        X = super().transform(start, end)\n",
    "\n",
    "        # Metadata froms self.ad\n",
    "        pert_names = self.ad.obs[\"target_gene\"].iloc[start:end].astype(str).to_list()\n",
    "\n",
    "        return {\n",
    "            \"pert_name\": pert_names,\n",
    "            \"pert_cell_counts\": X\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196177c-f1b5-4faa-aa31-ecea8a2ae0b0",
   "metadata": {},
   "source": [
    "## Configure the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2358f279-1f59-43a9-9078-143162455dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = adata.n_vars\n",
    "output_size = adata.n_vars\n",
    "control_pert = \"non-targeting\"\n",
    "\n",
    "validation_genes = pd.read_csv(\"/mnt/hdd2/tan/competition_support_set/pert_counts_Validation.csv\").target_gene\n",
    "pert_names = np.array(adata.obs.target_gene.unique().tolist() + validation_genes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a98412e2-8a7a-4559-b945-9c457382b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_cb(ad: anndata.AnnData, metadata: dict):\n",
    "    metadata[\"num_genes\"] = num_genes\n",
    "    metadata[\"num_classes\"] = output_size\n",
    "    metadata[\"control_pert\"] = control_pert\n",
    "    metadata[\"pert_names\"] = pert_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26051533-8080-4995-888a-5ba4fd6d94dc",
   "metadata": {},
   "source": [
    "## Create trainer & train perturbation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ebee8a-5eb5-42e8-9e95-a4f9cf677d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 13:23:20,084\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "\u001b[36m(pid=2601474)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "\u001b[36m(pid=2601474)\u001b[0m   import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=2601474)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainTrainable pid=2601474)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m   import pynvml  # type: ignore[import]\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=2601474)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=2601474)\u001b[0m - (node_id=dead53e42ca5e556bc76dfd97e8f424f74a97e8028e458b770249e18, ip=192.168.1.226, pid=2601762) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m =========Starting the training on 0 with num threads: 2=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.11 /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.1 ...\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m   | Name      | Type      | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m ------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 0 | embedding | Embedding | 3.6 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 1 | output    | Linear    | 326 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m ------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 330 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 330 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 1,322.154 Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:115: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /home/nam/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:115: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m /mnt/hdd2/nam/miniconda3/envs/test/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m   return torch.sparse_compressed_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 1/96 [00:03<06:11,  0.26it/s]\n",
      "Epoch 0:   1%|          | 1/96 [00:03<06:12,  0.25it/s, v_num=0, train_loss=1.680]\n",
      "Epoch 0:   2%|â–         | 2/96 [00:04<03:12,  0.49it/s, v_num=0, train_loss=1.680]\n",
      "Epoch 0:   2%|â–         | 2/96 [00:04<03:20,  0.47it/s, v_num=0, train_loss=19.30]\n",
      "Epoch 0:   3%|â–Ž         | 3/96 [00:04<02:17,  0.68it/s, v_num=0, train_loss=19.30]\n",
      "Epoch 0:   3%|â–Ž         | 3/96 [00:04<02:22,  0.65it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 0:   4%|â–         | 4/96 [00:04<01:49,  0.84it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 0:   4%|â–         | 4/96 [00:04<01:53,  0.81it/s, v_num=0, train_loss=7.710]\n",
      "Epoch 0:   5%|â–Œ         | 5/96 [00:05<01:33,  0.98it/s, v_num=0, train_loss=7.710]\n",
      "Epoch 0:   5%|â–Œ         | 5/96 [00:05<01:36,  0.95it/s, v_num=0, train_loss=11.10]\n",
      "Epoch 0:   6%|â–‹         | 6/96 [00:05<01:21,  1.10it/s, v_num=0, train_loss=11.10]\n",
      "Epoch 0:   6%|â–‹         | 6/96 [00:05<01:24,  1.07it/s, v_num=0, train_loss=6.330]\n",
      "Epoch 0:   7%|â–‹         | 7/96 [00:05<01:13,  1.20it/s, v_num=0, train_loss=6.330]\n",
      "Epoch 0:   7%|â–‹         | 7/96 [00:05<01:16,  1.17it/s, v_num=0, train_loss=1.170]\n",
      "Epoch 0:   8%|â–Š         | 8/96 [00:06<01:07,  1.30it/s, v_num=0, train_loss=1.170]\n",
      "Epoch 0:   8%|â–Š         | 8/96 [00:06<01:09,  1.27it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 0:   9%|â–‰         | 9/96 [00:06<01:02,  1.38it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 0:   9%|â–‰         | 9/96 [00:06<01:04,  1.35it/s, v_num=0, train_loss=6.830]\n",
      "Epoch 0:  10%|â–ˆ         | 10/96 [00:06<00:58,  1.46it/s, v_num=0, train_loss=6.830]\n",
      "Epoch 0:  10%|â–ˆ         | 10/96 [00:07<01:00,  1.43it/s, v_num=0, train_loss=5.560]\n",
      "Epoch 0:  11%|â–ˆâ–        | 11/96 [00:07<00:55,  1.53it/s, v_num=0, train_loss=5.560]\n",
      "Epoch 0:  11%|â–ˆâ–        | 11/96 [00:07<00:56,  1.49it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 0:  12%|â–ˆâ–Ž        | 12/96 [00:07<00:52,  1.59it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 0:  12%|â–ˆâ–Ž        | 12/96 [00:07<00:53,  1.56it/s, v_num=0, train_loss=1.010]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 13/96 [00:07<00:50,  1.65it/s, v_num=0, train_loss=1.010]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 13/96 [00:08<00:51,  1.62it/s, v_num=0, train_loss=1.900]\n",
      "Epoch 0:  15%|â–ˆâ–        | 14/96 [00:08<00:48,  1.70it/s, v_num=0, train_loss=1.900]\n",
      "Epoch 0:  15%|â–ˆâ–        | 14/96 [00:08<00:49,  1.67it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 15/96 [00:08<00:46,  1.75it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 15/96 [00:08<00:47,  1.72it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 16/96 [00:08<00:44,  1.80it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 16/96 [00:09<00:45,  1.76it/s, v_num=0, train_loss=1.980]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 17/96 [00:09<00:42,  1.84it/s, v_num=0, train_loss=1.980]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 17/96 [00:09<00:43,  1.81it/s, v_num=0, train_loss=0.904]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 18/96 [00:09<00:41,  1.88it/s, v_num=0, train_loss=0.904]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 18/96 [00:09<00:42,  1.84it/s, v_num=0, train_loss=1.040]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 19/96 [00:09<00:40,  1.91it/s, v_num=0, train_loss=1.040]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 19/96 [00:10<00:40,  1.88it/s, v_num=0, train_loss=1.610]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 20/96 [00:10<00:39,  1.94it/s, v_num=0, train_loss=1.610]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 20/96 [00:10<00:39,  1.91it/s, v_num=0, train_loss=1.890]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 21/96 [00:10<00:38,  1.96it/s, v_num=0, train_loss=1.890]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 21/96 [00:10<00:38,  1.93it/s, v_num=0, train_loss=1.570]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:11<00:37,  1.99it/s, v_num=0, train_loss=1.570]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:11<00:37,  1.96it/s, v_num=0, train_loss=0.836]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 23/96 [00:11<00:36,  2.02it/s, v_num=0, train_loss=0.836]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 23/96 [00:11<00:36,  1.99it/s, v_num=0, train_loss=0.655]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:11<00:35,  2.05it/s, v_num=0, train_loss=0.655]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:11<00:35,  2.02it/s, v_num=0, train_loss=0.937]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:12<00:34,  2.07it/s, v_num=0, train_loss=0.937]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:12<00:34,  2.04it/s, v_num=0, train_loss=1.110]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 26/96 [00:12<00:33,  2.09it/s, v_num=0, train_loss=1.110]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 26/96 [00:12<00:33,  2.06it/s, v_num=0, train_loss=1.040]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 27/96 [00:12<00:32,  2.11it/s, v_num=0, train_loss=1.040]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 27/96 [00:12<00:33,  2.09it/s, v_num=0, train_loss=0.655]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 28/96 [00:13<00:31,  2.13it/s, v_num=0, train_loss=0.655]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 28/96 [00:13<00:32,  2.11it/s, v_num=0, train_loss=0.534]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:13<00:31,  2.15it/s, v_num=0, train_loss=0.534]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:13<00:31,  2.13it/s, v_num=0, train_loss=0.570]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:13<00:30,  2.17it/s, v_num=0, train_loss=0.570]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:13<00:30,  2.15it/s, v_num=0, train_loss=0.702]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:14<00:29,  2.19it/s, v_num=0, train_loss=0.702]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:14<00:30,  2.16it/s, v_num=0, train_loss=0.649]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:14<00:29,  2.21it/s, v_num=0, train_loss=0.649]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:14<00:29,  2.18it/s, v_num=0, train_loss=0.558]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:15<00:28,  2.18it/s, v_num=0, train_loss=0.558]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:15<00:29,  2.16it/s, v_num=0, train_loss=0.411]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:15<00:28,  2.19it/s, v_num=0, train_loss=0.411]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:15<00:28,  2.16it/s, v_num=0, train_loss=0.451]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:15<00:27,  2.20it/s, v_num=0, train_loss=0.451]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:16<00:27,  2.18it/s, v_num=0, train_loss=0.473]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:16<00:27,  2.21it/s, v_num=0, train_loss=0.473]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:16<00:27,  2.19it/s, v_num=0, train_loss=0.509]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:16<00:26,  2.22it/s, v_num=0, train_loss=0.509]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:16<00:26,  2.20it/s, v_num=0, train_loss=0.377]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:16<00:25,  2.24it/s, v_num=0, train_loss=0.377]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:17<00:26,  2.21it/s, v_num=0, train_loss=0.352]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:17<00:25,  2.25it/s, v_num=0, train_loss=0.352]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:17<00:25,  2.23it/s, v_num=0, train_loss=0.345]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:17<00:24,  2.26it/s, v_num=0, train_loss=0.345]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:17<00:24,  2.24it/s, v_num=0, train_loss=0.340]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:18<00:24,  2.27it/s, v_num=0, train_loss=0.340]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:18<00:24,  2.25it/s, v_num=0, train_loss=0.326]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:18<00:23,  2.29it/s, v_num=0, train_loss=0.326]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:18<00:23,  2.27it/s, v_num=0, train_loss=0.340]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:18<00:23,  2.30it/s, v_num=0, train_loss=0.340]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:18<00:23,  2.28it/s, v_num=0, train_loss=0.282]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:19<00:22,  2.31it/s, v_num=0, train_loss=0.282]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:19<00:22,  2.29it/s, v_num=0, train_loss=0.283]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:19<00:21,  2.32it/s, v_num=0, train_loss=0.283]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:19<00:22,  2.30it/s, v_num=0, train_loss=0.255]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:19<00:21,  2.33it/s, v_num=0, train_loss=0.255]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:19<00:21,  2.31it/s, v_num=0, train_loss=0.285]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:20<00:20,  2.34it/s, v_num=0, train_loss=0.285]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:20<00:21,  2.32it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:20<00:20,  2.35it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:20<00:20,  2.33it/s, v_num=0, train_loss=0.250]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:20<00:19,  2.36it/s, v_num=0, train_loss=0.250]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:20<00:20,  2.34it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:21<00:19,  2.37it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:21<00:19,  2.35it/s, v_num=0, train_loss=0.230]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:21<00:18,  2.37it/s, v_num=0, train_loss=0.230]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:21<00:19,  2.36it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:21<00:18,  2.38it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:21<00:18,  2.36it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:22<00:17,  2.39it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:22<00:18,  2.37it/s, v_num=0, train_loss=0.223]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:22<00:17,  2.40it/s, v_num=0, train_loss=0.223]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:22<00:17,  2.38it/s, v_num=0, train_loss=0.211]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:22<00:17,  2.41it/s, v_num=0, train_loss=0.211]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:23<00:17,  2.39it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:23<00:16,  2.41it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:23<00:16,  2.40it/s, v_num=0, train_loss=0.223]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:23<00:16,  2.42it/s, v_num=0, train_loss=0.223]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:23<00:16,  2.40it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:23<00:15,  2.43it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:24<00:15,  2.41it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:24<00:15,  2.43it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:24<00:15,  2.42it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:24<00:14,  2.44it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:24<00:14,  2.42it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:24<00:14,  2.44it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:25<00:14,  2.43it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:25<00:13,  2.45it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:25<00:13,  2.43it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:25<00:13,  2.46it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:25<00:13,  2.44it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:26<00:13,  2.46it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:26<00:13,  2.45it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:26<00:12,  2.44it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:26<00:12,  2.42it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:27<00:12,  2.44it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:27<00:12,  2.43it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:27<00:11,  2.45it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:27<00:11,  2.43it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:27<00:11,  2.45it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:27<00:11,  2.44it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:28<00:10,  2.46it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:28<00:11,  2.44it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:28<00:10,  2.46it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:28<00:10,  2.45it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:28<00:10,  2.47it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:28<00:10,  2.46it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:29<00:09,  2.47it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:29<00:09,  2.46it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:29<00:09,  2.48it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:29<00:09,  2.47it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:29<00:08,  2.48it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:29<00:08,  2.47it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:30<00:08,  2.49it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:30<00:08,  2.47it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:30<00:08,  2.49it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:30<00:08,  2.48it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:30<00:07,  2.50it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:31<00:07,  2.48it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:31<00:07,  2.50it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:31<00:07,  2.49it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:31<00:06,  2.51it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:31<00:06,  2.49it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:31<00:06,  2.51it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:32<00:06,  2.50it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:32<00:05,  2.51it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:32<00:05,  2.50it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:32<00:05,  2.52it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:32<00:05,  2.51it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:32<00:05,  2.52it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:33<00:05,  2.51it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:33<00:04,  2.53it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:33<00:04,  2.51it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:33<00:04,  2.53it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:33<00:04,  2.52it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:33<00:03,  2.53it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:34<00:03,  2.52it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:34<00:03,  2.54it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:34<00:03,  2.53it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:34<00:03,  2.54it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:34<00:03,  2.53it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:34<00:02,  2.55it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:35<00:02,  2.53it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:35<00:02,  2.55it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:35<00:02,  2.54it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:35<00:01,  2.55it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:35<00:01,  2.54it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:35<00:01,  2.56it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:36<00:01,  2.54it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:36<00:01,  2.56it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:36<00:01,  2.55it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:36<00:00,  2.56it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:36<00:00,  2.55it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:37<00:00,  2.57it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:37<00:00,  2.55it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:37<00:00,  2.54it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:37<00:00,  2.53it/s, v_num=0, train_loss=0.185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/nam/protoplast_results/TorchTrainer_2025-09-28_13-23-24/TorchTrainer_4f753_00000_0_2025-09-28_13-23-24/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:53<00:00,  1.81it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [01:04<00:00,  1.48it/s, v_num=0, train_loss=0.185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2601762)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = RayTrainRunner(\n",
    "    ExampleModel,\n",
    "    PerturbAnnDataset,\n",
    "    model_keys = [\"num_genes\",\n",
    "                  \"num_classes\",\n",
    "                  \"control_pert\",\n",
    "                  \"pert_names\"],\n",
    "    metadata_cb = metadata_cb,\n",
    "    sparse_key = \"X\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3178ad-2069-4406-9d32-6d674d3b0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 workers with {'CPU': 2} each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 13:23:24,183\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Length of val_split 0 length of test_split 0 length of train_split 6\n",
      "=========Length of after dropping remainder val_split 0 length of test_split 0 length of train_split 6\n",
      "Data splitting time: 0.24 seconds\n",
      "Spawning Ray worker and initiating distributed training\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:24 (running for 00:00:00.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:29 (running for 00:00:05.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:34 (running for 00:00:10.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:39 (running for 00:00:15.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:44 (running for 00:00:20.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:49 (running for 00:00:25.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:54 (running for 00:00:30.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:23:59 (running for 00:00:35.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:04 (running for 00:00:40.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:09 (running for 00:00:45.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:14 (running for 00:00:50.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:19 (running for 00:00:55.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:24 (running for 00:01:00.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:29 (running for 00:01:05.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:34 (running for 00:01:10.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:39 (running for 00:01:15.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:44 (running for 00:01:20.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:49 (running for 00:01:25.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:55 (running for 00:01:30.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 13:24:58,921\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/nam/protoplast_results/TorchTrainer_2025-09-28_13-23-24' in 0.0099s.\n",
      "2025-09-28 13:24:58,925\tINFO tune.py:1041 -- Total run time: 94.74 seconds (94.70 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-28 13:24:58 (running for 00:01:34.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-09-28_13-23-17_060244_2592720/artifacts/2025-09-28_13-23-24/TorchTrainer_2025-09-28_13-23-24/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread_per_worker = 2\n",
    "batch_size = 2000\n",
    "test_size = 0.0\n",
    "val_size = 0.0\n",
    "\n",
    "result = trainer.train(\n",
    "    file_paths = file_paths,\n",
    "    batch_size = batch_size,\n",
    "    test_size = test_size,\n",
    "    val_size = val_size,\n",
    "    thread_per_worker = thread_per_worker,  # 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e430b9-c51d-4567-9418-cf87164b52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3690e8-0489-4b59-a3cd-020f66e8d6a8",
   "metadata": {},
   "source": [
    "## Perturbation Prediction Using the Trained Model\n",
    "\n",
    "With the model trained, we can now generate perturbation predictions. We'll start by loading the validation set, which provides the target genes and the number of predictions required for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364e0ac3-dd0a-4be1-990b-c8aa98c67cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_gene</th>\n",
       "      <th>n_cells</th>\n",
       "      <th>median_umi_per_cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SH3BP4</td>\n",
       "      <td>2925</td>\n",
       "      <td>54551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZNF581</td>\n",
       "      <td>2502</td>\n",
       "      <td>53803.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANXA6</td>\n",
       "      <td>2496</td>\n",
       "      <td>55175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PACSIN3</td>\n",
       "      <td>2101</td>\n",
       "      <td>54088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGST1</td>\n",
       "      <td>2096</td>\n",
       "      <td>54217.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_gene  n_cells  median_umi_per_cell\n",
       "0      SH3BP4     2925              54551.0\n",
       "1      ZNF581     2502              53803.5\n",
       "2       ANXA6     2496              55175.0\n",
       "3     PACSIN3     2101              54088.0\n",
       "4       MGST1     2096              54217.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set = pd.read_csv(\"/mnt/hdd2/tan/competition_support_set/pert_counts_Validation.csv\")\n",
    "validation_set.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68fca003-782c-4b2d-8fc5-3fa21b489363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2592720/459944279.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  tmp = torch.tensor([np.where(pert_names == row.target_gene)][0] * row.n_cells)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([]).long()\n",
    "for row in validation_set.iloc:\n",
    "    tmp = torch.tensor([np.where(pert_names == row.target_gene)][0] * row.n_cells)\n",
    "    X = torch.cat((X, tmp), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2747fb3-c89c-4e1e-8ce8-b77314550075",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \n",
    "X = X.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19be68-9877-4efd-968d-85be3e4184b4",
   "metadata": {},
   "source": [
    "Load the trained model from the checkpoint path in previous `train()` step & make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7da26a3-ab67-49fc-97eb-ca276de0919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExampleModel(\n",
       "  (embedding): Embedding(201, 18080)\n",
       "  (output): Linear(in_features=18080, out_features=18080, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExampleModel.load_from_checkpoint(result.checkpoint.path + \"/checkpoint.ckpt\", \n",
    "                                          num_genes = num_genes, \n",
    "                                          num_classes = output_size, \n",
    "                                          control_pert = control_pert, \n",
    "                                          pert_names = pert_names)\n",
    "model.eval()  # set to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b2f57c-ad8a-40b2-b89e-ee2adb4379fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3546,  0.6941,  0.3020,  ...,  0.7363,  0.4245, -0.1082],\n",
      "        [ 0.3546,  0.6941,  0.3020,  ...,  0.7363,  0.4245, -0.1082],\n",
      "        [ 0.3546,  0.6941,  0.3020,  ...,  0.7363,  0.4245, -0.1082],\n",
      "        ...,\n",
      "        [-0.3894, -0.5620, -0.1625,  ...,  0.2070,  0.5451,  0.2905],\n",
      "        [-0.3894, -0.5620, -0.1625,  ...,  0.2070,  0.5451,  0.2905],\n",
      "        [-0.3894, -0.5620, -0.1625,  ...,  0.2070,  0.5451,  0.2905]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3670284-0cc0-418a-b8dc-8ee136c00d3a",
   "metadata": {},
   "source": [
    "## Creating the Predicted AnnData\n",
    "Next, we generate an `AnnData` object from the modelâ€™s predicted gene perturbations. To complete the dataset, we also include the non-targeting control group. Since these controls aren't part of the prediction, we'll copy them directly from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38a7ab4-95fc-4202-aed7-05986736e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted_adata = anndata.AnnData(\n",
    "    X = pred.cpu().detach().numpy(),\n",
    "    obs = pd.DataFrame(\n",
    "        {\n",
    "            \"target_gene\": np.repeat(validation_set.target_gene, validation_set.n_cells).tolist(),\n",
    "        },\n",
    "        index = np.arange(validation_set.n_cells.sum()).astype(str),\n",
    "    ),\n",
    "    var = pd.DataFrame(index = list(adata.var_names)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fd8bdd4-6e5d-4cef-9b21-cda53dc1146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = anndata.concat([adata[adata.obs[\"target_gene\"] == \"non-targeting\"], \n",
    "                                    sample_predicted_adata])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24e1f02-42c4-4141-92a3-dc275a4f769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.write_h5ad(\"~/result/prediction.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3170894-f8da-4165-90f4-c951a946fade",
   "metadata": {},
   "source": [
    "## Running `cell-eval`\n",
    "\n",
    "Weâ€™ll now use `cell-eval` to process the `AnnData` object and prepare it for submission to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde38b8c-ebc5-475f-aeb9-97c9c30625bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cell_eval._cli._prep:Reading input anndata\n",
      "INFO:cell_eval._cli._prep:Reading gene list\n",
      "INFO:cell_eval._cli._prep:Preparing anndata\n",
      "INFO:cell_eval._cli._prep:Using 32-bit float encoding\n",
      "INFO:cell_eval._cli._prep:Setting data to sparse if not already\n"
     ]
    }
   ],
   "source": [
    "!cell-eval prep -i ~/result/prediction.h5ad -g /mnt/hdd2/tan/competition_support_set/gene_names.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
