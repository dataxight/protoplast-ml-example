{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c022736-7418-4ed6-a354-9e88d55b6a06",
   "metadata": {},
   "source": [
    "# Model Training and Inference with PROTOplast for the Virtual Cell Challenge\n",
    "This tutorial walks through the process of building a PyTorch Lightning model and training it using the PROTOplast for the Virtual Cell Challenge (VCC). It also covers loading a trained model from a checkpoint for inference, making predictions, writing the results into an AnnData object, and preparing a submission using the `cell-eval` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafea7f0-d2e6-45e3-8f95-6ab4c2775eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Logging initialized. Current level is: INFO\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import protoplast as pt\n",
    "import ray\n",
    "import torch\n",
    "\n",
    "from anndata.experimental import AnnCollection\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedAnnDataset\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb, DistributedCellLineAnnDataset\n",
    "\n",
    "from ray.train import Checkpoint\n",
    "from ray.train.lightning import RayDDPStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9f99b0-db7f-45bf-9880-3b023dd6217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(version(\"protoplast\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2805ec-0a19-422c-9c31-e477e2fc3ca0",
   "metadata": {},
   "source": [
    "## Training Set Overview\n",
    "To start, we load the dataset used to train the example gene perturbation model featured in this notebook. This dataset will also serve as the basis for filtering non-targeting controls in the final prediction set, which we'll submit to the Virtual Cell Challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6de799-c988-409a-866a-20829759c8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_gene</th>\n",
       "      <th>guide_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>batch_var</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCTGGAAGATTATCCACTTTAGG-Flex_1_01</th>\n",
       "      <td>ACAT2</td>\n",
       "      <td>ACAT2_P1P2_A|ACAT2_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGCCTGTTCCTGGTTAACTTTAGG-Flex_1_01</th>\n",
       "      <td>ACAT2</td>\n",
       "      <td>ACAT2_P1P2_A|ACAT2_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGGCTTGAGTTTGACTACTTTAGG-Flex_1_01</th>\n",
       "      <td>ACAT2</td>\n",
       "      <td>ACAT2_P1P2_A|ACAT2_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGTCATAAGGTTAGACACTTTAGG-Flex_1_01</th>\n",
       "      <td>ACAT2</td>\n",
       "      <td>ACAT2_P1P2_A|ACAT2_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATCCATCCATTTGGAGACTTTAGG-Flex_1_01</th>\n",
       "      <td>ACAT2</td>\n",
       "      <td>ACAT2_P1P2_A|ACAT2_P1P2_B</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>Flex_1_01</td>\n",
       "      <td>ARC_H1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   target_gene                   guide_id  \\\n",
       "ACCTGGAAGATTATCCACTTTAGG-Flex_1_01       ACAT2  ACAT2_P1P2_A|ACAT2_P1P2_B   \n",
       "AGCCTGTTCCTGGTTAACTTTAGG-Flex_1_01       ACAT2  ACAT2_P1P2_A|ACAT2_P1P2_B   \n",
       "AGGCTTGAGTTTGACTACTTTAGG-Flex_1_01       ACAT2  ACAT2_P1P2_A|ACAT2_P1P2_B   \n",
       "AGTCATAAGGTTAGACACTTTAGG-Flex_1_01       ACAT2  ACAT2_P1P2_A|ACAT2_P1P2_B   \n",
       "ATCCATCCATTTGGAGACTTTAGG-Flex_1_01       ACAT2  ACAT2_P1P2_A|ACAT2_P1P2_B   \n",
       "\n",
       "                                        batch  batch_var cell_type  \n",
       "ACCTGGAAGATTATCCACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AGCCTGTTCCTGGTTAACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AGGCTTGAGTTTGACTACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "AGTCATAAGGTTAGACACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  \n",
       "ATCCATCCATTTGGAGACTTTAGG-Flex_1_01  Flex_1_01  Flex_1_01    ARC_H1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = [\"/mnt/hdd2/tan/competition_support_set_sorted/competition_train.h5\"]\n",
    "adata = anndata.read_h5ad(file_paths[0], backed = \"r\")\n",
    "adata.obs.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ff28e-950b-4c8e-ae54-ab9d05ec6363",
   "metadata": {},
   "source": [
    "## Define example perturbation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbfc2cd-2d12-4182-b5ed-7401e0ca0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ExampleModel(pl.LightningModule):\n",
    "    def __init__(self, num_genes, num_classes, control_pert, pert_names):\n",
    "        super().__init__()\n",
    "        self.control_pert = control_pert\n",
    "        self.pert_names = pert_names\n",
    "        self.embedding = nn.Embedding(num_embeddings = len(pert_names), embedding_dim = num_genes)\n",
    "        self.output = nn.Linear(num_genes, num_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        embed = self.embedding(batch)\n",
    "        out = self.output(embed).squeeze(1)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \n",
    "        \n",
    "        batch_pert_cell_counts = batch[\"pert_cell_counts\"]\n",
    "        X = batch_pert_cell_counts\n",
    "\n",
    "        batch_pert_names = np.array(batch[\"pert_name\"])\n",
    "        sorted_idx = np.argsort(self.pert_names)\n",
    "        pos = np.searchsorted(self.pert_names[sorted_idx], batch_pert_names)\n",
    "        indices = torch.tensor(sorted_idx[pos]).unsqueeze(1).to(device)\n",
    "\n",
    "        out = self(indices)\n",
    "        mse_loss_fn = nn.MSELoss()\n",
    "        loss = mse_loss_fn(out, X)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca827a-053d-469b-a424-68cbb669495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbAnnDataset(DistributedAnnDataset):\n",
    "    def transform(self, start: int, end: int):\n",
    "        X = super().transform(start, end)\n",
    "\n",
    "        # Metadata froms self.ad\n",
    "        pert_names = self.ad.obs[\"target_gene\"].iloc[start:end].astype(str).to_list()\n",
    "\n",
    "        return {\n",
    "            \"pert_name\": pert_names,\n",
    "            \"pert_cell_counts\": X\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196177c-f1b5-4faa-aa31-ecea8a2ae0b0",
   "metadata": {},
   "source": [
    "## Configure the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2358f279-1f59-43a9-9078-143162455dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = adata.n_vars\n",
    "output_size = adata.n_vars\n",
    "control_pert = \"non-targeting\"\n",
    "\n",
    "validation_genes = pd.read_csv(\"/mnt/hdd1/dung/tahoe100/pert_counts_Validation.csv\").target_gene\n",
    "pert_names = np.array(adata.obs.target_gene.unique().tolist() + validation_genes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98412e2-8a7a-4559-b945-9c457382b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_cb(ad: anndata.AnnData, metadata: dict):\n",
    "    metadata[\"num_genes\"] = num_genes\n",
    "    metadata[\"num_classes\"] = output_size\n",
    "    metadata[\"control_pert\"] = control_pert\n",
    "    metadata[\"pert_names\"] = pert_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26051533-8080-4995-888a-5ba4fd6d94dc",
   "metadata": {},
   "source": [
    "## Create trainer & train perturbation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ebee8a-5eb5-42e8-9e95-a4f9cf677d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 01:22:24,994\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-11-08 01:22:25,020\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example/notebooks'.\n",
      "2025-11-08 01:22:25,041\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_b1dc7d84a1987670.zip' (3.78MiB) to Ray cluster...\n",
      "2025-11-08 01:22:25,063\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_b1dc7d84a1987670.zip'.\n",
      "/mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = RayTrainRunner(\n",
    "    ExampleModel,\n",
    "    PerturbAnnDataset,\n",
    "    model_keys = [\"num_genes\",\n",
    "                  \"num_classes\",\n",
    "                  \"control_pert\",\n",
    "                  \"pert_names\"],\n",
    "    metadata_cb = metadata_cb,\n",
    "    sparse_key = \"X\",\n",
    "    runtime_env_config = {\"working_dir\": os.getcwd()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3178ad-2069-4406-9d32-6d674d3b0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "protoplast.scrna.anndata.trainer - INFO - Using 1 workers where each worker uses: {'CPU': 2, 'GPU': 1}\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of val_split: 0 length of test_split: 0, length of train_split: 6\n",
      "protoplast.scrna.anndata.strategy - INFO - Length of after dropping remainder val_split: 0, length of test_split: 0, length of train_split: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=3286748)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainController pid=3286748)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=3286748)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=3286748)\u001b[0m Attempting to start training worker group of size 1 with the following resources: [{'CPU': 2, 'GPU': 1}] * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m root - INFO - Logging initialized. Current level is: INFO\n",
      "\u001b[36m(TrainController pid=3286748)\u001b[0m Started training worker group of size 1: \n",
      "\u001b[36m(TrainController pid=3286748)\u001b[0m - (ip=192.168.1.226, pid=3290138) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m   return _C._get_float32_matmul_precision()\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m   | Name      | Type      | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m ------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 0 | embedding | Embedding | 3.6 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 1 | output    | Linear    | 326 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m ------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 330 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 330 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 1,322.154 Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/protoplast/scrna/anndata/torch_dataloader.py:135: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m   return torch.sparse_compressed_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 1/96 [00:03<05:12,  0.30it/s, v_num=0, train_loss=1.900]\n",
      "Epoch 0:   2%|â–         | 2/96 [00:03<02:53,  0.54it/s, v_num=0, train_loss=1.800]\n",
      "Epoch 0:   3%|â–Ž         | 3/96 [00:03<01:59,  0.78it/s, v_num=0, train_loss=1.800]\n",
      "Epoch 0:   3%|â–Ž         | 3/96 [00:04<02:04,  0.75it/s, v_num=0, train_loss=34.00]\n",
      "Epoch 0:   4%|â–         | 4/96 [00:04<01:36,  0.96it/s, v_num=0, train_loss=34.00]\n",
      "Epoch 0:   4%|â–         | 4/96 [00:04<01:39,  0.92it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 0:   5%|â–Œ         | 5/96 [00:04<01:22,  1.11it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 0:   5%|â–Œ         | 5/96 [00:04<01:24,  1.07it/s, v_num=0, train_loss=1.880]\n",
      "Epoch 0:   6%|â–‹         | 6/96 [00:04<01:12,  1.24it/s, v_num=0, train_loss=1.880]\n",
      "Epoch 0:   6%|â–‹         | 6/96 [00:04<01:14,  1.20it/s, v_num=0, train_loss=1.480]\n",
      "Epoch 0:   7%|â–‹         | 7/96 [00:05<01:05,  1.35it/s, v_num=0, train_loss=1.480]\n",
      "Epoch 0:   7%|â–‹         | 7/96 [00:05<01:07,  1.31it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 0:   8%|â–Š         | 8/96 [00:05<01:00,  1.45it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 0:   8%|â–Š         | 8/96 [00:05<01:02,  1.41it/s, v_num=0, train_loss=1.310]\n",
      "Epoch 0:   9%|â–‰         | 9/96 [00:05<00:56,  1.54it/s, v_num=0, train_loss=1.310]\n",
      "Epoch 0:   9%|â–‰         | 9/96 [00:05<00:57,  1.50it/s, v_num=0, train_loss=1.690]\n",
      "Epoch 0:  10%|â–ˆ         | 10/96 [00:06<00:53,  1.62it/s, v_num=0, train_loss=1.690]\n",
      "Epoch 0:  10%|â–ˆ         | 10/96 [00:06<00:54,  1.58it/s, v_num=0, train_loss=5.600]\n",
      "Epoch 0:  11%|â–ˆâ–        | 11/96 [00:06<00:50,  1.69it/s, v_num=0, train_loss=5.600]\n",
      "Epoch 0:  11%|â–ˆâ–        | 11/96 [00:06<00:51,  1.65it/s, v_num=0, train_loss=0.537]\n",
      "Epoch 0:  12%|â–ˆâ–Ž        | 12/96 [00:06<00:47,  1.76it/s, v_num=0, train_loss=0.537]\n",
      "Epoch 0:  12%|â–ˆâ–Ž        | 12/96 [00:06<00:48,  1.72it/s, v_num=0, train_loss=1.340]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 13/96 [00:07<00:45,  1.82it/s, v_num=0, train_loss=1.340]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 13/96 [00:07<00:46,  1.78it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 0:  15%|â–ˆâ–        | 14/96 [00:07<00:43,  1.87it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 0:  15%|â–ˆâ–        | 14/96 [00:07<00:44,  1.83it/s, v_num=0, train_loss=0.501]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 15/96 [00:07<00:42,  1.92it/s, v_num=0, train_loss=0.501]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 15/96 [00:07<00:43,  1.88it/s, v_num=0, train_loss=3.640]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 16/96 [00:08<00:40,  1.96it/s, v_num=0, train_loss=3.640]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 16/96 [00:08<00:41,  1.93it/s, v_num=0, train_loss=1.930]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 17/96 [00:08<00:39,  2.01it/s, v_num=0, train_loss=1.930]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 17/96 [00:08<00:40,  1.97it/s, v_num=0, train_loss=3.570]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 18/96 [00:08<00:38,  2.03it/s, v_num=0, train_loss=3.570]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 18/96 [00:09<00:39,  2.00it/s, v_num=0, train_loss=1.210]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 19/96 [00:09<00:37,  2.07it/s, v_num=0, train_loss=1.210]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 19/96 [00:09<00:37,  2.03it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 20/96 [00:09<00:36,  2.10it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 20/96 [00:09<00:36,  2.07it/s, v_num=0, train_loss=1.120]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 21/96 [00:09<00:35,  2.13it/s, v_num=0, train_loss=1.120]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 21/96 [00:09<00:35,  2.10it/s, v_num=0, train_loss=1.650]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:10<00:34,  2.16it/s, v_num=0, train_loss=1.650]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:10<00:34,  2.13it/s, v_num=0, train_loss=2.640]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 23/96 [00:10<00:33,  2.19it/s, v_num=0, train_loss=2.640]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 23/96 [00:10<00:33,  2.16it/s, v_num=0, train_loss=2.110]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:10<00:32,  2.21it/s, v_num=0, train_loss=2.110]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:10<00:32,  2.18it/s, v_num=0, train_loss=1.070]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:11<00:31,  2.24it/s, v_num=0, train_loss=1.070]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:11<00:32,  2.20it/s, v_num=0, train_loss=1.980]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 26/96 [00:11<00:30,  2.26it/s, v_num=0, train_loss=1.980]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 26/96 [00:11<00:31,  2.23it/s, v_num=0, train_loss=2.470]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 27/96 [00:11<00:30,  2.28it/s, v_num=0, train_loss=2.470]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 27/96 [00:12<00:30,  2.25it/s, v_num=0, train_loss=1.350]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 28/96 [00:12<00:29,  2.30it/s, v_num=0, train_loss=1.350]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 28/96 [00:12<00:29,  2.27it/s, v_num=0, train_loss=0.712]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:12<00:28,  2.31it/s, v_num=0, train_loss=0.712]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:12<00:29,  2.28it/s, v_num=0, train_loss=0.701]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:12<00:28,  2.33it/s, v_num=0, train_loss=0.701]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:13<00:28,  2.30it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:13<00:27,  2.35it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:13<00:28,  2.32it/s, v_num=0, train_loss=1.010]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:13<00:27,  2.36it/s, v_num=0, train_loss=1.010]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:13<00:27,  2.34it/s, v_num=0, train_loss=1.420]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:13<00:26,  2.38it/s, v_num=0, train_loss=1.420]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:14<00:26,  2.35it/s, v_num=0, train_loss=0.770]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:14<00:26,  2.34it/s, v_num=0, train_loss=0.770]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:14<00:26,  2.32it/s, v_num=0, train_loss=1.580]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:14<00:25,  2.36it/s, v_num=0, train_loss=1.580]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:15<00:26,  2.33it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:15<00:25,  2.37it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:15<00:25,  2.35it/s, v_num=0, train_loss=4.110]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:15<00:24,  2.38it/s, v_num=0, train_loss=4.110]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:15<00:25,  2.36it/s, v_num=0, train_loss=2.700]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:15<00:24,  2.40it/s, v_num=0, train_loss=2.700]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:16<00:24,  2.37it/s, v_num=0, train_loss=1.730]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:16<00:23,  2.41it/s, v_num=0, train_loss=1.730]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:16<00:23,  2.39it/s, v_num=0, train_loss=1.430]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:16<00:23,  2.42it/s, v_num=0, train_loss=1.430]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:16<00:23,  2.40it/s, v_num=0, train_loss=1.390]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:16<00:22,  2.43it/s, v_num=0, train_loss=1.390]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:17<00:22,  2.41it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:17<00:22,  2.44it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:17<00:22,  2.42it/s, v_num=0, train_loss=1.550]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:17<00:21,  2.45it/s, v_num=0, train_loss=1.550]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:17<00:21,  2.43it/s, v_num=0, train_loss=1.870]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:17<00:21,  2.46it/s, v_num=0, train_loss=1.870]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:18<00:21,  2.44it/s, v_num=0, train_loss=1.510]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:18<00:20,  2.47it/s, v_num=0, train_loss=1.510]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:18<00:20,  2.45it/s, v_num=0, train_loss=1.870]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:18<00:20,  2.48it/s, v_num=0, train_loss=1.870]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:18<00:20,  2.46it/s, v_num=0, train_loss=1.690]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:19<00:20,  2.44it/s, v_num=0, train_loss=1.690]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:19<00:20,  2.42it/s, v_num=0, train_loss=1.490]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:19<00:19,  2.44it/s, v_num=0, train_loss=1.490]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:19<00:19,  2.42it/s, v_num=0, train_loss=1.560]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:19<00:19,  2.45it/s, v_num=0, train_loss=1.560]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:20<00:19,  2.43it/s, v_num=0, train_loss=2.330]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:20<00:18,  2.46it/s, v_num=0, train_loss=2.330]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:20<00:18,  2.44it/s, v_num=0, train_loss=0.725]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:20<00:18,  2.47it/s, v_num=0, train_loss=0.725]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:20<00:18,  2.45it/s, v_num=0, train_loss=4.520]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:20<00:17,  2.48it/s, v_num=0, train_loss=4.520]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:21<00:17,  2.46it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:21<00:17,  2.49it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:21<00:17,  2.47it/s, v_num=0, train_loss=1.960]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:21<00:16,  2.49it/s, v_num=0, train_loss=1.960]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:21<00:16,  2.47it/s, v_num=0, train_loss=1.820]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:21<00:16,  2.50it/s, v_num=0, train_loss=1.820]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:22<00:16,  2.48it/s, v_num=0, train_loss=0.700]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:22<00:15,  2.51it/s, v_num=0, train_loss=0.700]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:22<00:16,  2.49it/s, v_num=0, train_loss=1.870]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:22<00:15,  2.52it/s, v_num=0, train_loss=1.870]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:22<00:15,  2.50it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:22<00:15,  2.52it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:23<00:15,  2.50it/s, v_num=0, train_loss=0.629]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:23<00:14,  2.53it/s, v_num=0, train_loss=0.629]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:23<00:14,  2.51it/s, v_num=0, train_loss=1.120]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:23<00:14,  2.53it/s, v_num=0, train_loss=1.120]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:23<00:14,  2.52it/s, v_num=0, train_loss=1.630]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:24<00:13,  2.54it/s, v_num=0, train_loss=1.630]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:24<00:13,  2.52it/s, v_num=0, train_loss=0.910]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:24<00:13,  2.54it/s, v_num=0, train_loss=0.910]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:24<00:13,  2.53it/s, v_num=0, train_loss=4.150]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:24<00:12,  2.55it/s, v_num=0, train_loss=4.150]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:24<00:13,  2.53it/s, v_num=0, train_loss=1.950]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:25<00:12,  2.55it/s, v_num=0, train_loss=1.950]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:25<00:12,  2.54it/s, v_num=0, train_loss=6.370]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:25<00:12,  2.56it/s, v_num=0, train_loss=6.370]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:25<00:12,  2.54it/s, v_num=0, train_loss=1.480]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:25<00:11,  2.56it/s, v_num=0, train_loss=1.480]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:25<00:11,  2.54it/s, v_num=0, train_loss=1.260]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:26<00:11,  2.56it/s, v_num=0, train_loss=1.260]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:26<00:11,  2.55it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:26<00:10,  2.57it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:26<00:10,  2.55it/s, v_num=0, train_loss=2.150]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:26<00:10,  2.57it/s, v_num=0, train_loss=2.150]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:26<00:10,  2.56it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:27<00:10,  2.58it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:27<00:10,  2.56it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:27<00:09,  2.58it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:27<00:09,  2.57it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:27<00:09,  2.59it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:27<00:09,  2.57it/s, v_num=0, train_loss=2.230]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:28<00:08,  2.59it/s, v_num=0, train_loss=2.230]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:28<00:08,  2.58it/s, v_num=0, train_loss=1.250]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:28<00:08,  2.60it/s, v_num=0, train_loss=1.250]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:28<00:08,  2.58it/s, v_num=0, train_loss=0.495]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:28<00:08,  2.60it/s, v_num=0, train_loss=0.495]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:28<00:08,  2.59it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:29<00:07,  2.61it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:29<00:07,  2.59it/s, v_num=0, train_loss=0.353]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:29<00:07,  2.61it/s, v_num=0, train_loss=0.353]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:29<00:07,  2.60it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:29<00:06,  2.61it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:30<00:06,  2.60it/s, v_num=0, train_loss=1.460]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:30<00:06,  2.62it/s, v_num=0, train_loss=1.460]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:30<00:06,  2.60it/s, v_num=0, train_loss=1.590]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:30<00:06,  2.62it/s, v_num=0, train_loss=1.590]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:30<00:06,  2.61it/s, v_num=0, train_loss=1.960]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:30<00:05,  2.63it/s, v_num=0, train_loss=1.960]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:31<00:05,  2.61it/s, v_num=0, train_loss=1.240]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:31<00:05,  2.63it/s, v_num=0, train_loss=1.240]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:31<00:05,  2.62it/s, v_num=0, train_loss=1.260]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:31<00:04,  2.63it/s, v_num=0, train_loss=1.260]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:31<00:04,  2.62it/s, v_num=0, train_loss=1.620]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:31<00:04,  2.64it/s, v_num=0, train_loss=1.620]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:32<00:04,  2.62it/s, v_num=0, train_loss=1.180]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:32<00:04,  2.64it/s, v_num=0, train_loss=1.180]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:32<00:04,  2.63it/s, v_num=0, train_loss=1.270]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:32<00:03,  2.64it/s, v_num=0, train_loss=1.270]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:32<00:03,  2.63it/s, v_num=0, train_loss=5.560]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:32<00:03,  2.65it/s, v_num=0, train_loss=5.560]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:33<00:03,  2.64it/s, v_num=0, train_loss=1.530]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:33<00:03,  2.65it/s, v_num=0, train_loss=1.530]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:33<00:03,  2.64it/s, v_num=0, train_loss=2.650]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:33<00:02,  2.66it/s, v_num=0, train_loss=2.650]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:33<00:02,  2.64it/s, v_num=0, train_loss=1.360]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:33<00:02,  2.66it/s, v_num=0, train_loss=1.360]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:34<00:02,  2.65it/s, v_num=0, train_loss=0.462]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:34<00:01,  2.66it/s, v_num=0, train_loss=0.462]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:34<00:01,  2.65it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:34<00:01,  2.66it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:34<00:01,  2.65it/s, v_num=0, train_loss=2.040]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:34<00:01,  2.67it/s, v_num=0, train_loss=2.040]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:35<00:01,  2.66it/s, v_num=0, train_loss=1.810]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:35<00:00,  2.67it/s, v_num=0, train_loss=1.810]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:35<00:00,  2.66it/s, v_num=0, train_loss=1.050]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:35<00:00,  2.67it/s, v_num=0, train_loss=1.050]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:35<00:00,  2.66it/s, v_num=0, train_loss=34.70]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:35<00:00,  2.68it/s, v_num=0, train_loss=34.70]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:36<00:00,  2.67it/s, v_num=0, train_loss=3.930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-08_01-22-29/checkpoint_2025-11-08_01-23-43.156005)\n",
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/ray_train_run-2025-11-08_01-22-29/checkpoint_2025-11-08_01-23-43.156005), metrics={'train_loss': 3.930330514907837, 'epoch': 0, 'step': 96}, validation_spec=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:51<00:00,  1.86it/s, v_num=0, train_loss=3.930]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [01:04<00:00,  1.50it/s, v_num=0, train_loss=3.930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=3290138)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "thread_per_worker = 2\n",
    "batch_size = 2000\n",
    "test_size = 0.0\n",
    "val_size = 0.0\n",
    "\n",
    "result = trainer.train(\n",
    "    file_paths = file_paths,\n",
    "    batch_size = batch_size,\n",
    "    test_size = test_size,\n",
    "    val_size = val_size,\n",
    "    thread_per_worker = thread_per_worker,  # 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e430b9-c51d-4567-9418-cf87164b52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3690e8-0489-4b59-a3cd-020f66e8d6a8",
   "metadata": {},
   "source": [
    "## Perturbation Prediction Using the Trained Model\n",
    "\n",
    "With the model trained, we can now generate perturbation predictions. We'll start by loading the validation set, which provides the target genes and the number of predictions required for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "364e0ac3-dd0a-4be1-990b-c8aa98c67cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_gene</th>\n",
       "      <th>n_cells</th>\n",
       "      <th>median_umi_per_cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SH3BP4</td>\n",
       "      <td>2925</td>\n",
       "      <td>54551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZNF581</td>\n",
       "      <td>2502</td>\n",
       "      <td>53803.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANXA6</td>\n",
       "      <td>2496</td>\n",
       "      <td>55175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PACSIN3</td>\n",
       "      <td>2101</td>\n",
       "      <td>54088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGST1</td>\n",
       "      <td>2096</td>\n",
       "      <td>54217.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_gene  n_cells  median_umi_per_cell\n",
       "0      SH3BP4     2925              54551.0\n",
       "1      ZNF581     2502              53803.5\n",
       "2       ANXA6     2496              55175.0\n",
       "3     PACSIN3     2101              54088.0\n",
       "4       MGST1     2096              54217.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set = pd.read_csv(\"/mnt/hdd1/dung/tahoe100/pert_counts_Validation.csv\")\n",
    "validation_set.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68fca003-782c-4b2d-8fc5-3fa21b489363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3279900/459944279.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  tmp = torch.tensor([np.where(pert_names == row.target_gene)][0] * row.n_cells)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([]).long()\n",
    "for row in validation_set.iloc:\n",
    "    tmp = torch.tensor([np.where(pert_names == row.target_gene)][0] * row.n_cells)\n",
    "    X = torch.cat((X, tmp), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2747fb3-c89c-4e1e-8ce8-b77314550075",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \n",
    "X = X.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19be68-9877-4efd-968d-85be3e4184b4",
   "metadata": {},
   "source": [
    "Load the trained model from the checkpoint path in previous `train()` step & make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7da26a3-ab67-49fc-97eb-ca276de0919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExampleModel(\n",
       "  (embedding): Embedding(201, 18080)\n",
       "  (output): Linear(in_features=18080, out_features=18080, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExampleModel.load_from_checkpoint(result.checkpoint.path + \"/checkpoint.ckpt\", \n",
    "                                          num_genes = num_genes, \n",
    "                                          num_classes = output_size, \n",
    "                                          control_pert = control_pert, \n",
    "                                          pert_names = pert_names)\n",
    "model.eval()  # set to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b2f57c-ad8a-40b2-b89e-ee2adb4379fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1231,  0.1643, -1.6772,  ...,  0.8463,  1.7868,  0.9581],\n",
      "        [-0.1231,  0.1643, -1.6772,  ...,  0.8463,  1.7868,  0.9581],\n",
      "        [-0.1231,  0.1643, -1.6772,  ...,  0.8463,  1.7868,  0.9581],\n",
      "        ...,\n",
      "        [-0.9791,  0.2159, -0.8821,  ..., -0.0454,  1.3044,  0.7011],\n",
      "        [-0.9791,  0.2159, -0.8821,  ..., -0.0454,  1.3044,  0.7011],\n",
      "        [-0.9791,  0.2159, -0.8821,  ..., -0.0454,  1.3044,  0.7011]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3670284-0cc0-418a-b8dc-8ee136c00d3a",
   "metadata": {},
   "source": [
    "## Creating the Predicted AnnData\n",
    "Next, we generate an `AnnData` object from the modelâ€™s predicted gene perturbations. To complete the dataset, we also include the non-targeting control group. Since these controls aren't part of the prediction, we'll copy them directly from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38a7ab4-95fc-4202-aed7-05986736e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted_adata = anndata.AnnData(\n",
    "    X = pred.cpu().detach().numpy(),\n",
    "    obs = pd.DataFrame(\n",
    "        {\n",
    "            \"target_gene\": np.repeat(validation_set.target_gene, validation_set.n_cells).tolist(),\n",
    "        },\n",
    "        index = np.arange(validation_set.n_cells.sum()).astype(str),\n",
    "    ),\n",
    "    var = pd.DataFrame(index = list(adata.var_names)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fd8bdd4-6e5d-4cef-9b21-cda53dc1146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = anndata.concat([adata[adata.obs[\"target_gene\"] == \"non-targeting\"], \n",
    "                                    sample_predicted_adata])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e24e1f02-42c4-4141-92a3-dc275a4f769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'target_gene' as categorical\n"
     ]
    }
   ],
   "source": [
    "sample_submission.write_h5ad(\"/mnt/hdd1/dung/tahoe100/prediction.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3170894-f8da-4165-90f4-c951a946fade",
   "metadata": {},
   "source": [
    "## Running `cell-eval`\n",
    "\n",
    "Weâ€™ll now use `cell-eval` to process the `AnnData` object and prepare it for submission to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde38b8c-ebc5-475f-aeb9-97c9c30625bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:cell_eval._cli._prep:Reading input anndata\n",
      "INFO:cell_eval._cli._prep:Reading gene list\n",
      "INFO:cell_eval._cli._prep:Preparing anndata\n",
      "INFO:cell_eval._cli._prep:Using 32-bit float encoding\n",
      "INFO:cell_eval._cli._prep:Setting data to sparse if not already\n",
      "INFO:cell_eval._cli._prep:Simplifying obs dataframe\n",
      "INFO:cell_eval._cli._prep:Simplifying var dataframe\n",
      "INFO:cell_eval._cli._prep:Creating final minimal AnnData object\n",
      "INFO:cell_eval._cli._prep:Applying normlog transformation if required\n",
      "INFO:cell_eval._evaluator:Input is found to be log-normalized already - skipping transformation.\n",
      "INFO:cell_eval._cli._prep:Writing h5ad output to /tmp/tmp65q0mox8/pred.h5ad\n",
      "INFO:cell_eval._cli._prep:Zstd compressing /tmp/tmp65q0mox8/pred.h5ad\n",
      "/tmp/tmp65q0mox8/pred.h5ad :  4.58%   (  10.7 GiB =>    501 MiB, /tmp/tmp65q0mox8/pred.h5ad.zst) \n",
      "INFO:cell_eval._cli._prep:Packing files into /mnt/hdd1/dung/tahoe100/prediction.prep.vcc\n",
      "INFO:cell_eval._cli._prep:Done\n"
     ]
    }
   ],
   "source": [
    "!cell-eval prep -i /mnt/hdd1/dung/tahoe100/prediction.h5ad -g /mnt/hdd1/dung/tahoe100/gene_names.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deac4cd-11ad-491c-a254-758306590698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
