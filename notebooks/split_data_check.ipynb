{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7339e9ac-6017-4737-9adc-13db4f807119",
   "metadata": {},
   "source": [
    "# Test split data with simple classfier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "- Training data: 100%\n",
    "- Batch size: 2000 for plate 3 and 12\n",
    "- Batch size: 20 for subset plate 3 (2k)\n",
    "\n",
    "**Problems:**\n",
    "- Plate 3: 97,402/4,705,402 was dropped\n",
    "- Plate 12: 119,057/10,487,057 was dropped\n",
    "- Subset plate 3: 720/2000 was dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bkHC",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "CPU times: user 19.1 s, sys: 2.63 s, total: 21.8 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import ray\n",
    "import protoplast\n",
    "import glob\n",
    "from protoplast.scrna.anndata.lightning_models import LinearClassifier\n",
    "from protoplast.scrna.anndata.torch_dataloader import DistributedCellLineAnnDataset as Dcl\n",
    "from protoplast.scrna.anndata.torch_dataloader import cell_line_metadata_cb\n",
    "from protoplast.scrna.anndata.trainer import RayTrainRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "## Simple Classifier with plate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "BYtC",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:28:56,980\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "2025-10-21 05:28:59,247\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example'.\n",
      "2025-10-21 05:28:59,379\tWARNING packaging.py:430 -- File /mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack is very large (34.70MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack']})`\n",
      "2025-10-21 05:28:59,597\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_76006aa0ce295dc1.zip' (69.99MiB) to Ray cluster...\n",
      "2025-10-21 05:29:00,078\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_76006aa0ce295dc1.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 959 ms, sys: 780 ms, total: 1.74 s\n",
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Using CPython \u001b[36m3.11.13\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[2mInstalled \u001b[1m296 packages\u001b[0m \u001b[2min 320ms\u001b[0m\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=1124611)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainTrainable pid=1124611)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=1124611)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=1124611)\u001b[0m - (node_id=e62789ba906f5b07c75fd07ca57023862e96d8694963a47c63c1883d, ip=192.168.1.226, pid=1125420) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m =========Starting the training on 0 with num threads: 4=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "Epoch 0:   0%|          | 0/2304 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/runtime_resources/working_dir_files/_ray_pkg_76006aa0ce295dc1/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 3/2304 [00:12<2:37:28,  0.24it/s, v_num=0, train_loss=3.270]\n",
      "Epoch 0:   0%|          | 9/2304 [00:12<52:51,  0.72it/s, v_num=0, train_loss=1.820]  \n",
      "Epoch 0:   0%|          | 10/2304 [00:12<47:36,  0.80it/s, v_num=0, train_loss=2.050]\n",
      "Epoch 0:   1%|          | 15/2304 [00:12<31:53,  1.20it/s, v_num=0, train_loss=0.815]\n",
      "Epoch 0:   1%|          | 16/2304 [00:12<29:57,  1.27it/s, v_num=0, train_loss=0.757]\n",
      "Epoch 0:   1%|          | 21/2304 [00:12<22:58,  1.66it/s, v_num=0, train_loss=0.722]\n",
      "Epoch 0:   1%|          | 27/2304 [00:12<17:59,  2.11it/s, v_num=0, train_loss=0.958]\n",
      "Epoch 0:   1%|â–         | 32/2304 [00:12<15:16,  2.48it/s, v_num=0, train_loss=0.534]\n",
      "Epoch 0:   1%|â–         | 33/2304 [00:12<14:49,  2.55it/s, v_num=0, train_loss=0.275]\n",
      "Epoch 0:   2%|â–         | 38/2304 [00:13<12:56,  2.92it/s, v_num=0, train_loss=0.627]\n",
      "Epoch 0:   2%|â–         | 43/2304 [00:13<11:30,  3.27it/s, v_num=0, train_loss=0.437]\n",
      "Epoch 0:   2%|â–         | 44/2304 [00:13<11:15,  3.34it/s, v_num=0, train_loss=0.329]\n",
      "Epoch 0:   2%|â–         | 49/2304 [00:13<10:10,  3.69it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:   2%|â–         | 50/2304 [00:13<09:58,  3.77it/s, v_num=0, train_loss=0.478]\n",
      "Epoch 0:   2%|â–         | 56/2304 [00:13<08:57,  4.18it/s, v_num=0, train_loss=0.638]\n",
      "Epoch 0:   2%|â–         | 57/2304 [00:13<08:48,  4.25it/s, v_num=0, train_loss=0.418]\n",
      "Epoch 0:   3%|â–Ž         | 63/2304 [00:13<08:00,  4.66it/s, v_num=0, train_loss=0.593]\n",
      "Epoch 0:   3%|â–Ž         | 64/2304 [00:13<07:53,  4.73it/s, v_num=0, train_loss=0.585]\n",
      "Epoch 0:   3%|â–Ž         | 66/2304 [00:15<09:02,  4.13it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:   3%|â–Ž         | 72/2304 [00:16<08:20,  4.46it/s, v_num=0, train_loss=0.413]\n",
      "Epoch 0:   3%|â–Ž         | 78/2304 [00:16<07:43,  4.80it/s, v_num=0, train_loss=0.538]\n",
      "Epoch 0:   4%|â–Ž         | 84/2304 [00:16<07:12,  5.13it/s, v_num=0, train_loss=0.323]\n",
      "Epoch 0:   4%|â–         | 90/2304 [00:16<06:45,  5.46it/s, v_num=0, train_loss=0.447]\n",
      "Epoch 0:   4%|â–         | 96/2304 [00:16<06:21,  5.78it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:   4%|â–         | 100/2304 [00:16<06:08,  5.99it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:   4%|â–         | 101/2304 [00:16<06:04,  6.04it/s, v_num=0, train_loss=0.306]\n",
      "Epoch 0:   5%|â–         | 106/2304 [00:16<05:49,  6.29it/s, v_num=0, train_loss=0.395]\n",
      "Epoch 0:   5%|â–         | 112/2304 [00:16<05:31,  6.60it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:   5%|â–Œ         | 118/2304 [00:17<05:16,  6.91it/s, v_num=0, train_loss=0.355]\n",
      "Epoch 0:   5%|â–Œ         | 124/2304 [00:17<05:02,  7.22it/s, v_num=0, train_loss=0.645]\n",
      "Epoch 0:   6%|â–Œ         | 128/2304 [00:17<04:53,  7.41it/s, v_num=0, train_loss=0.504]\n",
      "Epoch 0:   6%|â–Œ         | 130/2304 [00:18<05:16,  6.87it/s, v_num=0, train_loss=0.249]\n",
      "Epoch 0:   6%|â–Œ         | 131/2304 [00:19<05:15,  6.89it/s, v_num=0, train_loss=0.284]\n",
      "Epoch 0:   6%|â–Œ         | 136/2304 [00:19<05:05,  7.10it/s, v_num=0, train_loss=0.306]\n",
      "Epoch 0:   6%|â–Œ         | 137/2304 [00:19<05:03,  7.14it/s, v_num=0, train_loss=0.496]\n",
      "Epoch 0:   6%|â–Œ         | 142/2304 [00:19<04:53,  7.37it/s, v_num=0, train_loss=0.348]\n",
      "Epoch 0:   6%|â–Œ         | 143/2304 [00:19<04:51,  7.41it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:   6%|â–‹         | 149/2304 [00:19<04:40,  7.68it/s, v_num=0, train_loss=0.289]\n",
      "Epoch 0:   7%|â–‹         | 150/2304 [00:19<04:38,  7.72it/s, v_num=0, train_loss=0.566]\n",
      "Epoch 0:   7%|â–‹         | 155/2304 [00:19<04:30,  7.94it/s, v_num=0, train_loss=0.284]\n",
      "Epoch 0:   7%|â–‹         | 156/2304 [00:19<04:29,  7.98it/s, v_num=0, train_loss=0.295]\n",
      "Epoch 0:   7%|â–‹         | 162/2304 [00:19<04:19,  8.24it/s, v_num=0, train_loss=0.494]\n",
      "Epoch 0:   7%|â–‹         | 168/2304 [00:19<04:11,  8.49it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:   8%|â–Š         | 174/2304 [00:19<04:03,  8.75it/s, v_num=0, train_loss=0.328]\n",
      "Epoch 0:   8%|â–Š         | 180/2304 [00:20<03:56,  9.00it/s, v_num=0, train_loss=0.242]\n",
      "Epoch 0:   8%|â–Š         | 186/2304 [00:20<03:49,  9.25it/s, v_num=0, train_loss=0.466]\n",
      "Epoch 0:   8%|â–Š         | 187/2304 [00:20<03:47,  9.29it/s, v_num=0, train_loss=0.490]\n",
      "Epoch 0:   8%|â–Š         | 192/2304 [00:20<03:42,  9.49it/s, v_num=0, train_loss=0.387]\n",
      "Epoch 0:   8%|â–Š         | 195/2304 [00:22<03:59,  8.79it/s, v_num=0, train_loss=0.324]\n",
      "Epoch 0:   9%|â–Š         | 196/2304 [00:22<04:01,  8.74it/s, v_num=0, train_loss=0.351]\n",
      "Epoch 0:   9%|â–Š         | 197/2304 [00:22<03:59,  8.78it/s, v_num=0, train_loss=0.517]\n",
      "Epoch 0:   9%|â–‰         | 203/2304 [00:22<03:53,  9.00it/s, v_num=0, train_loss=0.275]\n",
      "Epoch 0:   9%|â–‰         | 209/2304 [00:22<03:47,  9.22it/s, v_num=0, train_loss=0.351]\n",
      "Epoch 0:   9%|â–‰         | 215/2304 [00:22<03:41,  9.44it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  10%|â–‰         | 221/2304 [00:22<03:35,  9.65it/s, v_num=0, train_loss=0.349]\n",
      "Epoch 0:  10%|â–‰         | 227/2304 [00:23<03:30,  9.86it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  10%|â–ˆ         | 233/2304 [00:23<03:25, 10.07it/s, v_num=0, train_loss=0.264]\n",
      "Epoch 0:  10%|â–ˆ         | 239/2304 [00:23<03:20, 10.28it/s, v_num=0, train_loss=0.539]\n",
      "Epoch 0:  11%|â–ˆ         | 245/2304 [00:23<03:16, 10.49it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  11%|â–ˆ         | 246/2304 [00:23<03:15, 10.52it/s, v_num=0, train_loss=0.425]\n",
      "Epoch 0:  11%|â–ˆ         | 252/2304 [00:23<03:11, 10.73it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  11%|â–ˆ         | 256/2304 [00:23<03:08, 10.87it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  11%|â–ˆ         | 258/2304 [00:25<03:22, 10.09it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  11%|â–ˆâ–        | 263/2304 [00:25<03:20, 10.20it/s, v_num=0, train_loss=0.249]\n",
      "Epoch 0:  11%|â–ˆâ–        | 264/2304 [00:25<03:19, 10.23it/s, v_num=0, train_loss=0.344]\n",
      "Epoch 0:  12%|â–ˆâ–        | 270/2304 [00:25<03:15, 10.41it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  12%|â–ˆâ–        | 276/2304 [00:26<03:11, 10.60it/s, v_num=0, train_loss=0.260]\n",
      "Epoch 0:  12%|â–ˆâ–        | 276/2304 [00:26<03:11, 10.60it/s, v_num=0, train_loss=0.221]\n",
      "Epoch 0:  12%|â–ˆâ–        | 282/2304 [00:26<03:07, 10.78it/s, v_num=0, train_loss=0.383]\n",
      "Epoch 0:  12%|â–ˆâ–        | 287/2304 [00:26<03:04, 10.93it/s, v_num=0, train_loss=0.190]\n",
      "Epoch 0:  12%|â–ˆâ–Ž        | 288/2304 [00:26<03:03, 10.96it/s, v_num=0, train_loss=0.410]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 293/2304 [00:26<03:01, 11.10it/s, v_num=0, train_loss=0.391]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 294/2304 [00:26<03:00, 11.14it/s, v_num=0, train_loss=0.518]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 300/2304 [00:26<02:57, 11.31it/s, v_num=0, train_loss=0.253]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 305/2304 [00:26<02:54, 11.45it/s, v_num=0, train_loss=0.316]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 309/2304 [00:26<02:52, 11.55it/s, v_num=0, train_loss=0.274]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 310/2304 [00:26<02:52, 11.58it/s, v_num=0, train_loss=0.289]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 316/2304 [00:26<02:49, 11.76it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  14%|â–ˆâ–        | 320/2304 [00:26<02:47, 11.87it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:  14%|â–ˆâ–        | 321/2304 [00:28<02:58, 11.12it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  14%|â–ˆâ–        | 322/2304 [00:28<02:58, 11.12it/s, v_num=0, train_loss=0.216]\n",
      "Epoch 0:  14%|â–ˆâ–        | 328/2304 [00:29<02:55, 11.28it/s, v_num=0, train_loss=0.604] \n",
      "Epoch 0:  14%|â–ˆâ–        | 334/2304 [00:29<02:52, 11.44it/s, v_num=0, train_loss=0.083] \n",
      "Epoch 0:  15%|â–ˆâ–        | 340/2304 [00:29<02:49, 11.61it/s, v_num=0, train_loss=0.414]\n",
      "Epoch 0:  15%|â–ˆâ–        | 341/2304 [00:29<02:48, 11.63it/s, v_num=0, train_loss=0.387]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 346/2304 [00:29<02:46, 11.76it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 347/2304 [00:29<02:45, 11.79it/s, v_num=0, train_loss=0.359]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 352/2304 [00:29<02:43, 11.92it/s, v_num=0, train_loss=0.321]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 358/2304 [00:29<02:41, 12.07it/s, v_num=0, train_loss=0.245]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 359/2304 [00:29<02:40, 12.10it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 364/2304 [00:29<02:38, 12.23it/s, v_num=0, train_loss=0.277]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 370/2304 [00:29<02:36, 12.37it/s, v_num=0, train_loss=0.460]\n",
      "Epoch 0:  16%|â–ˆâ–‹        | 376/2304 [00:30<02:33, 12.53it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 382/2304 [00:30<02:31, 12.68it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 384/2304 [00:30<02:30, 12.73it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 385/2304 [00:32<02:40, 11.93it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 390/2304 [00:32<02:40, 11.95it/s, v_num=0, train_loss=0.263] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 395/2304 [00:32<02:38, 12.07it/s, v_num=0, train_loss=0.258] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 401/2304 [00:32<02:35, 12.21it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 406/2304 [00:32<02:34, 12.32it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 411/2304 [00:33<02:32, 12.42it/s, v_num=0, train_loss=0.273]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 416/2304 [00:33<02:30, 12.53it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 421/2304 [00:33<02:28, 12.64it/s, v_num=0, train_loss=0.357]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 422/2304 [00:33<02:28, 12.66it/s, v_num=0, train_loss=0.132]\n",
      "Epoch 0:  19%|â–ˆâ–Š        | 427/2304 [00:33<02:26, 12.77it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 432/2304 [00:33<02:25, 12.88it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 438/2304 [00:33<02:23, 13.01it/s, v_num=0, train_loss=0.322] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 443/2304 [00:33<02:21, 13.12it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 448/2304 [00:33<02:20, 13.22it/s, v_num=0, train_loss=0.225]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 450/2304 [00:36<02:28, 12.49it/s, v_num=0, train_loss=0.243]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 456/2304 [00:36<02:26, 12.61it/s, v_num=0, train_loss=0.249]\n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 462/2304 [00:36<02:24, 12.74it/s, v_num=0, train_loss=0.359] \n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 468/2304 [00:36<02:22, 12.86it/s, v_num=0, train_loss=0.350]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 473/2304 [00:36<02:21, 12.97it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 474/2304 [00:36<02:20, 12.99it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 480/2304 [00:36<02:19, 13.11it/s, v_num=0, train_loss=0.570] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 485/2304 [00:36<02:17, 13.21it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 486/2304 [00:36<02:17, 13.23it/s, v_num=0, train_loss=0.173]\n",
      "Epoch 0:  21%|â–ˆâ–ˆâ–       | 492/2304 [00:36<02:15, 13.35it/s, v_num=0, train_loss=0.301]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 497/2304 [00:36<02:14, 13.45it/s, v_num=0, train_loss=0.397]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 498/2304 [00:36<02:14, 13.47it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 504/2304 [00:37<02:12, 13.59it/s, v_num=0, train_loss=0.376]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 510/2304 [00:37<02:10, 13.71it/s, v_num=0, train_loss=0.425]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 512/2304 [00:37<02:10, 13.75it/s, v_num=0, train_loss=0.418]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 516/2304 [00:39<02:15, 13.18it/s, v_num=0, train_loss=0.216]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 522/2304 [00:39<02:14, 13.30it/s, v_num=0, train_loss=0.314]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 522/2304 [00:39<02:14, 13.30it/s, v_num=0, train_loss=0.325]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 528/2304 [00:39<02:12, 13.41it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 533/2304 [00:39<02:11, 13.50it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 534/2304 [00:39<02:10, 13.52it/s, v_num=0, train_loss=0.323]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 540/2304 [00:39<02:09, 13.63it/s, v_num=0, train_loss=0.699]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 546/2304 [00:39<02:07, 13.75it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 552/2304 [00:39<02:06, 13.86it/s, v_num=0, train_loss=0.592]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 557/2304 [00:39<02:05, 13.95it/s, v_num=0, train_loss=0.355]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 558/2304 [00:39<02:05, 13.97it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 564/2304 [00:40<02:03, 14.08it/s, v_num=0, train_loss=0.342]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 565/2304 [00:40<02:03, 14.10it/s, v_num=0, train_loss=0.411]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 571/2304 [00:40<02:01, 14.21it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 576/2304 [00:40<02:00, 14.30it/s, v_num=0, train_loss=0.473]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 579/2304 [00:42<02:05, 13.71it/s, v_num=0, train_loss=0.593]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 583/2304 [00:42<02:04, 13.77it/s, v_num=0, train_loss=0.460]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 588/2304 [00:42<02:03, 13.85it/s, v_num=0, train_loss=0.217]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 589/2304 [00:42<02:03, 13.87it/s, v_num=0, train_loss=0.172]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 595/2304 [00:42<02:02, 13.97it/s, v_num=0, train_loss=0.491]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 601/2304 [00:42<02:00, 14.08it/s, v_num=0, train_loss=0.271]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 602/2304 [00:42<02:00, 14.09it/s, v_num=0, train_loss=0.315]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 608/2304 [00:42<01:59, 14.20it/s, v_num=0, train_loss=0.426]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 613/2304 [00:42<01:58, 14.28it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 619/2304 [00:43<01:57, 14.38it/s, v_num=0, train_loss=0.357]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 625/2304 [00:43<01:55, 14.48it/s, v_num=0, train_loss=0.507]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 626/2304 [00:43<01:55, 14.50it/s, v_num=0, train_loss=0.312]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 632/2304 [00:43<01:54, 14.60it/s, v_num=0, train_loss=0.319]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 637/2304 [00:43<01:53, 14.68it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 638/2304 [00:43<01:53, 14.69it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 640/2304 [00:43<01:53, 14.72it/s, v_num=0, train_loss=0.306]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 641/2304 [00:45<01:57, 14.18it/s, v_num=0, train_loss=0.410]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 646/2304 [00:45<01:56, 14.24it/s, v_num=0, train_loss=0.282]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 647/2304 [00:45<01:56, 14.25it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 653/2304 [00:45<01:55, 14.35it/s, v_num=0, train_loss=0.294]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 658/2304 [00:45<01:54, 14.42it/s, v_num=0, train_loss=0.331]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 664/2304 [00:45<01:52, 14.52it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 670/2304 [00:45<01:51, 14.61it/s, v_num=0, train_loss=0.258]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 676/2304 [00:45<01:50, 14.70it/s, v_num=0, train_loss=0.597]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 682/2304 [00:46<01:49, 14.80it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 688/2304 [00:46<01:48, 14.89it/s, v_num=0, train_loss=0.474]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 694/2304 [00:46<01:47, 14.98it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 700/2304 [00:46<01:46, 15.07it/s, v_num=0, train_loss=0.274]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 704/2304 [00:46<01:45, 15.14it/s, v_num=0, train_loss=0.350]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 709/2304 [00:48<01:48, 14.65it/s, v_num=0, train_loss=0.537]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 710/2304 [00:48<01:48, 14.67it/s, v_num=0, train_loss=0.380]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 715/2304 [00:48<01:47, 14.74it/s, v_num=0, train_loss=0.655]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 721/2304 [00:48<01:46, 14.82it/s, v_num=0, train_loss=0.295]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 722/2304 [00:48<01:46, 14.84it/s, v_num=0, train_loss=0.325]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 728/2304 [00:48<01:45, 14.93it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 734/2304 [00:48<01:44, 15.02it/s, v_num=0, train_loss=0.390]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 740/2304 [00:48<01:43, 15.10it/s, v_num=0, train_loss=0.506]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 741/2304 [00:49<01:43, 15.12it/s, v_num=0, train_loss=0.301]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 747/2304 [00:49<01:42, 15.21it/s, v_num=0, train_loss=0.419]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 753/2304 [00:49<01:41, 15.29it/s, v_num=0, train_loss=0.289]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 759/2304 [00:49<01:40, 15.38it/s, v_num=0, train_loss=0.285]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 765/2304 [00:49<01:39, 15.47it/s, v_num=0, train_loss=0.587]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 766/2304 [00:49<01:39, 15.48it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 768/2304 [00:49<01:39, 15.51it/s, v_num=0, train_loss=0.287]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 769/2304 [00:51<01:42, 14.98it/s, v_num=0, train_loss=0.393]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 770/2304 [00:51<01:42, 14.99it/s, v_num=0, train_loss=0.555]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 776/2304 [00:51<01:41, 15.08it/s, v_num=0, train_loss=0.273]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 781/2304 [00:51<01:40, 15.14it/s, v_num=0, train_loss=0.323]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 782/2304 [00:51<01:40, 15.16it/s, v_num=0, train_loss=0.297]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 788/2304 [00:51<01:39, 15.24it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 794/2304 [00:51<01:38, 15.32it/s, v_num=0, train_loss=0.404] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 800/2304 [00:51<01:37, 15.40it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 806/2304 [00:52<01:36, 15.48it/s, v_num=0, train_loss=0.342]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 812/2304 [00:52<01:35, 15.56it/s, v_num=0, train_loss=0.494]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 818/2304 [00:52<01:34, 15.64it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 824/2304 [00:52<01:34, 15.73it/s, v_num=0, train_loss=0.539]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 825/2304 [00:52<01:33, 15.74it/s, v_num=0, train_loss=0.505]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 831/2304 [00:52<01:33, 15.82it/s, v_num=0, train_loss=0.360]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 832/2304 [00:52<01:32, 15.83it/s, v_num=0, train_loss=0.351]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 834/2304 [00:54<01:35, 15.34it/s, v_num=0, train_loss=0.322]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 835/2304 [00:54<01:35, 15.35it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 841/2304 [00:54<01:34, 15.43it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 842/2304 [00:54<01:34, 15.44it/s, v_num=0, train_loss=0.417]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 848/2304 [00:54<01:33, 15.52it/s, v_num=0, train_loss=0.390]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 849/2304 [00:54<01:33, 15.54it/s, v_num=0, train_loss=0.381]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 850/2304 [00:54<01:33, 15.55it/s, v_num=0, train_loss=0.451]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 855/2304 [00:54<01:32, 15.61it/s, v_num=0, train_loss=0.210]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 856/2304 [00:54<01:32, 15.63it/s, v_num=0, train_loss=0.214]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 861/2304 [00:54<01:31, 15.69it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 867/2304 [00:54<01:31, 15.77it/s, v_num=0, train_loss=0.563]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 868/2304 [00:55<01:31, 15.78it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 873/2304 [00:55<01:30, 15.84it/s, v_num=0, train_loss=0.172]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 880/2304 [00:55<01:29, 15.93it/s, v_num=0, train_loss=0.618]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 886/2304 [00:55<01:28, 16.01it/s, v_num=0, train_loss=0.340]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 892/2304 [00:55<01:27, 16.08it/s, v_num=0, train_loss=0.591]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 893/2304 [00:55<01:27, 16.10it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 896/2304 [00:55<01:27, 16.13it/s, v_num=0, train_loss=0.369]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 898/2304 [00:57<01:29, 15.70it/s, v_num=0, train_loss=0.687]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 900/2304 [00:57<01:29, 15.70it/s, v_num=0, train_loss=0.267]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 906/2304 [00:57<01:28, 15.77it/s, v_num=0, train_loss=0.562]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 911/2304 [00:57<01:28, 15.83it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 912/2304 [00:57<01:27, 15.84it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 918/2304 [00:57<01:27, 15.91it/s, v_num=0, train_loss=0.459]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 919/2304 [00:57<01:26, 15.93it/s, v_num=0, train_loss=0.539]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 924/2304 [00:57<01:26, 15.98it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 925/2304 [00:57<01:26, 16.00it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 925/2304 [00:57<01:26, 16.00it/s, v_num=0, train_loss=0.322]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 930/2304 [00:57<01:25, 16.06it/s, v_num=0, train_loss=0.403]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 931/2304 [00:57<01:25, 16.07it/s, v_num=0, train_loss=0.539]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 936/2304 [00:58<01:24, 16.13it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 937/2304 [00:58<01:24, 16.14it/s, v_num=0, train_loss=0.230]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 942/2304 [00:58<01:24, 16.19it/s, v_num=0, train_loss=0.350]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 943/2304 [00:58<01:23, 16.21it/s, v_num=0, train_loss=0.357]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 949/2304 [00:58<01:23, 16.28it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 955/2304 [00:58<01:22, 16.35it/s, v_num=0, train_loss=0.282]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 956/2304 [00:58<01:22, 16.36it/s, v_num=0, train_loss=0.551]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 960/2304 [00:58<01:21, 16.41it/s, v_num=0, train_loss=0.466]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 966/2304 [01:00<01:23, 16.00it/s, v_num=0, train_loss=0.251]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 971/2304 [01:00<01:23, 16.05it/s, v_num=0, train_loss=0.263]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 972/2304 [01:00<01:22, 16.06it/s, v_num=0, train_loss=0.304]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 978/2304 [01:00<01:22, 16.13it/s, v_num=0, train_loss=0.479]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 983/2304 [01:00<01:21, 16.19it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 984/2304 [01:00<01:21, 16.20it/s, v_num=0, train_loss=0.263]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 989/2304 [01:00<01:20, 16.26it/s, v_num=0, train_loss=0.302]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 995/2304 [01:00<01:20, 16.32it/s, v_num=0, train_loss=0.652]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1001/2304 [01:01<01:19, 16.39it/s, v_num=0, train_loss=0.0794]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1007/2304 [01:01<01:18, 16.46it/s, v_num=0, train_loss=0.540] \n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1013/2304 [01:01<01:18, 16.52it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1019/2304 [01:01<01:17, 16.59it/s, v_num=0, train_loss=0.369]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1020/2304 [01:01<01:17, 16.60it/s, v_num=0, train_loss=0.560]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1024/2304 [01:01<01:16, 16.65it/s, v_num=0, train_loss=0.390]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1025/2304 [01:03<01:18, 16.20it/s, v_num=0, train_loss=0.443]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1026/2304 [01:03<01:18, 16.21it/s, v_num=0, train_loss=0.259]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1028/2304 [01:03<01:18, 16.22it/s, v_num=0, train_loss=0.281]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1029/2304 [01:03<01:18, 16.23it/s, v_num=0, train_loss=0.419]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1035/2304 [01:03<01:17, 16.29it/s, v_num=0, train_loss=0.226]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1041/2304 [01:03<01:17, 16.36it/s, v_num=0, train_loss=0.392]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1042/2304 [01:03<01:17, 16.37it/s, v_num=0, train_loss=0.516]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1048/2304 [01:03<01:16, 16.44it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1048/2304 [01:03<01:16, 16.44it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1054/2304 [01:03<01:15, 16.50it/s, v_num=0, train_loss=0.589]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1060/2304 [01:03<01:15, 16.56it/s, v_num=0, train_loss=0.190]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1066/2304 [01:04<01:14, 16.63it/s, v_num=0, train_loss=0.390]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1067/2304 [01:04<01:14, 16.64it/s, v_num=0, train_loss=0.603]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1072/2304 [01:04<01:13, 16.69it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1073/2304 [01:04<01:13, 16.70it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1079/2304 [01:04<01:13, 16.77it/s, v_num=0, train_loss=0.507]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1080/2304 [01:04<01:12, 16.78it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1086/2304 [01:04<01:12, 16.84it/s, v_num=0, train_loss=0.404]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1088/2304 [01:04<01:12, 16.86it/s, v_num=0, train_loss=0.511]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1091/2304 [01:06<01:13, 16.45it/s, v_num=0, train_loss=0.384]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1094/2304 [01:06<01:13, 16.44it/s, v_num=0, train_loss=0.307]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1095/2304 [01:06<01:13, 16.45it/s, v_num=0, train_loss=0.307]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1095/2304 [01:06<01:13, 16.45it/s, v_num=0, train_loss=0.278]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1101/2304 [01:06<01:12, 16.52it/s, v_num=0, train_loss=0.422]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1107/2304 [01:06<01:12, 16.58it/s, v_num=0, train_loss=0.172]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1112/2304 [01:06<01:11, 16.63it/s, v_num=0, train_loss=0.379]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1118/2304 [01:07<01:11, 16.68it/s, v_num=0, train_loss=0.461]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1123/2304 [01:07<01:10, 16.73it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1124/2304 [01:07<01:10, 16.74it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1130/2304 [01:07<01:09, 16.80it/s, v_num=0, train_loss=0.333]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1135/2304 [01:07<01:09, 16.85it/s, v_num=0, train_loss=0.604] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1136/2304 [01:07<01:09, 16.86it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1142/2304 [01:07<01:08, 16.92it/s, v_num=0, train_loss=0.305]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1148/2304 [01:07<01:08, 16.98it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1152/2304 [01:07<01:07, 17.02it/s, v_num=0, train_loss=0.0987]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1155/2304 [01:09<01:09, 16.58it/s, v_num=0, train_loss=0.400] \n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1156/2304 [01:09<01:09, 16.59it/s, v_num=0, train_loss=0.481]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1161/2304 [01:09<01:08, 16.64it/s, v_num=0, train_loss=0.519]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1167/2304 [01:09<01:08, 16.70it/s, v_num=0, train_loss=0.357]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1168/2304 [01:09<01:07, 16.71it/s, v_num=0, train_loss=0.294]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1174/2304 [01:10<01:07, 16.77it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1179/2304 [01:10<01:06, 16.81it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1185/2304 [01:10<01:06, 16.87it/s, v_num=0, train_loss=0.314]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1191/2304 [01:10<01:05, 16.93it/s, v_num=0, train_loss=0.237]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1197/2304 [01:10<01:05, 16.98it/s, v_num=0, train_loss=0.293]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1203/2304 [01:10<01:04, 17.04it/s, v_num=0, train_loss=0.265]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1209/2304 [01:10<01:04, 17.10it/s, v_num=0, train_loss=0.266]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1215/2304 [01:10<01:03, 17.15it/s, v_num=0, train_loss=0.561]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1216/2304 [01:10<01:03, 17.16it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1219/2304 [01:12<01:04, 16.77it/s, v_num=0, train_loss=0.427]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1220/2304 [01:12<01:04, 16.78it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1225/2304 [01:12<01:04, 16.83it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1231/2304 [01:12<01:03, 16.88it/s, v_num=0, train_loss=0.300]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1232/2304 [01:12<01:03, 16.89it/s, v_num=0, train_loss=0.402]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1238/2304 [01:13<01:02, 16.95it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1244/2304 [01:13<01:02, 17.00it/s, v_num=0, train_loss=0.514]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1250/2304 [01:13<01:01, 17.06it/s, v_num=0, train_loss=0.245]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1256/2304 [01:13<01:01, 17.11it/s, v_num=0, train_loss=0.324]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1261/2304 [01:13<01:00, 17.16it/s, v_num=0, train_loss=0.311]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1262/2304 [01:13<01:00, 17.17it/s, v_num=0, train_loss=0.370]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1268/2304 [01:13<01:00, 17.22it/s, v_num=0, train_loss=0.466]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1274/2304 [01:13<00:59, 17.28it/s, v_num=0, train_loss=0.614]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1275/2304 [01:13<00:59, 17.29it/s, v_num=0, train_loss=0.315]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1280/2304 [01:13<00:59, 17.33it/s, v_num=0, train_loss=0.269]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1285/2304 [01:15<01:00, 16.94it/s, v_num=0, train_loss=0.141]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1290/2304 [01:15<00:59, 16.99it/s, v_num=0, train_loss=0.443]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1291/2304 [01:15<00:59, 17.00it/s, v_num=0, train_loss=0.650]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1296/2304 [01:16<00:59, 17.04it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1297/2304 [01:16<00:59, 17.05it/s, v_num=0, train_loss=0.266]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1303/2304 [01:16<00:58, 17.10it/s, v_num=0, train_loss=0.393]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1309/2304 [01:16<00:58, 17.15it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1315/2304 [01:16<00:57, 17.21it/s, v_num=0, train_loss=0.366]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1316/2304 [01:16<00:57, 17.22it/s, v_num=0, train_loss=0.443]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1322/2304 [01:16<00:56, 17.27it/s, v_num=0, train_loss=0.271]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1328/2304 [01:16<00:56, 17.32it/s, v_num=0, train_loss=0.444]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1334/2304 [01:16<00:55, 17.37it/s, v_num=0, train_loss=0.202]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1340/2304 [01:16<00:55, 17.43it/s, v_num=0, train_loss=0.307]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1341/2304 [01:16<00:55, 17.44it/s, v_num=0, train_loss=0.292]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1344/2304 [01:16<00:54, 17.46it/s, v_num=0, train_loss=0.280]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1346/2304 [01:18<00:55, 17.12it/s, v_num=0, train_loss=0.547]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1347/2304 [01:18<00:55, 17.12it/s, v_num=0, train_loss=0.547]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1347/2304 [01:18<00:55, 17.12it/s, v_num=0, train_loss=0.263]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1353/2304 [01:18<00:55, 17.18it/s, v_num=0, train_loss=0.306]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1359/2304 [01:18<00:54, 17.23it/s, v_num=0, train_loss=0.258]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1360/2304 [01:18<00:54, 17.24it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1365/2304 [01:19<00:54, 17.28it/s, v_num=0, train_loss=0.240]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1366/2304 [01:19<00:54, 17.28it/s, v_num=0, train_loss=0.308]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1371/2304 [01:19<00:53, 17.33it/s, v_num=0, train_loss=0.533]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1372/2304 [01:19<00:53, 17.34it/s, v_num=0, train_loss=0.247]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1378/2304 [01:19<00:53, 17.39it/s, v_num=0, train_loss=0.499]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1383/2304 [01:19<00:52, 17.43it/s, v_num=0, train_loss=0.327]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1384/2304 [01:19<00:52, 17.43it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1390/2304 [01:19<00:52, 17.48it/s, v_num=0, train_loss=0.374]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1396/2304 [01:19<00:51, 17.53it/s, v_num=0, train_loss=0.479]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1402/2304 [01:19<00:51, 17.59it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1403/2304 [01:19<00:51, 17.59it/s, v_num=0, train_loss=0.482]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1408/2304 [01:19<00:50, 17.64it/s, v_num=0, train_loss=0.455]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1410/2304 [01:21<00:51, 17.24it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1414/2304 [01:21<00:51, 17.25it/s, v_num=0, train_loss=0.259]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1415/2304 [01:21<00:51, 17.26it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1421/2304 [01:22<00:51, 17.31it/s, v_num=0, train_loss=0.322]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1427/2304 [01:22<00:50, 17.36it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1433/2304 [01:22<00:50, 17.40it/s, v_num=0, train_loss=0.248]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1438/2304 [01:22<00:49, 17.44it/s, v_num=0, train_loss=0.250] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1444/2304 [01:22<00:49, 17.49it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1450/2304 [01:22<00:48, 17.54it/s, v_num=0, train_loss=0.296]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1455/2304 [01:22<00:48, 17.57it/s, v_num=0, train_loss=0.490]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1456/2304 [01:22<00:48, 17.58it/s, v_num=0, train_loss=0.234]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1462/2304 [01:22<00:47, 17.63it/s, v_num=0, train_loss=0.274]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1468/2304 [01:23<00:47, 17.68it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1472/2304 [01:23<00:46, 17.71it/s, v_num=0, train_loss=0.535]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1473/2304 [01:25<00:48, 17.26it/s, v_num=0, train_loss=0.391]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1474/2304 [01:25<00:48, 17.26it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1479/2304 [01:25<00:47, 17.28it/s, v_num=0, train_loss=0.254]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1485/2304 [01:25<00:47, 17.33it/s, v_num=0, train_loss=0.410]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1490/2304 [01:25<00:46, 17.36it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1491/2304 [01:25<00:46, 17.37it/s, v_num=0, train_loss=0.240]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1496/2304 [01:25<00:46, 17.41it/s, v_num=0, train_loss=0.238]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1502/2304 [01:26<00:45, 17.45it/s, v_num=0, train_loss=0.436]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1507/2304 [01:26<00:45, 17.49it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1508/2304 [01:26<00:45, 17.49it/s, v_num=0, train_loss=0.440]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1513/2304 [01:26<00:45, 17.53it/s, v_num=0, train_loss=0.226]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1514/2304 [01:26<00:45, 17.54it/s, v_num=0, train_loss=0.419]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1519/2304 [01:26<00:44, 17.57it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1525/2304 [01:26<00:44, 17.62it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1530/2304 [01:26<00:43, 17.66it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1536/2304 [01:26<00:43, 17.70it/s, v_num=0, train_loss=0.239]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1537/2304 [01:28<00:44, 17.32it/s, v_num=0, train_loss=0.227]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1540/2304 [01:28<00:44, 17.33it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1541/2304 [01:28<00:44, 17.34it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1546/2304 [01:28<00:43, 17.37it/s, v_num=0, train_loss=0.201]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1551/2304 [01:29<00:43, 17.41it/s, v_num=0, train_loss=0.304]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1552/2304 [01:29<00:43, 17.42it/s, v_num=0, train_loss=0.407]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1557/2304 [01:29<00:42, 17.45it/s, v_num=0, train_loss=0.509]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1558/2304 [01:29<00:42, 17.46it/s, v_num=0, train_loss=0.133]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1564/2304 [01:29<00:42, 17.50it/s, v_num=0, train_loss=0.457]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1569/2304 [01:29<00:41, 17.54it/s, v_num=0, train_loss=0.413]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1570/2304 [01:29<00:41, 17.55it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1575/2304 [01:29<00:41, 17.58it/s, v_num=0, train_loss=0.293]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1576/2304 [01:29<00:41, 17.59it/s, v_num=0, train_loss=0.302]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1581/2304 [01:29<00:41, 17.63it/s, v_num=0, train_loss=0.281]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1582/2304 [01:29<00:40, 17.63it/s, v_num=0, train_loss=0.492]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1587/2304 [01:29<00:40, 17.67it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1588/2304 [01:29<00:40, 17.68it/s, v_num=0, train_loss=0.396]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1594/2304 [01:29<00:40, 17.72it/s, v_num=0, train_loss=0.447]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1600/2304 [01:30<00:39, 17.76it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1601/2304 [01:31<00:40, 17.41it/s, v_num=0, train_loss=0.294]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1603/2304 [01:32<00:40, 17.38it/s, v_num=0, train_loss=0.447]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1607/2304 [01:32<00:40, 17.41it/s, v_num=0, train_loss=0.439]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1611/2304 [01:32<00:39, 17.43it/s, v_num=0, train_loss=0.519]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1617/2304 [01:32<00:39, 17.47it/s, v_num=0, train_loss=0.294]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1622/2304 [01:32<00:38, 17.51it/s, v_num=0, train_loss=0.222]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1627/2304 [01:32<00:38, 17.54it/s, v_num=0, train_loss=0.272]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1633/2304 [01:32<00:38, 17.58it/s, v_num=0, train_loss=0.253]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1638/2304 [01:32<00:37, 17.62it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1643/2304 [01:33<00:37, 17.65it/s, v_num=0, train_loss=0.305]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1648/2304 [01:33<00:37, 17.68it/s, v_num=0, train_loss=0.306]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1653/2304 [01:33<00:36, 17.71it/s, v_num=0, train_loss=0.487]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1657/2304 [01:33<00:36, 17.73it/s, v_num=0, train_loss=0.281]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1663/2304 [01:33<00:36, 17.78it/s, v_num=0, train_loss=0.314]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1663/2304 [01:33<00:36, 17.78it/s, v_num=0, train_loss=0.0727]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1664/2304 [01:33<00:35, 17.78it/s, v_num=0, train_loss=0.341] \n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1667/2304 [01:35<00:36, 17.44it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1668/2304 [01:35<00:36, 17.45it/s, v_num=0, train_loss=0.301]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1674/2304 [01:35<00:36, 17.49it/s, v_num=0, train_loss=0.324]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1679/2304 [01:35<00:35, 17.52it/s, v_num=0, train_loss=0.348]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1680/2304 [01:35<00:35, 17.53it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1686/2304 [01:35<00:35, 17.57it/s, v_num=0, train_loss=0.313]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1692/2304 [01:36<00:34, 17.61it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1697/2304 [01:36<00:34, 17.64it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1703/2304 [01:36<00:33, 17.69it/s, v_num=0, train_loss=0.315]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1709/2304 [01:36<00:33, 17.73it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1715/2304 [01:36<00:33, 17.77it/s, v_num=0, train_loss=0.382]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1716/2304 [01:36<00:33, 17.77it/s, v_num=0, train_loss=0.428]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1722/2304 [01:36<00:32, 17.82it/s, v_num=0, train_loss=0.236]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1728/2304 [01:36<00:32, 17.86it/s, v_num=0, train_loss=0.411]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1730/2304 [01:38<00:32, 17.54it/s, v_num=0, train_loss=0.606]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1736/2304 [01:38<00:32, 17.58it/s, v_num=0, train_loss=0.312]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1742/2304 [01:38<00:31, 17.63it/s, v_num=0, train_loss=0.354]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1743/2304 [01:38<00:31, 17.63it/s, v_num=0, train_loss=0.359]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1748/2304 [01:38<00:31, 17.66it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1749/2304 [01:38<00:31, 17.67it/s, v_num=0, train_loss=0.324]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1755/2304 [01:39<00:30, 17.71it/s, v_num=0, train_loss=0.650]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1761/2304 [01:39<00:30, 17.75it/s, v_num=0, train_loss=0.248]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1767/2304 [01:39<00:30, 17.79it/s, v_num=0, train_loss=0.357]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1773/2304 [01:39<00:29, 17.83it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1774/2304 [01:39<00:29, 17.84it/s, v_num=0, train_loss=0.395]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1780/2304 [01:39<00:29, 17.88it/s, v_num=0, train_loss=0.549]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1786/2304 [01:39<00:28, 17.92it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1787/2304 [01:39<00:28, 17.93it/s, v_num=0, train_loss=0.418]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1792/2304 [01:39<00:28, 17.96it/s, v_num=0, train_loss=0.373]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1794/2304 [01:41<00:28, 17.63it/s, v_num=0, train_loss=0.486]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1800/2304 [01:41<00:28, 17.67it/s, v_num=0, train_loss=0.375]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1806/2304 [01:41<00:28, 17.71it/s, v_num=0, train_loss=0.448]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1812/2304 [01:42<00:27, 17.75it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1818/2304 [01:42<00:27, 17.79it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1824/2304 [01:42<00:26, 17.82it/s, v_num=0, train_loss=0.273]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1830/2304 [01:42<00:26, 17.86it/s, v_num=0, train_loss=0.369]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1835/2304 [01:42<00:26, 17.89it/s, v_num=0, train_loss=0.244]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1836/2304 [01:42<00:26, 17.90it/s, v_num=0, train_loss=0.281]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1842/2304 [01:42<00:25, 17.94it/s, v_num=0, train_loss=0.261]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1848/2304 [01:42<00:25, 17.98it/s, v_num=0, train_loss=0.581]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1849/2304 [01:42<00:25, 17.98it/s, v_num=0, train_loss=0.284]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1855/2304 [01:42<00:24, 18.02it/s, v_num=0, train_loss=0.493]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1856/2304 [01:42<00:24, 18.03it/s, v_num=0, train_loss=0.518]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1859/2304 [01:44<00:25, 17.74it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1864/2304 [01:45<00:24, 17.75it/s, v_num=0, train_loss=0.274]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1870/2304 [01:45<00:24, 17.79it/s, v_num=0, train_loss=0.474]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1876/2304 [01:45<00:24, 17.83it/s, v_num=0, train_loss=0.307]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1877/2304 [01:45<00:23, 17.84it/s, v_num=0, train_loss=0.442]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1882/2304 [01:45<00:23, 17.87it/s, v_num=0, train_loss=0.339]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1883/2304 [01:45<00:23, 17.87it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1888/2304 [01:45<00:23, 17.90it/s, v_num=0, train_loss=0.0992]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1894/2304 [01:45<00:22, 17.94it/s, v_num=0, train_loss=0.246] \n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1899/2304 [01:45<00:22, 17.97it/s, v_num=0, train_loss=0.428]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1904/2304 [01:45<00:22, 18.00it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1910/2304 [01:45<00:21, 18.03it/s, v_num=0, train_loss=0.311] \n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1915/2304 [01:46<00:21, 18.06it/s, v_num=0, train_loss=0.313]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1920/2304 [01:46<00:21, 18.09it/s, v_num=0, train_loss=0.550]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1923/2304 [01:48<00:21, 17.74it/s, v_num=0, train_loss=0.424]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1927/2304 [01:48<00:21, 17.76it/s, v_num=0, train_loss=0.325]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1933/2304 [01:48<00:20, 17.79it/s, v_num=0, train_loss=0.370]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1939/2304 [01:48<00:20, 17.83it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1945/2304 [01:48<00:20, 17.87it/s, v_num=0, train_loss=0.219]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1951/2304 [01:48<00:19, 17.90it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1956/2304 [01:49<00:19, 17.93it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1957/2304 [01:49<00:19, 17.94it/s, v_num=0, train_loss=0.391]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1963/2304 [01:49<00:18, 17.97it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1968/2304 [01:49<00:18, 18.00it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1974/2304 [01:49<00:18, 18.04it/s, v_num=0, train_loss=0.255]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1975/2304 [01:49<00:18, 18.04it/s, v_num=0, train_loss=0.383]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1980/2304 [01:49<00:17, 18.07it/s, v_num=0, train_loss=0.205] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1981/2304 [01:49<00:17, 18.08it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1984/2304 [01:49<00:17, 18.10it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1986/2304 [01:51<00:17, 17.79it/s, v_num=0, train_loss=0.298]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1987/2304 [01:51<00:17, 17.78it/s, v_num=0, train_loss=0.249]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1988/2304 [01:51<00:17, 17.78it/s, v_num=0, train_loss=0.426]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1994/2304 [01:51<00:17, 17.82it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2000/2304 [01:52<00:17, 17.85it/s, v_num=0, train_loss=0.430]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2006/2304 [01:52<00:16, 17.89it/s, v_num=0, train_loss=0.265]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2012/2304 [01:52<00:16, 17.92it/s, v_num=0, train_loss=0.256]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2018/2304 [01:52<00:15, 17.96it/s, v_num=0, train_loss=0.198]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2024/2304 [01:52<00:15, 17.99it/s, v_num=0, train_loss=0.370]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2029/2304 [01:52<00:15, 18.02it/s, v_num=0, train_loss=0.370]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2030/2304 [01:52<00:15, 18.03it/s, v_num=0, train_loss=0.546]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2036/2304 [01:52<00:14, 18.06it/s, v_num=0, train_loss=0.233]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2042/2304 [01:52<00:14, 18.10it/s, v_num=0, train_loss=0.326]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2048/2304 [01:52<00:14, 18.13it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2053/2304 [01:54<00:14, 17.85it/s, v_num=0, train_loss=0.234]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2054/2304 [01:55<00:13, 17.86it/s, v_num=0, train_loss=0.310]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2060/2304 [01:55<00:13, 17.89it/s, v_num=0, train_loss=0.442]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2066/2304 [01:55<00:13, 17.93it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2067/2304 [01:55<00:13, 17.93it/s, v_num=0, train_loss=0.329]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2073/2304 [01:55<00:12, 17.97it/s, v_num=0, train_loss=0.418]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2079/2304 [01:55<00:12, 18.00it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2085/2304 [01:55<00:12, 18.04it/s, v_num=0, train_loss=0.365]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2091/2304 [01:55<00:11, 18.07it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2096/2304 [01:55<00:11, 18.10it/s, v_num=0, train_loss=0.355]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2097/2304 [01:55<00:11, 18.10it/s, v_num=0, train_loss=0.268]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2103/2304 [01:55<00:11, 18.14it/s, v_num=0, train_loss=0.179]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2110/2304 [01:56<00:10, 18.18it/s, v_num=0, train_loss=0.515]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2110/2304 [01:56<00:10, 18.18it/s, v_num=0, train_loss=0.460]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2112/2304 [01:56<00:10, 18.19it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2113/2304 [01:58<00:10, 17.90it/s, v_num=0, train_loss=0.230]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2117/2304 [01:59<00:10, 17.79it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2121/2304 [01:59<00:10, 17.81it/s, v_num=0, train_loss=0.325]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2122/2304 [01:59<00:10, 17.81it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2127/2304 [01:59<00:09, 17.84it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2131/2304 [01:59<00:09, 17.86it/s, v_num=0, train_loss=0.152] \n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2136/2304 [01:59<00:09, 17.88it/s, v_num=0, train_loss=0.0806]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2137/2304 [01:59<00:09, 17.89it/s, v_num=0, train_loss=0.647] \n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2141/2304 [01:59<00:09, 17.91it/s, v_num=0, train_loss=0.634] \n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2142/2304 [01:59<00:09, 17.91it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2146/2304 [01:59<00:08, 17.93it/s, v_num=0, train_loss=0.078]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2150/2304 [01:59<00:08, 17.95it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2151/2304 [01:59<00:08, 17.95it/s, v_num=0, train_loss=0.265]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2155/2304 [01:59<00:08, 17.97it/s, v_num=0, train_loss=0.188] \n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2160/2304 [02:00<00:08, 17.99it/s, v_num=0, train_loss=0.242] \n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2165/2304 [02:00<00:07, 18.02it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2170/2304 [02:00<00:07, 18.04it/s, v_num=0, train_loss=0.276]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2175/2304 [02:00<00:07, 18.06it/s, v_num=0, train_loss=0.0696]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2176/2304 [02:00<00:07, 18.07it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2178/2304 [02:03<00:07, 17.58it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2183/2304 [02:03<00:06, 17.61it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2187/2304 [02:04<00:06, 17.62it/s, v_num=0, train_loss=0.0579]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2188/2304 [02:04<00:06, 17.63it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2192/2304 [02:04<00:06, 17.65it/s, v_num=0, train_loss=0.108]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2193/2304 [02:04<00:06, 17.65it/s, v_num=0, train_loss=0.0975]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2197/2304 [02:04<00:06, 17.67it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2198/2304 [02:04<00:05, 17.67it/s, v_num=0, train_loss=0.178]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2202/2304 [02:04<00:05, 17.69it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2206/2304 [02:04<00:05, 17.71it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2207/2304 [02:04<00:05, 17.71it/s, v_num=0, train_loss=0.0794]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2211/2304 [02:04<00:05, 17.73it/s, v_num=0, train_loss=0.0398]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2215/2304 [02:04<00:05, 17.75it/s, v_num=0, train_loss=0.0722]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2220/2304 [02:04<00:04, 17.77it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2224/2304 [02:05<00:04, 17.78it/s, v_num=0, train_loss=0.0977]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2228/2304 [02:05<00:04, 17.80it/s, v_num=0, train_loss=0.0403]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2229/2304 [02:05<00:04, 17.81it/s, v_num=0, train_loss=0.0382]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2233/2304 [02:05<00:03, 17.82it/s, v_num=0, train_loss=0.0431]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2237/2304 [02:05<00:03, 17.84it/s, v_num=0, train_loss=0.0596]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2240/2304 [02:05<00:03, 17.85it/s, v_num=0, train_loss=0.0852]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2244/2304 [02:09<00:03, 17.32it/s, v_num=0, train_loss=0.0699]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2249/2304 [02:09<00:03, 17.35it/s, v_num=0, train_loss=0.0418]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2253/2304 [02:09<00:02, 17.36it/s, v_num=0, train_loss=0.0453]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2257/2304 [02:09<00:02, 17.38it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2262/2304 [02:10<00:02, 17.40it/s, v_num=0, train_loss=0.0645]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2266/2304 [02:10<00:02, 17.42it/s, v_num=0, train_loss=0.0623]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2267/2304 [02:10<00:02, 17.42it/s, v_num=0, train_loss=0.0886]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2271/2304 [02:10<00:01, 17.44it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2272/2304 [02:10<00:01, 17.44it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2276/2304 [02:10<00:01, 17.46it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2281/2304 [02:10<00:01, 17.48it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2285/2304 [02:10<00:01, 17.50it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2290/2304 [02:10<00:00, 17.52it/s, v_num=0, train_loss=0.0808]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2295/2304 [02:10<00:00, 17.54it/s, v_num=0, train_loss=0.0942]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2300/2304 [02:10<00:00, 17.57it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2301/2304 [02:10<00:00, 17.57it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2304/2304 [02:11<00:00, 17.58it/s, v_num=0, train_loss=0.144] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-10-21_05-29-17/TorchTrainer_e354d_00000_0_2025-10-21_05-29-17/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=1125420)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2304/2304 [02:11<00:00, 17.56it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2304/2304 [02:11<00:00, 17.55it/s, v_num=0, train_loss=0.144]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,  # replace with your own model\n",
    "    Dcl,  # replace with your own Dataset\n",
    "    [\"num_genes\", \"num_classes\"],  # change according to what you need for your model\n",
    "    cell_line_metadata_cb,  # include data you need for your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49b8b51-c03c-408b-981b-d801b81ac1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 Î¼s, sys: 1 Î¼s, total: 10 Î¼s\n",
      "Wall time: 20.5 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [\"/mnt/hdd2/tan/tahoe100m/plate3_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
    "batch_size = 2000\n",
    "test_size = 0.0\n",
    "val_size = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1276fd-f441-4ee5-9425-877f9a0c564e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "Using 1 workers with {'CPU': 4} each\n",
      "=========Length of val_split 0 length of test_split 0 length of train_split 147\n",
      "=========Length of after dropping remainder val_split 0 length of test_split 0 length of train_split 144\n",
      "Data splitting time: 12.60 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:29:17,362\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning Ray worker and initiating distributed training\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:18 (running for 00:00:00.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:23 (running for 00:00:05.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:28 (running for 00:00:10.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:33 (running for 00:00:15.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:38 (running for 00:00:20.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:43 (running for 00:00:25.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:48 (running for 00:00:30.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:53 (running for 00:00:35.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:29:58 (running for 00:00:40.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:03 (running for 00:00:45.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:08 (running for 00:00:50.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:13 (running for 00:00:55.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:18 (running for 00:01:00.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:23 (running for 00:01:05.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:28 (running for 00:01:10.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:33 (running for 00:01:15.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:38 (running for 00:01:20.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:43 (running for 00:01:25.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:48 (running for 00:01:30.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:53 (running for 00:01:35.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:30:58 (running for 00:01:40.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:03 (running for 00:01:45.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:08 (running for 00:01:50.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:13 (running for 00:01:55.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:18 (running for 00:02:00.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:23 (running for 00:02:05.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:28 (running for 00:02:10.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:33 (running for 00:02:15.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:38 (running for 00:02:20.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:43 (running for 00:02:25.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:48 (running for 00:02:31.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:53 (running for 00:02:36.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:31:58 (running for 00:02:41.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:32:04,029\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/dtran/protoplast_results/TorchTrainer_2025-10-21_05-29-17' in 0.0090s.\n",
      "2025-10-21 05:32:04,032\tINFO tune.py:1041 -- Total run time: 166.67 seconds (166.13 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-10-21 05:32:03 (running for 00:02:46.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:32:04 (running for 00:02:46.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-28-54_013661_1117002/artifacts/2025-10-21_05-29-17/TorchTrainer_2025-10-21_05-29-17/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "CPU times: user 12.9 s, sys: 2.27 s, total: 15.2 s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 2000\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.0\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cac8856-4118-42bc-b23b-dcfbbf1871fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 4705402 Ã— 62710 backed at '/mnt/hdd2/tan/tahoe100m/plate3_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad'\n",
       "    obs: 'sample', 'gene_count', 'tscp_count', 'mread_count', 'drugname_drugconc', 'drug', 'cell_line', 'sublibrary', 'BARCODE', 'pcnt_mito', 'S_score', 'G2M_score', 'phase', 'pass_filter', 'cell_name', 'plate'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check plate 3\n",
    "import anndata as ad\n",
    "adata = ad.read_h5ad(\n",
    "    '/mnt/hdd2/tan/tahoe100m/plate3_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad',\n",
    "    backed=\"r\"\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c396a457-8ac6-41c4-b615-2761c35a26b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000 * 2304"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ae91e-c9aa-432d-a2dc-d3b11ef0c30c",
   "metadata": {},
   "source": [
    "**number of obs in plate 3 is 4705402**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b919a4-de98-4d58-ad7e-28427160df26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97402"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4705402 - 4608000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91585c4-e918-43e1-9ad2-31c7e1318847",
   "metadata": {},
   "source": [
    "## Simple Classifier with subset plate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238659c6-0dfd-4591-92fe-e212d893f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 Î¼s, sys: 3 Î¼s, total: 19 Î¼s\n",
      "Wall time: 33.6 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [\"/mnt/hdd1/dung/tahoe100/tahoe100_data/plate3_2k-obs.h5ad\"]\n",
    "batch_size = 20\n",
    "test_size = 0.0\n",
    "val_size = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1375e59e-77f4-462f-98f1-24635b01018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:35:05,713\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "2025-10-21 05:35:07,747\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example'.\n",
      "2025-10-21 05:35:07,879\tWARNING packaging.py:430 -- File /mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack is very large (34.70MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack']})`\n",
      "2025-10-21 05:35:08,094\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_b39efe59389269b9.zip' (69.86MiB) to Ray cluster...\n",
      "2025-10-21 05:35:08,579\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_b39efe59389269b9.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 752 ms, sys: 813 ms, total: 1.56 s\n",
      "Wall time: 11 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Using CPython \u001b[36m3.11.13\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[2mInstalled \u001b[1m296 packages\u001b[0m \u001b[2min 323ms\u001b[0m\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=1135791)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainTrainable pid=1135791)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=1135791)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=1135791)\u001b[0m - (node_id=1c47986fdd822e91642beae2757d0a99f137918620e073622607d172, ip=192.168.1.226, pid=1136456) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m =========Starting the training on 0 with num threads: 4=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "Epoch 0:   0%|          | 0/64 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/runtime_resources/working_dir_files/_ray_pkg_b39efe59389269b9/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17%|â–ˆâ–‹        | 11/64 [00:00<00:03, 17.65it/s, v_num=0, train_loss=3.840]\n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 13/64 [00:00<00:02, 20.55it/s, v_num=0, train_loss=3.540]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 15/64 [00:00<00:02, 23.44it/s, v_num=0, train_loss=3.760]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:00<00:01, 24.79it/s, v_num=0, train_loss=3.020]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 17/64 [00:00<00:01, 26.19it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [00:00<00:00, 42.16it/s, v_num=0, train_loss=1.760]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 34/64 [00:00<00:00, 44.14it/s, v_num=0, train_loss=1.790]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [00:00<00:00, 45.13it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [00:00<00:00, 46.09it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [00:00<00:00, 47.07it/s, v_num=0, train_loss=1.400]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [00:00<00:00, 61.39it/s, v_num=0, train_loss=1.630]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [00:00<00:00, 62.90it/s, v_num=0, train_loss=0.615]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [00:00<00:00, 63.65it/s, v_num=0, train_loss=0.970]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [00:00<00:00, 64.40it/s, v_num=0, train_loss=0.551]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:00<00:00, 67.01it/s, v_num=0, train_loss=0.939]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:01<00:00, 56.67it/s, v_num=0, train_loss=0.939]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:01<00:00, 51.71it/s, v_num=0, train_loss=0.939]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-10-21_05-35-13/TorchTrainer_b7814_00000_0_2025-10-21_05-35-13/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=1136456)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,  # replace with your own model\n",
    "    Dcl,  # replace with your own Dataset\n",
    "    [\"num_genes\", \"num_classes\"],  # change according to what you need for your model\n",
    "    cell_line_metadata_cb,  # include data you need for your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4aeab9-ec45-4102-a551-b3fe46d382eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:35:13,332\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "Using 1 workers with {'CPU': 4} each\n",
      "=========Length of val_split 0 length of test_split 0 length of train_split 6\n",
      "=========Warning: 0.3333333333333333 of data is dropped\n",
      "=========Length of after dropping remainder val_split 0 length of test_split 0 length of train_split 4\n",
      "Data splitting time: 0.09 seconds\n",
      "Spawning Ray worker and initiating distributed training\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:13 (running for 00:00:00.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:18 (running for 00:00:05.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:23 (running for 00:00:10.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:28 (running for 00:00:15.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:33 (running for 00:00:20.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:38 (running for 00:00:25.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:43 (running for 00:00:30.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:48 (running for 00:00:35.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:35:50,328\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/dtran/protoplast_results/TorchTrainer_2025-10-21_05-35-13' in 0.0085s.\n",
      "2025-10-21 05:35:50,331\tINFO tune.py:1041 -- Total run time: 37.00 seconds (36.98 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-10-21 05:35:50 (running for 00:00:36.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-35-02_326560_1117002/artifacts/2025-10-21_05-35-13/TorchTrainer_2025-10-21_05-35-13/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "CPU times: user 586 ms, sys: 142 ms, total: 728 ms\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 20\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.0\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49fefd0-27cc-40a0-a574-de4822e86670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f42aad-8277-418b-bac9-7d1ce5ed18a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 2000 Ã— 62710 backed at '/mnt/hdd1/dung/tahoe100/tahoe100_data/plate3_2k-obs.h5ad'\n",
       "    obs: 'sample', 'gene_count', 'tscp_count', 'mread_count', 'drugname_drugconc', 'drug', 'cell_line', 'sublibrary', 'BARCODE', 'pcnt_mito', 'S_score', 'G2M_score', 'phase', 'pass_filter', 'cell_name', 'plate'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check subset plate 3\n",
    "import anndata as ad\n",
    "adata = ad.read_h5ad(\n",
    "    '/mnt/hdd1/dung/tahoe100/tahoe100_data/plate3_2k-obs.h5ad',\n",
    "    backed=\"r\"\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5450738e-2efe-40b6-b6f1-df09d2767ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000 - 1280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f761d-96c1-4ab4-bea2-5d9514b4c6f0",
   "metadata": {},
   "source": [
    "## Simple Classifier with plate 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91e4320-849f-47a0-af27-67ed6333b02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 Î¼s, sys: 2 Î¼s, total: 14 Î¼s\n",
      "Wall time: 23.4 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [\"/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
    "batch_size = 2000\n",
    "test_size = 0.0\n",
    "val_size = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74a2785c-616b-42eb-8370-5fae0aaf0680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:37:40,838\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "2025-10-21 05:37:41,038\tINFO packaging.py:588 -- Creating a file package for local module '/mnt/hdd1/dung/protoplast-ml-example'.\n",
      "2025-10-21 05:37:41,169\tWARNING packaging.py:430 -- File /mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack is very large (34.70MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/mnt/hdd1/dung/protoplast-ml-example/.git/modules/submodules/SIMS/objects/pack/pack-682433dc4cf8becc2b44606f464dde9068565261.pack']})`\n",
      "2025-10-21 05:37:41,388\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_3fbad0cfa52c6e74.zip' (69.87MiB) to Ray cluster...\n",
      "2025-10-21 05:37:41,835\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_3fbad0cfa52c6e74.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 609 ms, sys: 717 ms, total: 1.33 s\n",
      "Wall time: 9.57 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Using CPython \u001b[36m3.11.13\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[2mInstalled \u001b[1m296 packages\u001b[0m \u001b[2min 324ms\u001b[0m\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=1145747)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(TrainTrainable pid=1145747)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m \u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/mnt/hdd1/dung/protoplast-ml-example/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=1145747)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=1145747)\u001b[0m - (node_id=7d25471cce9ea94872fc66a00d7b94df796714fdaf6668b57c229afe, ip=192.168.1.226, pid=1146525) world_rank=0, local_rank=0, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m âœ“ Applied AnnDataFileManager patch, AnnData cannot be imported after the patch!\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m =========Starting the training on 0 with num threads: 4=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /mnt/hdd1/dung/protoplast-ml-example/.venv/lib/pyth ...\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   | Name    | Type             | Params | Mode \n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 0 | model   | Linear           | 3.1 M  | train\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 3.1 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 3.1 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 12.542    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 2         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "Epoch 0:   0%|          | 0/5184 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   return torch.sparse_csr_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/.venv/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:473: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   return torch.sparse_compressed_tensor(\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 2/5184 [00:25<18:20:09,  0.08it/s, v_num=0, train_loss=3.520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/runtime_resources/working_dir_files/_ray_pkg_3fbad0cfa52c6e74/submodules/protoplast/src/protoplast/scrna/anndata/torch_dataloader.py:130: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m   return torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 4/5184 [00:25<9:17:30,  0.15it/s, v_num=0, train_loss=2.520] \n",
      "Epoch 0:   0%|          | 5/5184 [00:25<7:26:16,  0.19it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 0:   0%|          | 9/5184 [00:25<4:08:43,  0.35it/s, v_num=0, train_loss=1.050]\n",
      "Epoch 0:   0%|          | 14/5184 [00:26<2:40:30,  0.54it/s, v_num=0, train_loss=0.579]\n",
      "Epoch 0:   0%|          | 14/5184 [00:26<2:40:30,  0.54it/s, v_num=0, train_loss=0.676]\n",
      "Epoch 0:   0%|          | 18/5184 [00:26<2:05:13,  0.69it/s, v_num=0, train_loss=0.469]\n",
      "Epoch 0:   0%|          | 22/5184 [00:26<1:42:48,  0.84it/s, v_num=0, train_loss=0.492]\n",
      "Epoch 0:   1%|          | 26/5184 [00:26<1:27:17,  0.98it/s, v_num=0, train_loss=0.317]\n",
      "Epoch 0:   1%|          | 27/5184 [00:26<1:24:08,  1.02it/s, v_num=0, train_loss=0.270]\n",
      "Epoch 0:   1%|          | 31/5184 [00:26<1:13:31,  1.17it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:   1%|          | 32/5184 [00:26<1:11:17,  1.20it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:   1%|          | 32/5184 [00:26<1:11:17,  1.20it/s, v_num=0, train_loss=0.226]\n",
      "Epoch 0:   1%|          | 37/5184 [00:26<1:01:51,  1.39it/s, v_num=0, train_loss=0.295]\n",
      "Epoch 0:   1%|          | 41/5184 [00:26<55:59,  1.53it/s, v_num=0, train_loss=0.301]  \n",
      "Epoch 0:   1%|          | 46/5184 [00:26<50:04,  1.71it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:   1%|          | 50/5184 [00:26<46:11,  1.85it/s, v_num=0, train_loss=0.190]\n",
      "Epoch 0:   1%|          | 51/5184 [00:27<45:19,  1.89it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:   1%|          | 55/5184 [00:27<42:08,  2.03it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:   1%|          | 56/5184 [00:27<41:24,  2.06it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:   1%|          | 60/5184 [00:27<38:45,  2.20it/s, v_num=0, train_loss=0.0958]\n",
      "Epoch 0:   1%|          | 64/5184 [00:27<36:26,  2.34it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:   1%|â–         | 66/5184 [00:31<40:33,  2.10it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:   1%|â–         | 67/5184 [00:31<39:58,  2.13it/s, v_num=0, train_loss=0.0697]\n",
      "Epoch 0:   1%|â–         | 71/5184 [00:31<37:49,  2.25it/s, v_num=0, train_loss=0.0895]\n",
      "Epoch 0:   1%|â–         | 72/5184 [00:31<37:19,  2.28it/s, v_num=0, train_loss=0.0895]\n",
      "Epoch 0:   1%|â–         | 72/5184 [00:31<37:19,  2.28it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:   1%|â–         | 76/5184 [00:31<35:27,  2.40it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:   2%|â–         | 81/5184 [00:31<33:21,  2.55it/s, v_num=0, train_loss=0.098] \n",
      "Epoch 0:   2%|â–         | 85/5184 [00:31<31:52,  2.67it/s, v_num=0, train_loss=0.0963]\n",
      "Epoch 0:   2%|â–         | 90/5184 [00:32<30:11,  2.81it/s, v_num=0, train_loss=0.082] \n",
      "Epoch 0:   2%|â–         | 94/5184 [00:32<28:59,  2.93it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:   2%|â–         | 98/5184 [00:32<27:52,  3.04it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:   2%|â–         | 102/5184 [00:32<26:51,  3.15it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:   2%|â–         | 103/5184 [00:32<26:36,  3.18it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:   2%|â–         | 107/5184 [00:32<25:40,  3.30it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:   2%|â–         | 112/5184 [00:32<24:36,  3.44it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:   2%|â–         | 117/5184 [00:32<23:36,  3.58it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:   2%|â–         | 121/5184 [00:32<22:52,  3.69it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:   2%|â–         | 122/5184 [00:32<22:42,  3.72it/s, v_num=0, train_loss=0.087]\n",
      "Epoch 0:   2%|â–         | 126/5184 [00:32<22:02,  3.83it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:   2%|â–         | 127/5184 [00:32<21:52,  3.85it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:   2%|â–         | 128/5184 [00:32<21:42,  3.88it/s, v_num=0, train_loss=0.0933]\n",
      "Epoch 0:   3%|â–Ž         | 130/5184 [00:37<24:14,  3.48it/s, v_num=0, train_loss=0.196] \n",
      "Epoch 0:   3%|â–Ž         | 131/5184 [00:37<24:15,  3.47it/s, v_num=0, train_loss=0.160]\n",
      "Epoch 0:   3%|â–Ž         | 134/5184 [00:37<23:45,  3.54it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:   3%|â–Ž         | 135/5184 [00:37<23:35,  3.57it/s, v_num=0, train_loss=0.0572]\n",
      "Epoch 0:   3%|â–Ž         | 139/5184 [00:37<22:57,  3.66it/s, v_num=0, train_loss=0.0907]\n",
      "Epoch 0:   3%|â–Ž         | 143/5184 [00:38<22:22,  3.76it/s, v_num=0, train_loss=0.0864]\n",
      "Epoch 0:   3%|â–Ž         | 144/5184 [00:38<22:13,  3.78it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:   3%|â–Ž         | 148/5184 [00:38<21:39,  3.87it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:   3%|â–Ž         | 152/5184 [00:38<21:08,  3.97it/s, v_num=0, train_loss=0.0774]\n",
      "Epoch 0:   3%|â–Ž         | 157/5184 [00:38<20:30,  4.08it/s, v_num=0, train_loss=0.0916]\n",
      "Epoch 0:   3%|â–Ž         | 161/5184 [00:38<20:02,  4.18it/s, v_num=0, train_loss=0.0919]\n",
      "Epoch 0:   3%|â–Ž         | 165/5184 [00:38<19:35,  4.27it/s, v_num=0, train_loss=0.0796]\n",
      "Epoch 0:   3%|â–Ž         | 166/5184 [00:38<19:29,  4.29it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:   3%|â–Ž         | 170/5184 [00:38<19:03,  4.38it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:   3%|â–Ž         | 174/5184 [00:38<18:39,  4.47it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:   3%|â–Ž         | 179/5184 [00:39<18:11,  4.59it/s, v_num=0, train_loss=0.0494]\n",
      "Epoch 0:   4%|â–Ž         | 183/5184 [00:39<17:49,  4.68it/s, v_num=0, train_loss=0.0495]\n",
      "Epoch 0:   4%|â–Ž         | 188/5184 [00:39<17:23,  4.79it/s, v_num=0, train_loss=0.0611]\n",
      "Epoch 0:   4%|â–Ž         | 192/5184 [00:39<17:03,  4.88it/s, v_num=0, train_loss=0.068] \n",
      "Epoch 0:   4%|â–         | 195/5184 [00:44<18:46,  4.43it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:   4%|â–         | 196/5184 [00:44<18:41,  4.45it/s, v_num=0, train_loss=0.0957]\n",
      "Epoch 0:   4%|â–         | 200/5184 [00:44<18:20,  4.53it/s, v_num=0, train_loss=0.0975]\n",
      "Epoch 0:   4%|â–         | 204/5184 [00:44<18:01,  4.61it/s, v_num=0, train_loss=0.0907]\n",
      "Epoch 0:   4%|â–         | 208/5184 [00:44<17:41,  4.69it/s, v_num=0, train_loss=0.0644]\n",
      "Epoch 0:   4%|â–         | 213/5184 [00:44<17:19,  4.78it/s, v_num=0, train_loss=0.0817]\n",
      "Epoch 0:   4%|â–         | 217/5184 [00:44<17:01,  4.86it/s, v_num=0, train_loss=0.0748]\n",
      "Epoch 0:   4%|â–         | 221/5184 [00:44<16:44,  4.94it/s, v_num=0, train_loss=0.0745]\n",
      "Epoch 0:   4%|â–         | 225/5184 [00:44<16:28,  5.02it/s, v_num=0, train_loss=0.0761]\n",
      "Epoch 0:   4%|â–         | 226/5184 [00:44<16:24,  5.04it/s, v_num=0, train_loss=0.0971]\n",
      "Epoch 0:   4%|â–         | 230/5184 [00:44<16:08,  5.11it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:   5%|â–         | 235/5184 [00:45<15:50,  5.21it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:   5%|â–         | 239/5184 [00:45<15:35,  5.29it/s, v_num=0, train_loss=0.0734]\n",
      "Epoch 0:   5%|â–         | 244/5184 [00:45<15:18,  5.38it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:   5%|â–         | 248/5184 [00:45<15:04,  5.46it/s, v_num=0, train_loss=0.0658]\n",
      "Epoch 0:   5%|â–         | 249/5184 [00:45<15:01,  5.48it/s, v_num=0, train_loss=0.0934]\n",
      "Epoch 0:   5%|â–         | 253/5184 [00:45<14:48,  5.55it/s, v_num=0, train_loss=0.0661]\n",
      "Epoch 0:   5%|â–         | 254/5184 [00:45<14:44,  5.57it/s, v_num=0, train_loss=0.0588]\n",
      "Epoch 0:   5%|â–         | 256/5184 [00:45<14:38,  5.61it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:   5%|â–         | 257/5184 [00:48<15:38,  5.25it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:   5%|â–Œ         | 262/5184 [00:49<15:22,  5.34it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:   5%|â–Œ         | 266/5184 [00:49<15:09,  5.41it/s, v_num=0, train_loss=0.0871]\n",
      "Epoch 0:   5%|â–Œ         | 267/5184 [00:49<15:06,  5.43it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:   5%|â–Œ         | 272/5184 [00:49<14:50,  5.51it/s, v_num=0, train_loss=0.0787]\n",
      "Epoch 0:   5%|â–Œ         | 276/5184 [00:49<14:38,  5.58it/s, v_num=0, train_loss=0.0933]\n",
      "Epoch 0:   5%|â–Œ         | 277/5184 [00:49<14:36,  5.60it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:   5%|â–Œ         | 281/5184 [00:49<14:24,  5.67it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:   6%|â–Œ         | 286/5184 [00:49<14:10,  5.76it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:   6%|â–Œ         | 291/5184 [00:49<13:57,  5.84it/s, v_num=0, train_loss=0.213] \n",
      "Epoch 0:   6%|â–Œ         | 295/5184 [00:49<13:47,  5.91it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:   6%|â–Œ         | 296/5184 [00:49<13:44,  5.93it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:   6%|â–Œ         | 300/5184 [00:50<13:34,  6.00it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:   6%|â–Œ         | 305/5184 [00:50<13:22,  6.08it/s, v_num=0, train_loss=0.0927]\n",
      "Epoch 0:   6%|â–Œ         | 310/5184 [00:50<13:10,  6.17it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:   6%|â–Œ         | 315/5184 [00:50<12:58,  6.25it/s, v_num=0, train_loss=0.0841]\n",
      "Epoch 0:   6%|â–Œ         | 319/5184 [00:50<12:49,  6.32it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:   6%|â–Œ         | 320/5184 [00:50<12:47,  6.34it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:   6%|â–Œ         | 323/5184 [00:54<13:41,  5.92it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:   6%|â–‹         | 324/5184 [00:54<13:39,  5.93it/s, v_num=0, train_loss=0.0925]\n",
      "Epoch 0:   6%|â–‹         | 328/5184 [00:54<13:30,  5.99it/s, v_num=0, train_loss=0.0917]\n",
      "Epoch 0:   6%|â–‹         | 332/5184 [00:54<13:21,  6.05it/s, v_num=0, train_loss=0.0853]\n",
      "Epoch 0:   6%|â–‹         | 333/5184 [00:54<13:19,  6.07it/s, v_num=0, train_loss=0.0998]\n",
      "Epoch 0:   7%|â–‹         | 338/5184 [00:54<13:08,  6.15it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:   7%|â–‹         | 343/5184 [00:55<12:57,  6.23it/s, v_num=0, train_loss=0.0899]\n",
      "Epoch 0:   7%|â–‹         | 348/5184 [00:55<12:47,  6.30it/s, v_num=0, train_loss=0.0889]\n",
      "Epoch 0:   7%|â–‹         | 353/5184 [00:55<12:37,  6.38it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:   7%|â–‹         | 357/5184 [00:55<12:29,  6.44it/s, v_num=0, train_loss=0.133]\n",
      "Epoch 0:   7%|â–‹         | 358/5184 [00:55<12:27,  6.46it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:   7%|â–‹         | 363/5184 [00:55<12:18,  6.53it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:   7%|â–‹         | 368/5184 [00:55<12:08,  6.61it/s, v_num=0, train_loss=0.168]\n",
      "Epoch 0:   7%|â–‹         | 373/5184 [00:55<11:59,  6.68it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:   7%|â–‹         | 378/5184 [00:55<11:50,  6.76it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:   7%|â–‹         | 383/5184 [00:56<11:42,  6.84it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:   7%|â–‹         | 384/5184 [00:56<11:40,  6.85it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:   7%|â–‹         | 387/5184 [01:00<12:25,  6.43it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:   7%|â–‹         | 388/5184 [01:00<12:23,  6.45it/s, v_num=0, train_loss=0.156]\n",
      "Epoch 0:   8%|â–Š         | 392/5184 [01:00<12:16,  6.50it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:   8%|â–Š         | 393/5184 [01:00<12:14,  6.52it/s, v_num=0, train_loss=0.0942]\n",
      "Epoch 0:   8%|â–Š         | 398/5184 [01:00<12:06,  6.59it/s, v_num=0, train_loss=0.0781]\n",
      "Epoch 0:   8%|â–Š         | 403/5184 [01:00<11:57,  6.66it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:   8%|â–Š         | 408/5184 [01:00<11:49,  6.73it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:   8%|â–Š         | 413/5184 [01:00<11:41,  6.80it/s, v_num=0, train_loss=0.098]\n",
      "Epoch 0:   8%|â–Š         | 417/5184 [01:00<11:35,  6.85it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:   8%|â–Š         | 418/5184 [01:00<11:34,  6.87it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:   8%|â–Š         | 423/5184 [01:00<11:26,  6.94it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:   8%|â–Š         | 427/5184 [01:01<11:20,  6.99it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:   8%|â–Š         | 428/5184 [01:01<11:19,  7.00it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:   8%|â–Š         | 432/5184 [01:01<11:13,  7.06it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:   8%|â–Š         | 433/5184 [01:01<11:11,  7.07it/s, v_num=0, train_loss=0.0873]\n",
      "Epoch 0:   8%|â–Š         | 438/5184 [01:01<11:04,  7.14it/s, v_num=0, train_loss=0.195] \n",
      "Epoch 0:   8%|â–Š         | 439/5184 [01:01<11:03,  7.16it/s, v_num=0, train_loss=0.0987]\n",
      "Epoch 0:   9%|â–Š         | 444/5184 [01:01<10:56,  7.22it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:   9%|â–Š         | 448/5184 [01:01<10:50,  7.28it/s, v_num=0, train_loss=0.222] \n",
      "Epoch 0:   9%|â–Š         | 449/5184 [01:04<11:25,  6.91it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:   9%|â–Š         | 453/5184 [01:05<11:20,  6.95it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:   9%|â–‰         | 458/5184 [01:05<11:13,  7.02it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:   9%|â–‰         | 463/5184 [01:05<11:06,  7.08it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:   9%|â–‰         | 467/5184 [01:05<11:01,  7.13it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:   9%|â–‰         | 468/5184 [01:05<11:00,  7.14it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:   9%|â–‰         | 473/5184 [01:05<10:53,  7.21it/s, v_num=0, train_loss=0.194] \n",
      "Epoch 0:   9%|â–‰         | 478/5184 [01:05<10:47,  7.27it/s, v_num=0, train_loss=0.141]\n",
      "Epoch 0:   9%|â–‰         | 483/5184 [01:05<10:40,  7.33it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:   9%|â–‰         | 488/5184 [01:05<10:34,  7.40it/s, v_num=0, train_loss=0.0925]\n",
      "Epoch 0:   9%|â–‰         | 492/5184 [01:06<10:30,  7.44it/s, v_num=0, train_loss=0.0768]\n",
      "Epoch 0:  10%|â–‰         | 497/5184 [01:06<10:24,  7.51it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  10%|â–‰         | 502/5184 [01:06<10:18,  7.57it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  10%|â–‰         | 507/5184 [01:06<10:12,  7.63it/s, v_num=0, train_loss=0.0808]\n",
      "Epoch 0:  10%|â–‰         | 512/5184 [01:06<10:07,  7.69it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  10%|â–‰         | 513/5184 [01:09<10:34,  7.36it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  10%|â–‰         | 514/5184 [01:09<10:35,  7.35it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  10%|â–‰         | 515/5184 [01:09<10:34,  7.36it/s, v_num=0, train_loss=0.160]\n",
      "Epoch 0:  10%|â–‰         | 516/5184 [01:10<10:33,  7.36it/s, v_num=0, train_loss=0.0939]\n",
      "Epoch 0:  10%|â–ˆ         | 521/5184 [01:10<10:28,  7.42it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  10%|â–ˆ         | 526/5184 [01:10<10:22,  7.48it/s, v_num=0, train_loss=0.0793]\n",
      "Epoch 0:  10%|â–ˆ         | 531/5184 [01:10<10:17,  7.54it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  10%|â–ˆ         | 535/5184 [01:10<10:12,  7.59it/s, v_num=0, train_loss=0.0518]\n",
      "Epoch 0:  10%|â–ˆ         | 536/5184 [01:10<10:11,  7.60it/s, v_num=0, train_loss=0.0603]\n",
      "Epoch 0:  10%|â–ˆ         | 540/5184 [01:10<10:07,  7.64it/s, v_num=0, train_loss=0.0696]\n",
      "Epoch 0:  10%|â–ˆ         | 541/5184 [01:10<10:06,  7.66it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  11%|â–ˆ         | 545/5184 [01:10<10:02,  7.70it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  11%|â–ˆ         | 550/5184 [01:10<09:57,  7.76it/s, v_num=0, train_loss=0.0612]\n",
      "Epoch 0:  11%|â–ˆ         | 554/5184 [01:11<09:53,  7.80it/s, v_num=0, train_loss=0.0671]\n",
      "Epoch 0:  11%|â–ˆ         | 555/5184 [01:11<09:52,  7.81it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  11%|â–ˆ         | 559/5184 [01:11<09:48,  7.86it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  11%|â–ˆ         | 564/5184 [01:11<09:43,  7.92it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  11%|â–ˆ         | 569/5184 [01:11<09:38,  7.97it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  11%|â–ˆ         | 574/5184 [01:11<09:34,  8.03it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  11%|â–ˆ         | 576/5184 [01:11<09:32,  8.05it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  11%|â–ˆ         | 577/5184 [01:15<10:02,  7.64it/s, v_num=0, train_loss=0.163]\n",
      "Epoch 0:  11%|â–ˆ         | 579/5184 [01:15<10:01,  7.66it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  11%|â–ˆ         | 580/5184 [01:15<10:01,  7.66it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  11%|â–ˆ         | 583/5184 [01:15<09:58,  7.69it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  11%|â–ˆâ–        | 584/5184 [01:15<09:57,  7.70it/s, v_num=0, train_loss=0.237]\n",
      "Epoch 0:  11%|â–ˆâ–        | 589/5184 [01:15<09:52,  7.75it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  11%|â–ˆâ–        | 594/5184 [01:16<09:47,  7.81it/s, v_num=0, train_loss=0.0883]\n",
      "Epoch 0:  12%|â–ˆâ–        | 598/5184 [01:16<09:44,  7.85it/s, v_num=0, train_loss=0.0816]\n",
      "Epoch 0:  12%|â–ˆâ–        | 599/5184 [01:16<09:43,  7.86it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  12%|â–ˆâ–        | 603/5184 [01:16<09:39,  7.90it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  12%|â–ˆâ–        | 604/5184 [01:16<09:38,  7.91it/s, v_num=0, train_loss=0.0762]\n",
      "Epoch 0:  12%|â–ˆâ–        | 609/5184 [01:16<09:34,  7.97it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  12%|â–ˆâ–        | 613/5184 [01:16<09:30,  8.01it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  12%|â–ˆâ–        | 614/5184 [01:16<09:29,  8.02it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  12%|â–ˆâ–        | 619/5184 [01:16<09:25,  8.07it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  12%|â–ˆâ–        | 624/5184 [01:16<09:21,  8.13it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  12%|â–ˆâ–        | 629/5184 [01:16<09:16,  8.18it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  12%|â–ˆâ–        | 634/5184 [01:17<09:12,  8.23it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  12%|â–ˆâ–        | 639/5184 [01:17<09:08,  8.28it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  12%|â–ˆâ–        | 640/5184 [01:17<09:07,  8.29it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  12%|â–ˆâ–        | 641/5184 [01:20<09:27,  8.01it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  12%|â–ˆâ–        | 642/5184 [01:20<09:27,  8.00it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  12%|â–ˆâ–        | 643/5184 [01:20<09:27,  8.01it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  12%|â–ˆâ–Ž        | 648/5184 [01:20<09:23,  8.05it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 649/5184 [01:20<09:22,  8.06it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 653/5184 [01:20<09:19,  8.10it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 654/5184 [01:20<09:18,  8.11it/s, v_num=0, train_loss=0.0681]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 659/5184 [01:20<09:14,  8.16it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 664/5184 [01:20<09:10,  8.21it/s, v_num=0, train_loss=0.185] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 668/5184 [01:20<09:07,  8.25it/s, v_num=0, train_loss=0.0881]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 669/5184 [01:20<09:06,  8.26it/s, v_num=0, train_loss=0.0881]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 669/5184 [01:20<09:06,  8.26it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 673/5184 [01:21<09:03,  8.30it/s, v_num=0, train_loss=0.0929]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 674/5184 [01:21<09:02,  8.31it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 678/5184 [01:21<08:59,  8.35it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 682/5184 [01:21<08:56,  8.39it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 687/5184 [01:21<08:53,  8.43it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 692/5184 [01:21<08:49,  8.48it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  13%|â–ˆâ–Ž        | 697/5184 [01:21<08:45,  8.53it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 701/5184 [01:21<08:43,  8.57it/s, v_num=0, train_loss=0.179] \n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 702/5184 [01:21<08:42,  8.58it/s, v_num=0, train_loss=0.0649]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 704/5184 [01:21<08:40,  8.60it/s, v_num=0, train_loss=0.0874]\n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 706/5184 [01:25<09:02,  8.25it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 710/5184 [01:25<09:00,  8.28it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  14%|â–ˆâ–Ž        | 711/5184 [01:25<08:59,  8.29it/s, v_num=0, train_loss=0.0877]\n",
      "Epoch 0:  14%|â–ˆâ–        | 715/5184 [01:25<08:56,  8.33it/s, v_num=0, train_loss=0.0595]\n",
      "Epoch 0:  14%|â–ˆâ–        | 719/5184 [01:25<08:53,  8.37it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  14%|â–ˆâ–        | 720/5184 [01:25<08:53,  8.37it/s, v_num=0, train_loss=0.0952]\n",
      "Epoch 0:  14%|â–ˆâ–        | 725/5184 [01:26<08:49,  8.42it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  14%|â–ˆâ–        | 730/5184 [01:26<08:45,  8.47it/s, v_num=0, train_loss=0.0966]\n",
      "Epoch 0:  14%|â–ˆâ–        | 734/5184 [01:26<08:43,  8.50it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  14%|â–ˆâ–        | 735/5184 [01:26<08:42,  8.51it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  14%|â–ˆâ–        | 739/5184 [01:26<08:39,  8.55it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  14%|â–ˆâ–        | 740/5184 [01:26<08:39,  8.56it/s, v_num=0, train_loss=0.0739]\n",
      "Epoch 0:  14%|â–ˆâ–        | 744/5184 [01:26<08:36,  8.60it/s, v_num=0, train_loss=0.0954]\n",
      "Epoch 0:  14%|â–ˆâ–        | 745/5184 [01:26<08:35,  8.61it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  14%|â–ˆâ–        | 749/5184 [01:26<08:33,  8.64it/s, v_num=0, train_loss=0.0794]\n",
      "Epoch 0:  14%|â–ˆâ–        | 750/5184 [01:26<08:32,  8.65it/s, v_num=0, train_loss=0.0761]\n",
      "Epoch 0:  15%|â–ˆâ–        | 754/5184 [01:26<08:29,  8.69it/s, v_num=0, train_loss=0.0829]\n",
      "Epoch 0:  15%|â–ˆâ–        | 755/5184 [01:26<08:29,  8.70it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  15%|â–ˆâ–        | 760/5184 [01:26<08:26,  8.74it/s, v_num=0, train_loss=0.0621]\n",
      "Epoch 0:  15%|â–ˆâ–        | 765/5184 [01:27<08:22,  8.79it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  15%|â–ˆâ–        | 768/5184 [01:27<08:20,  8.82it/s, v_num=0, train_loss=0.145] \n",
      "Epoch 0:  15%|â–ˆâ–        | 769/5184 [01:29<08:35,  8.56it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  15%|â–ˆâ–        | 770/5184 [01:29<08:35,  8.56it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  15%|â–ˆâ–        | 771/5184 [01:30<08:35,  8.56it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  15%|â–ˆâ–        | 773/5184 [01:30<08:34,  8.57it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  15%|â–ˆâ–        | 774/5184 [01:30<08:34,  8.58it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 779/5184 [01:30<08:30,  8.62it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 783/5184 [01:30<08:28,  8.66it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 784/5184 [01:30<08:27,  8.67it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 789/5184 [01:30<08:24,  8.71it/s, v_num=0, train_loss=0.216]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 794/5184 [01:30<08:21,  8.75it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 799/5184 [01:30<08:18,  8.80it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  15%|â–ˆâ–Œ        | 803/5184 [01:30<08:16,  8.83it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 804/5184 [01:30<08:15,  8.84it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 808/5184 [01:31<08:13,  8.87it/s, v_num=0, train_loss=0.0723]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 813/5184 [01:31<08:10,  8.92it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 818/5184 [01:31<08:07,  8.96it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 818/5184 [01:31<08:07,  8.96it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 823/5184 [01:31<08:04,  9.00it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 828/5184 [01:31<08:01,  9.05it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 832/5184 [01:31<07:59,  9.08it/s, v_num=0, train_loss=0.0706]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 834/5184 [01:35<08:15,  8.77it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 835/5184 [01:35<08:16,  8.76it/s, v_num=0, train_loss=0.0651]\n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 838/5184 [01:35<08:15,  8.77it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  16%|â–ˆâ–Œ        | 842/5184 [01:35<08:13,  8.80it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  16%|â–ˆâ–‹        | 843/5184 [01:35<08:12,  8.81it/s, v_num=0, train_loss=0.0861]\n",
      "Epoch 0:  16%|â–ˆâ–‹        | 848/5184 [01:35<08:09,  8.85it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  16%|â–ˆâ–‹        | 853/5184 [01:35<08:06,  8.90it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 857/5184 [01:35<08:04,  8.93it/s, v_num=0, train_loss=0.224] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 858/5184 [01:36<08:04,  8.94it/s, v_num=0, train_loss=0.0915]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 862/5184 [01:36<08:01,  8.97it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 863/5184 [01:36<08:01,  8.98it/s, v_num=0, train_loss=0.191]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 867/5184 [01:36<07:59,  9.01it/s, v_num=0, train_loss=0.0724]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 868/5184 [01:36<07:58,  9.02it/s, v_num=0, train_loss=0.0737]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 872/5184 [01:36<07:56,  9.05it/s, v_num=0, train_loss=0.0416]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 877/5184 [01:36<07:53,  9.09it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 881/5184 [01:36<07:51,  9.12it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 882/5184 [01:36<07:51,  9.13it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 887/5184 [01:36<07:48,  9.17it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 892/5184 [01:36<07:45,  9.21it/s, v_num=0, train_loss=0.0503]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 896/5184 [01:36<07:43,  9.24it/s, v_num=0, train_loss=0.0991]\n",
      "Epoch 0:  17%|â–ˆâ–‹        | 898/5184 [01:40<07:59,  8.93it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  17%|â–ˆâ–‹        | 903/5184 [01:40<07:57,  8.97it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 908/5184 [01:40<07:54,  9.01it/s, v_num=0, train_loss=0.153] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 913/5184 [01:40<07:51,  9.05it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 917/5184 [01:40<07:49,  9.08it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 918/5184 [01:40<07:49,  9.09it/s, v_num=0, train_loss=0.0903]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 922/5184 [01:41<07:47,  9.12it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 923/5184 [01:41<07:46,  9.13it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 927/5184 [01:41<07:44,  9.16it/s, v_num=0, train_loss=0.0994]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 928/5184 [01:41<07:44,  9.17it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 932/5184 [01:41<07:42,  9.20it/s, v_num=0, train_loss=0.0889]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 933/5184 [01:41<07:41,  9.20it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 937/5184 [01:41<07:39,  9.24it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 938/5184 [01:41<07:39,  9.24it/s, v_num=0, train_loss=0.0864]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 942/5184 [01:41<07:37,  9.27it/s, v_num=0, train_loss=0.0652]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 943/5184 [01:41<07:36,  9.28it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 947/5184 [01:41<07:35,  9.31it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 948/5184 [01:41<07:34,  9.32it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 952/5184 [01:41<07:32,  9.35it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 953/5184 [01:41<07:32,  9.36it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  18%|â–ˆâ–Š        | 957/5184 [01:41<07:30,  9.39it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  18%|â–ˆâ–Š        | 958/5184 [01:41<07:29,  9.39it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  19%|â–ˆâ–Š        | 960/5184 [01:42<07:28,  9.41it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  19%|â–ˆâ–Š        | 961/5184 [01:46<07:46,  9.06it/s, v_num=0, train_loss=0.0963]\n",
      "Epoch 0:  19%|â–ˆâ–Š        | 962/5184 [01:46<07:46,  9.06it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  19%|â–ˆâ–Š        | 966/5184 [01:46<07:44,  9.08it/s, v_num=0, train_loss=0.0792]\n",
      "Epoch 0:  19%|â–ˆâ–Š        | 970/5184 [01:46<07:42,  9.11it/s, v_num=0, train_loss=0.0981]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 974/5184 [01:46<07:40,  9.14it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 975/5184 [01:46<07:40,  9.15it/s, v_num=0, train_loss=0.0447]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 979/5184 [01:46<07:38,  9.18it/s, v_num=0, train_loss=0.0643]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 984/5184 [01:46<07:35,  9.21it/s, v_num=0, train_loss=0.0514]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 984/5184 [01:46<07:35,  9.21it/s, v_num=0, train_loss=0.0565]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 988/5184 [01:46<07:34,  9.24it/s, v_num=0, train_loss=0.0884]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 992/5184 [01:47<07:32,  9.27it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 993/5184 [01:47<07:31,  9.28it/s, v_num=0, train_loss=0.0793]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 997/5184 [01:47<07:30,  9.30it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 1001/5184 [01:47<07:28,  9.33it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 1002/5184 [01:47<07:27,  9.34it/s, v_num=0, train_loss=0.0782]\n",
      "Epoch 0:  19%|â–ˆâ–‰        | 1006/5184 [01:47<07:26,  9.37it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  19%|â–ˆâ–‰        | 1010/5184 [01:47<07:24,  9.39it/s, v_num=0, train_loss=0.0702]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1011/5184 [01:47<07:23,  9.40it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1015/5184 [01:47<07:22,  9.43it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1016/5184 [01:47<07:21,  9.44it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1020/5184 [01:47<07:19,  9.47it/s, v_num=0, train_loss=0.0336]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1024/5184 [01:47<07:18,  9.49it/s, v_num=0, train_loss=0.0515]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1027/5184 [01:51<07:30,  9.22it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1031/5184 [01:51<07:28,  9.25it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1032/5184 [01:51<07:28,  9.26it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  20%|â–ˆâ–‰        | 1036/5184 [01:51<07:26,  9.29it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 1041/5184 [01:51<07:24,  9.32it/s, v_num=0, train_loss=0.0377]\n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 1046/5184 [01:51<07:22,  9.35it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 1050/5184 [01:51<07:20,  9.38it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 1055/5184 [01:52<07:18,  9.42it/s, v_num=0, train_loss=0.0828]\n",
      "Epoch 0:  20%|â–ˆâ–ˆ        | 1060/5184 [01:52<07:16,  9.45it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1065/5184 [01:52<07:14,  9.49it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1070/5184 [01:52<07:12,  9.52it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1074/5184 [01:52<07:10,  9.55it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1079/5184 [01:52<07:08,  9.58it/s, v_num=0, train_loss=0.138]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1084/5184 [01:52<07:06,  9.62it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1085/5184 [01:52<07:05,  9.62it/s, v_num=0, train_loss=0.212]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1088/5184 [01:52<07:04,  9.64it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1090/5184 [01:56<07:17,  9.35it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1095/5184 [01:56<07:15,  9.39it/s, v_num=0, train_loss=0.0865]\n",
      "Epoch 0:  21%|â–ˆâ–ˆ        | 1100/5184 [01:56<07:13,  9.42it/s, v_num=0, train_loss=0.204] \n",
      "Epoch 0:  21%|â–ˆâ–ˆâ–       | 1105/5184 [01:56<07:11,  9.45it/s, v_num=0, train_loss=0.0737]\n",
      "Epoch 0:  21%|â–ˆâ–ˆâ–       | 1109/5184 [01:56<07:09,  9.48it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  21%|â–ˆâ–ˆâ–       | 1110/5184 [01:57<07:09,  9.49it/s, v_num=0, train_loss=0.0917]\n",
      "Epoch 0:  21%|â–ˆâ–ˆâ–       | 1114/5184 [01:57<07:07,  9.51it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1119/5184 [01:57<07:05,  9.54it/s, v_num=0, train_loss=0.0751]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1124/5184 [01:57<07:03,  9.58it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1128/5184 [01:57<07:02,  9.60it/s, v_num=0, train_loss=0.176] \n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1129/5184 [01:57<07:02,  9.61it/s, v_num=0, train_loss=0.0688]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1133/5184 [01:57<07:00,  9.63it/s, v_num=0, train_loss=0.0723]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1138/5184 [01:57<06:58,  9.67it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1143/5184 [01:57<06:56,  9.70it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1148/5184 [01:57<06:54,  9.73it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1152/5184 [01:58<06:53,  9.76it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1153/5184 [02:01<07:03,  9.51it/s, v_num=0, train_loss=0.214]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1156/5184 [02:01<07:02,  9.53it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1161/5184 [02:01<07:00,  9.56it/s, v_num=0, train_loss=0.132]\n",
      "Epoch 0:  22%|â–ˆâ–ˆâ–       | 1165/5184 [02:01<06:59,  9.58it/s, v_num=0, train_loss=0.194]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1170/5184 [02:01<06:57,  9.62it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1175/5184 [02:01<06:55,  9.65it/s, v_num=0, train_loss=0.0977]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1176/5184 [02:01<06:55,  9.65it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1180/5184 [02:01<06:53,  9.68it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1181/5184 [02:01<06:53,  9.69it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1186/5184 [02:02<06:51,  9.72it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1190/5184 [02:02<06:49,  9.74it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1191/5184 [02:02<06:49,  9.75it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1196/5184 [02:02<06:47,  9.78it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1201/5184 [02:02<06:45,  9.81it/s, v_num=0, train_loss=0.0932]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1206/5184 [02:02<06:44,  9.84it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1211/5184 [02:02<06:42,  9.87it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1212/5184 [02:02<06:41,  9.88it/s, v_num=0, train_loss=0.172]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1216/5184 [02:02<06:40,  9.91it/s, v_num=0, train_loss=0.154]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1217/5184 [02:06<06:51,  9.63it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 1218/5184 [02:06<06:51,  9.63it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 1220/5184 [02:06<06:51,  9.64it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 1224/5184 [02:06<06:49,  9.66it/s, v_num=0, train_loss=0.0875]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 1225/5184 [02:06<06:49,  9.67it/s, v_num=0, train_loss=0.182] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 1229/5184 [02:06<06:48,  9.69it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 1230/5184 [02:06<06:47,  9.70it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1235/5184 [02:06<06:45,  9.73it/s, v_num=0, train_loss=0.0594]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1239/5184 [02:07<06:44,  9.75it/s, v_num=0, train_loss=0.0983]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1240/5184 [02:07<06:44,  9.76it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1244/5184 [02:07<06:42,  9.78it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1245/5184 [02:07<06:42,  9.79it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1249/5184 [02:07<06:41,  9.81it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1250/5184 [02:07<06:40,  9.82it/s, v_num=0, train_loss=0.0963]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1254/5184 [02:07<06:39,  9.84it/s, v_num=0, train_loss=0.0577]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1255/5184 [02:07<06:38,  9.85it/s, v_num=0, train_loss=0.0862]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1259/5184 [02:07<06:37,  9.87it/s, v_num=0, train_loss=0.0917]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1260/5184 [02:07<06:37,  9.88it/s, v_num=0, train_loss=0.066] \n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1264/5184 [02:07<06:35,  9.90it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1265/5184 [02:07<06:35,  9.91it/s, v_num=0, train_loss=0.0905]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1269/5184 [02:07<06:34,  9.93it/s, v_num=0, train_loss=0.0815]\n",
      "Epoch 0:  24%|â–ˆâ–ˆâ–       | 1270/5184 [02:07<06:33,  9.94it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1274/5184 [02:07<06:32,  9.96it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1275/5184 [02:07<06:32,  9.97it/s, v_num=0, train_loss=0.0899]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1279/5184 [02:08<06:30,  9.99it/s, v_num=0, train_loss=0.0846]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1280/5184 [02:08<06:30, 10.00it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1283/5184 [02:11<06:40,  9.74it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1287/5184 [02:11<06:39,  9.76it/s, v_num=0, train_loss=0.0742]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1288/5184 [02:11<06:38,  9.77it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1292/5184 [02:11<06:37,  9.79it/s, v_num=0, train_loss=0.0445]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–       | 1293/5184 [02:12<06:37,  9.80it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1297/5184 [02:12<06:35,  9.82it/s, v_num=0, train_loss=0.145] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1298/5184 [02:12<06:35,  9.82it/s, v_num=0, train_loss=0.096]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1302/5184 [02:12<06:34,  9.85it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1303/5184 [02:12<06:33,  9.85it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1307/5184 [02:12<06:32,  9.88it/s, v_num=0, train_loss=0.161]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1308/5184 [02:12<06:32,  9.88it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1312/5184 [02:12<06:30,  9.90it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1316/5184 [02:12<06:29,  9.93it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1317/5184 [02:12<06:29,  9.93it/s, v_num=0, train_loss=0.0615]\n",
      "Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1321/5184 [02:12<06:28,  9.95it/s, v_num=0, train_loss=0.0681]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1322/5184 [02:12<06:27,  9.96it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1326/5184 [02:12<06:26,  9.98it/s, v_num=0, train_loss=0.0897]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1327/5184 [02:12<06:26,  9.99it/s, v_num=0, train_loss=0.064] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1331/5184 [02:12<06:24, 10.01it/s, v_num=0, train_loss=0.0489]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1332/5184 [02:12<06:24, 10.02it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1336/5184 [02:13<06:23, 10.04it/s, v_num=0, train_loss=0.0804]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1337/5184 [02:13<06:22, 10.04it/s, v_num=0, train_loss=0.095] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1342/5184 [02:13<06:21, 10.07it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1344/5184 [02:13<06:20, 10.09it/s, v_num=0, train_loss=0.0917]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1345/5184 [02:16<06:30,  9.84it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1347/5184 [02:16<06:29,  9.84it/s, v_num=0, train_loss=0.0805]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1350/5184 [02:17<06:29,  9.85it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1351/5184 [02:17<06:28,  9.86it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1355/5184 [02:17<06:27,  9.88it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1356/5184 [02:17<06:27,  9.89it/s, v_num=0, train_loss=0.0693]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 1360/5184 [02:17<06:25,  9.91it/s, v_num=0, train_loss=0.0806]\n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 1365/5184 [02:17<06:24,  9.93it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 1369/5184 [02:17<06:23,  9.96it/s, v_num=0, train_loss=0.0854]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1374/5184 [02:17<06:21,  9.98it/s, v_num=0, train_loss=0.0944]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1378/5184 [02:17<06:20, 10.01it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1379/5184 [02:17<06:20, 10.01it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1383/5184 [02:17<06:18, 10.03it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1384/5184 [02:17<06:18, 10.04it/s, v_num=0, train_loss=0.0638]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1388/5184 [02:17<06:17, 10.06it/s, v_num=0, train_loss=0.0921]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1393/5184 [02:18<06:15, 10.09it/s, v_num=0, train_loss=0.0801]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1398/5184 [02:18<06:14, 10.11it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1402/5184 [02:18<06:13, 10.14it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1403/5184 [02:18<06:12, 10.14it/s, v_num=0, train_loss=0.0977]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1407/5184 [02:18<06:11, 10.16it/s, v_num=0, train_loss=0.084] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1408/5184 [02:18<06:11, 10.17it/s, v_num=0, train_loss=0.092]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1411/5184 [02:22<06:20,  9.92it/s, v_num=0, train_loss=0.0993]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1413/5184 [02:22<06:20,  9.92it/s, v_num=0, train_loss=0.078] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1417/5184 [02:22<06:18,  9.94it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1418/5184 [02:22<06:18,  9.95it/s, v_num=0, train_loss=0.100]\n",
      "Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 1423/5184 [02:22<06:17,  9.98it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1427/5184 [02:22<06:15, 10.00it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1431/5184 [02:22<06:14, 10.02it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1436/5184 [02:22<06:13, 10.04it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1440/5184 [02:23<06:11, 10.07it/s, v_num=0, train_loss=0.0615]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1441/5184 [02:23<06:11, 10.07it/s, v_num=0, train_loss=0.0783]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1445/5184 [02:23<06:10, 10.09it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1450/5184 [02:23<06:09, 10.12it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1455/5184 [02:23<06:07, 10.14it/s, v_num=0, train_loss=0.142]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1459/5184 [02:23<06:06, 10.16it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1464/5184 [02:23<06:05, 10.19it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1468/5184 [02:23<06:03, 10.21it/s, v_num=0, train_loss=0.0931]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1469/5184 [02:23<06:03, 10.22it/s, v_num=0, train_loss=0.0583]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1472/5184 [02:23<06:02, 10.23it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1473/5184 [02:27<06:11, 10.00it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1475/5184 [02:27<06:11,  9.98it/s, v_num=0, train_loss=0.0997]\n",
      "Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 1477/5184 [02:28<06:11,  9.98it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 1481/5184 [02:28<06:10, 10.00it/s, v_num=0, train_loss=0.0989]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 1486/5184 [02:28<06:08, 10.02it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 1487/5184 [02:28<06:08, 10.03it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1491/5184 [02:28<06:07, 10.05it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1495/5184 [02:28<06:06, 10.07it/s, v_num=0, train_loss=0.0595]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1499/5184 [02:28<06:05, 10.09it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1502/5184 [02:28<06:04, 10.10it/s, v_num=0, train_loss=0.0244]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1503/5184 [02:28<06:04, 10.10it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1507/5184 [02:28<06:03, 10.12it/s, v_num=0, train_loss=0.0595]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1512/5184 [02:28<06:01, 10.15it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1516/5184 [02:29<06:00, 10.17it/s, v_num=0, train_loss=0.0691]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1520/5184 [02:29<05:59, 10.19it/s, v_num=0, train_loss=0.083] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1521/5184 [02:29<05:59, 10.19it/s, v_num=0, train_loss=0.0824]\n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1525/5184 [02:29<05:58, 10.21it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 1526/5184 [02:29<05:57, 10.22it/s, v_num=0, train_loss=0.0583]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1530/5184 [02:29<05:56, 10.24it/s, v_num=0, train_loss=0.0621]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1531/5184 [02:29<05:56, 10.24it/s, v_num=0, train_loss=0.0485]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1535/5184 [02:29<05:55, 10.26it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1536/5184 [02:29<05:55, 10.27it/s, v_num=0, train_loss=0.0419]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1537/5184 [02:33<06:04, 10.00it/s, v_num=0, train_loss=0.0441]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1541/5184 [02:33<06:03, 10.02it/s, v_num=0, train_loss=0.0395]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1545/5184 [02:33<06:02, 10.04it/s, v_num=0, train_loss=0.0703]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1550/5184 [02:34<06:01, 10.06it/s, v_num=0, train_loss=0.0961]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–‰       | 1554/5184 [02:34<06:00, 10.08it/s, v_num=0, train_loss=0.0813]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1559/5184 [02:34<05:58, 10.11it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1563/5184 [02:34<05:57, 10.12it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1564/5184 [02:34<05:57, 10.13it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1568/5184 [02:34<05:56, 10.15it/s, v_num=0, train_loss=0.0867]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1573/5184 [02:34<05:54, 10.17it/s, v_num=0, train_loss=0.0752]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1577/5184 [02:34<05:53, 10.19it/s, v_num=0, train_loss=0.0717]\n",
      "Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 1581/5184 [02:34<05:52, 10.21it/s, v_num=0, train_loss=0.0374]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1582/5184 [02:34<05:52, 10.22it/s, v_num=0, train_loss=0.0608]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1586/5184 [02:34<05:51, 10.23it/s, v_num=0, train_loss=0.0527]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1591/5184 [02:35<05:50, 10.26it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1596/5184 [02:35<05:48, 10.28it/s, v_num=0, train_loss=0.0632]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1600/5184 [02:35<05:47, 10.30it/s, v_num=0, train_loss=0.0759]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1602/5184 [02:39<05:55, 10.07it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1606/5184 [02:39<05:54, 10.09it/s, v_num=0, train_loss=0.079] \n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1607/5184 [02:39<05:54, 10.09it/s, v_num=0, train_loss=0.0964]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1612/5184 [02:39<05:53, 10.11it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 1616/5184 [02:39<05:52, 10.13it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 1621/5184 [02:39<05:50, 10.16it/s, v_num=0, train_loss=0.0958]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 1625/5184 [02:39<05:49, 10.18it/s, v_num=0, train_loss=0.0998]\n",
      "Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 1630/5184 [02:39<05:48, 10.20it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1635/5184 [02:39<05:47, 10.22it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1639/5184 [02:40<05:46, 10.24it/s, v_num=0, train_loss=0.215] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1643/5184 [02:40<05:45, 10.26it/s, v_num=0, train_loss=0.201] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1644/5184 [02:40<05:44, 10.26it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1648/5184 [02:40<05:43, 10.28it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1653/5184 [02:40<05:42, 10.31it/s, v_num=0, train_loss=0.0708]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1658/5184 [02:40<05:41, 10.33it/s, v_num=0, train_loss=0.0826]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1663/5184 [02:40<05:40, 10.35it/s, v_num=0, train_loss=0.0756]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1664/5184 [02:40<05:39, 10.36it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1665/5184 [02:44<05:47, 10.14it/s, v_num=0, train_loss=0.0853]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1666/5184 [02:44<05:46, 10.14it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1670/5184 [02:44<05:45, 10.16it/s, v_num=0, train_loss=0.091] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1675/5184 [02:44<05:44, 10.18it/s, v_num=0, train_loss=0.0609]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1679/5184 [02:44<05:43, 10.20it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1680/5184 [02:44<05:43, 10.20it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 1684/5184 [02:44<05:42, 10.22it/s, v_num=0, train_loss=0.189] \n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1685/5184 [02:44<05:42, 10.23it/s, v_num=0, train_loss=0.108]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1689/5184 [02:44<05:41, 10.24it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1690/5184 [02:44<05:40, 10.25it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1694/5184 [02:44<05:39, 10.27it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1695/5184 [02:45<05:39, 10.27it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1699/5184 [02:45<05:38, 10.29it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1703/5184 [02:45<05:37, 10.31it/s, v_num=0, train_loss=0.092]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1707/5184 [02:45<05:36, 10.33it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1708/5184 [02:45<05:36, 10.33it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1713/5184 [02:45<05:35, 10.35it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1713/5184 [02:45<05:35, 10.35it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1718/5184 [02:45<05:34, 10.37it/s, v_num=0, train_loss=0.100] \n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1723/5184 [02:45<05:32, 10.40it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1727/5184 [02:45<05:31, 10.41it/s, v_num=0, train_loss=0.189] \n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1728/5184 [02:45<05:31, 10.42it/s, v_num=0, train_loss=0.086]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1730/5184 [02:49<05:38, 10.19it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1731/5184 [02:49<05:38, 10.20it/s, v_num=0, train_loss=0.0877]\n",
      "Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1735/5184 [02:49<05:37, 10.21it/s, v_num=0, train_loss=0.0755]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1740/5184 [02:49<05:36, 10.24it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1744/5184 [02:50<05:35, 10.25it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1745/5184 [02:50<05:35, 10.26it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1750/5184 [02:50<05:34, 10.28it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1754/5184 [02:50<05:33, 10.30it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1755/5184 [02:50<05:32, 10.30it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1759/5184 [02:50<05:31, 10.32it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1760/5184 [02:50<05:31, 10.32it/s, v_num=0, train_loss=0.0871]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1764/5184 [02:50<05:30, 10.34it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1769/5184 [02:50<05:29, 10.36it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1773/5184 [02:50<05:28, 10.38it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1774/5184 [02:50<05:28, 10.39it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1779/5184 [02:50<05:27, 10.41it/s, v_num=0, train_loss=0.0987]\n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1783/5184 [02:51<05:26, 10.42it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 1788/5184 [02:51<05:25, 10.45it/s, v_num=0, train_loss=0.0919]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1792/5184 [02:51<05:24, 10.46it/s, v_num=0, train_loss=0.175] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1796/5184 [02:55<05:30, 10.24it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1800/5184 [02:55<05:29, 10.26it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1805/5184 [02:55<05:28, 10.28it/s, v_num=0, train_loss=0.0644]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1809/5184 [02:55<05:27, 10.30it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1810/5184 [02:55<05:27, 10.30it/s, v_num=0, train_loss=0.0884]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 1814/5184 [02:55<05:26, 10.32it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1819/5184 [02:55<05:25, 10.34it/s, v_num=0, train_loss=0.0521]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1823/5184 [02:56<05:24, 10.36it/s, v_num=0, train_loss=0.0612]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1824/5184 [02:56<05:24, 10.36it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1828/5184 [02:56<05:23, 10.38it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1832/5184 [02:56<05:22, 10.40it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1833/5184 [02:56<05:22, 10.40it/s, v_num=0, train_loss=0.0761]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1837/5184 [02:56<05:21, 10.42it/s, v_num=0, train_loss=0.0317]\n",
      "Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1838/5184 [02:56<05:21, 10.42it/s, v_num=0, train_loss=0.0946]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1843/5184 [02:56<05:19, 10.44it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1848/5184 [02:56<05:18, 10.46it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1852/5184 [02:56<05:17, 10.48it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1856/5184 [02:56<05:17, 10.50it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1858/5184 [03:00<05:22, 10.30it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1859/5184 [03:00<05:22, 10.30it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1863/5184 [03:00<05:22, 10.31it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1864/5184 [03:00<05:21, 10.32it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1869/5184 [03:00<05:20, 10.34it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1874/5184 [03:00<05:19, 10.36it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1878/5184 [03:01<05:18, 10.38it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1879/5184 [03:01<05:18, 10.38it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1883/5184 [03:01<05:17, 10.40it/s, v_num=0, train_loss=0.0938]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1884/5184 [03:01<05:17, 10.40it/s, v_num=0, train_loss=0.0938]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1884/5184 [03:01<05:17, 10.40it/s, v_num=0, train_loss=0.0872]\n",
      "Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1888/5184 [03:01<05:16, 10.42it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1893/5184 [03:01<05:15, 10.44it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1897/5184 [03:01<05:14, 10.45it/s, v_num=0, train_loss=0.0959]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1898/5184 [03:01<05:14, 10.46it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1902/5184 [03:01<05:13, 10.47it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1907/5184 [03:01<05:12, 10.49it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1911/5184 [03:01<05:11, 10.51it/s, v_num=0, train_loss=0.0988]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1912/5184 [03:01<05:11, 10.51it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1916/5184 [03:01<05:10, 10.53it/s, v_num=0, train_loss=0.0921]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1920/5184 [03:02<05:09, 10.55it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1922/5184 [03:06<05:15, 10.32it/s, v_num=0, train_loss=0.0561]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1923/5184 [03:06<05:15, 10.33it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1925/5184 [03:06<05:15, 10.33it/s, v_num=0, train_loss=0.0824]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1929/5184 [03:06<05:14, 10.34it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1934/5184 [03:06<05:13, 10.36it/s, v_num=0, train_loss=0.0745]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1934/5184 [03:06<05:13, 10.36it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1938/5184 [03:06<05:12, 10.38it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1939/5184 [03:06<05:12, 10.38it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1943/5184 [03:06<05:11, 10.40it/s, v_num=0, train_loss=0.0714]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1947/5184 [03:07<05:10, 10.41it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1951/5184 [03:07<05:10, 10.43it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1955/5184 [03:07<05:09, 10.44it/s, v_num=0, train_loss=0.0776]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1960/5184 [03:07<05:08, 10.46it/s, v_num=0, train_loss=0.0945]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1963/5184 [03:07<05:07, 10.47it/s, v_num=0, train_loss=0.0579]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1964/5184 [03:07<05:07, 10.47it/s, v_num=0, train_loss=0.0849]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1968/5184 [03:07<05:06, 10.49it/s, v_num=0, train_loss=0.0873]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1972/5184 [03:07<05:05, 10.50it/s, v_num=0, train_loss=0.0756]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1977/5184 [03:07<05:04, 10.52it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1982/5184 [03:07<05:03, 10.54it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1984/5184 [03:08<05:03, 10.55it/s, v_num=0, train_loss=0.0404]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1985/5184 [03:12<05:09, 10.33it/s, v_num=0, train_loss=0.0371]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1986/5184 [03:12<05:09, 10.33it/s, v_num=0, train_loss=0.0382]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1990/5184 [03:12<05:08, 10.34it/s, v_num=0, train_loss=0.0476]\n",
      "Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1994/5184 [03:12<05:08, 10.36it/s, v_num=0, train_loss=0.0638]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 1998/5184 [03:12<05:07, 10.37it/s, v_num=0, train_loss=0.0524]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 1999/5184 [03:12<05:06, 10.37it/s, v_num=0, train_loss=0.0552]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 2003/5184 [03:12<05:06, 10.39it/s, v_num=0, train_loss=0.0765]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 2007/5184 [03:12<05:05, 10.40it/s, v_num=0, train_loss=0.0477]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2011/5184 [03:13<05:04, 10.42it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2015/5184 [03:13<05:03, 10.43it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2019/5184 [03:13<05:02, 10.45it/s, v_num=0, train_loss=0.0984]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2023/5184 [03:13<05:02, 10.46it/s, v_num=0, train_loss=0.0522]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2024/5184 [03:13<05:01, 10.47it/s, v_num=0, train_loss=0.0431]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2028/5184 [03:13<05:01, 10.48it/s, v_num=0, train_loss=0.0444]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2032/5184 [03:13<05:00, 10.50it/s, v_num=0, train_loss=0.0197]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2033/5184 [03:13<05:00, 10.50it/s, v_num=0, train_loss=0.056] \n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2037/5184 [03:13<04:59, 10.51it/s, v_num=0, train_loss=0.0565]\n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2042/5184 [03:13<04:58, 10.53it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2046/5184 [03:13<04:57, 10.55it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2048/5184 [03:14<04:57, 10.56it/s, v_num=0, train_loss=0.0691]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2049/5184 [03:18<05:03, 10.34it/s, v_num=0, train_loss=0.0423]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2052/5184 [03:18<05:02, 10.34it/s, v_num=0, train_loss=0.0697]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2056/5184 [03:18<05:02, 10.36it/s, v_num=0, train_loss=0.0807]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2057/5184 [03:18<05:01, 10.36it/s, v_num=0, train_loss=0.0575]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2061/5184 [03:18<05:01, 10.37it/s, v_num=0, train_loss=0.0633]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2065/5184 [03:18<05:00, 10.39it/s, v_num=0, train_loss=0.0978]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2066/5184 [03:18<05:00, 10.39it/s, v_num=0, train_loss=0.0693]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2070/5184 [03:18<04:59, 10.41it/s, v_num=0, train_loss=0.0326]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2074/5184 [03:18<04:58, 10.42it/s, v_num=0, train_loss=0.0433]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2075/5184 [03:19<04:58, 10.43it/s, v_num=0, train_loss=0.0486]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2079/5184 [03:19<04:57, 10.44it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2083/5184 [03:19<04:56, 10.45it/s, v_num=0, train_loss=0.0725]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2087/5184 [03:19<04:55, 10.47it/s, v_num=0, train_loss=0.0604]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2091/5184 [03:19<04:55, 10.48it/s, v_num=0, train_loss=0.0478]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2095/5184 [03:19<04:54, 10.50it/s, v_num=0, train_loss=0.0351]\n",
      "Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2099/5184 [03:19<04:53, 10.51it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2103/5184 [03:19<04:52, 10.52it/s, v_num=0, train_loss=0.0989]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2104/5184 [03:19<04:52, 10.53it/s, v_num=0, train_loss=0.0403]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2108/5184 [03:19<04:51, 10.54it/s, v_num=0, train_loss=0.0599]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2109/5184 [03:19<04:51, 10.55it/s, v_num=0, train_loss=0.0415]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2112/5184 [03:20<04:50, 10.56it/s, v_num=0, train_loss=0.070] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2113/5184 [03:24<04:56, 10.35it/s, v_num=0, train_loss=0.0477]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2114/5184 [03:24<04:56, 10.34it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2115/5184 [03:24<04:56, 10.34it/s, v_num=0, train_loss=0.0655]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2119/5184 [03:24<04:56, 10.35it/s, v_num=0, train_loss=0.0558]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2122/5184 [03:24<04:55, 10.36it/s, v_num=0, train_loss=0.0528]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2126/5184 [03:24<04:54, 10.38it/s, v_num=0, train_loss=0.0917]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2130/5184 [03:24<04:53, 10.39it/s, v_num=0, train_loss=0.099] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2131/5184 [03:25<04:53, 10.39it/s, v_num=0, train_loss=0.054]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2134/5184 [03:25<04:53, 10.40it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2135/5184 [03:25<04:52, 10.41it/s, v_num=0, train_loss=0.0561]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2139/5184 [03:25<04:52, 10.42it/s, v_num=0, train_loss=0.058] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2143/5184 [03:25<04:51, 10.43it/s, v_num=0, train_loss=0.060] \n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2146/5184 [03:25<04:50, 10.44it/s, v_num=0, train_loss=0.0736]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2147/5184 [03:25<04:50, 10.45it/s, v_num=0, train_loss=0.0454]\n",
      "Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2151/5184 [03:25<04:49, 10.46it/s, v_num=0, train_loss=0.0927]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2155/5184 [03:25<04:49, 10.48it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2156/5184 [03:25<04:48, 10.48it/s, v_num=0, train_loss=0.0948]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2160/5184 [03:25<04:48, 10.49it/s, v_num=0, train_loss=0.0525]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2164/5184 [03:25<04:47, 10.51it/s, v_num=0, train_loss=0.0576]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2168/5184 [03:26<04:46, 10.52it/s, v_num=0, train_loss=0.0706]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2169/5184 [03:26<04:46, 10.52it/s, v_num=0, train_loss=0.0582]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2173/5184 [03:26<04:45, 10.54it/s, v_num=0, train_loss=0.0848]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2176/5184 [03:26<04:45, 10.55it/s, v_num=0, train_loss=0.0198]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2178/5184 [03:30<04:50, 10.34it/s, v_num=0, train_loss=0.0908]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2180/5184 [03:30<04:50, 10.34it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2184/5184 [03:30<04:49, 10.36it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2188/5184 [03:30<04:48, 10.37it/s, v_num=0, train_loss=0.0814]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2192/5184 [03:31<04:48, 10.38it/s, v_num=0, train_loss=0.0773]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2193/5184 [03:31<04:47, 10.39it/s, v_num=0, train_loss=0.0492]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2197/5184 [03:31<04:47, 10.40it/s, v_num=0, train_loss=0.0956]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2200/5184 [03:31<04:46, 10.41it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2201/5184 [03:31<04:46, 10.41it/s, v_num=0, train_loss=0.0392]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2204/5184 [03:31<04:45, 10.42it/s, v_num=0, train_loss=0.0507]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2205/5184 [03:31<04:45, 10.43it/s, v_num=0, train_loss=0.0642]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2208/5184 [03:31<04:45, 10.44it/s, v_num=0, train_loss=0.0454]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2209/5184 [03:31<04:44, 10.44it/s, v_num=0, train_loss=0.0459]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2212/5184 [03:31<04:44, 10.45it/s, v_num=0, train_loss=0.0834]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2213/5184 [03:31<04:44, 10.45it/s, v_num=0, train_loss=0.0441]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2217/5184 [03:31<04:43, 10.47it/s, v_num=0, train_loss=0.0408]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2221/5184 [03:31<04:42, 10.48it/s, v_num=0, train_loss=0.0801]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2224/5184 [03:32<04:42, 10.49it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2225/5184 [03:32<04:42, 10.49it/s, v_num=0, train_loss=0.0824]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2229/5184 [03:32<04:41, 10.51it/s, v_num=0, train_loss=0.0529]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2233/5184 [03:32<04:40, 10.52it/s, v_num=0, train_loss=0.0825]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2234/5184 [03:32<04:40, 10.52it/s, v_num=0, train_loss=0.036] \n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2238/5184 [03:32<04:39, 10.54it/s, v_num=0, train_loss=0.0634]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2240/5184 [03:32<04:39, 10.54it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2243/5184 [03:37<04:45, 10.32it/s, v_num=0, train_loss=0.0547]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2246/5184 [03:37<04:44, 10.33it/s, v_num=0, train_loss=0.0479]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2250/5184 [03:37<04:43, 10.34it/s, v_num=0, train_loss=0.0595]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2253/5184 [03:37<04:43, 10.35it/s, v_num=0, train_loss=0.0435]\n",
      "Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2254/5184 [03:37<04:43, 10.35it/s, v_num=0, train_loss=0.0494]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2258/5184 [03:37<04:42, 10.37it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2262/5184 [03:37<04:41, 10.38it/s, v_num=0, train_loss=0.0646]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2266/5184 [03:38<04:40, 10.39it/s, v_num=0, train_loss=0.0771]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2270/5184 [03:38<04:40, 10.40it/s, v_num=0, train_loss=0.0683]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2274/5184 [03:38<04:39, 10.42it/s, v_num=0, train_loss=0.0312]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2277/5184 [03:38<04:38, 10.43it/s, v_num=0, train_loss=0.0362]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2281/5184 [03:38<04:38, 10.44it/s, v_num=0, train_loss=0.0239]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2285/5184 [03:38<04:37, 10.45it/s, v_num=0, train_loss=0.0386]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2289/5184 [03:38<04:36, 10.46it/s, v_num=0, train_loss=0.0384]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2290/5184 [03:38<04:36, 10.47it/s, v_num=0, train_loss=0.0429]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2294/5184 [03:38<04:35, 10.48it/s, v_num=0, train_loss=0.0508]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2298/5184 [03:38<04:35, 10.49it/s, v_num=0, train_loss=0.0843]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2302/5184 [03:39<04:34, 10.51it/s, v_num=0, train_loss=0.0574]\n",
      "Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2304/5184 [03:39<04:33, 10.51it/s, v_num=0, train_loss=0.0469]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2307/5184 [03:43<04:38, 10.32it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2311/5184 [03:43<04:37, 10.34it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2315/5184 [03:43<04:37, 10.35it/s, v_num=0, train_loss=0.0604]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2316/5184 [03:43<04:37, 10.35it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2319/5184 [03:43<04:36, 10.36it/s, v_num=0, train_loss=0.0478]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2320/5184 [03:43<04:36, 10.36it/s, v_num=0, train_loss=0.042] \n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2324/5184 [03:43<04:35, 10.38it/s, v_num=0, train_loss=0.049] \n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2328/5184 [03:44<04:34, 10.39it/s, v_num=0, train_loss=0.053] \n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2332/5184 [03:44<04:34, 10.40it/s, v_num=0, train_loss=0.0575]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2333/5184 [03:44<04:33, 10.41it/s, v_num=0, train_loss=0.0509]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2337/5184 [03:44<04:33, 10.42it/s, v_num=0, train_loss=0.0651]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2341/5184 [03:44<04:32, 10.43it/s, v_num=0, train_loss=0.0689]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2345/5184 [03:44<04:31, 10.44it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2349/5184 [03:44<04:31, 10.46it/s, v_num=0, train_loss=0.0429]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2352/5184 [03:44<04:30, 10.47it/s, v_num=0, train_loss=0.0328]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2353/5184 [03:44<04:30, 10.47it/s, v_num=0, train_loss=0.0549]\n",
      "Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2357/5184 [03:44<04:29, 10.48it/s, v_num=0, train_loss=0.0411]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2361/5184 [03:45<04:29, 10.49it/s, v_num=0, train_loss=0.0317]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2365/5184 [03:45<04:28, 10.51it/s, v_num=0, train_loss=0.0684]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2368/5184 [03:45<04:27, 10.52it/s, v_num=0, train_loss=0.059] \n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2369/5184 [03:49<04:32, 10.33it/s, v_num=0, train_loss=0.0912]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2373/5184 [03:49<04:31, 10.34it/s, v_num=0, train_loss=0.0894]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2378/5184 [03:49<04:30, 10.36it/s, v_num=0, train_loss=0.0555]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2382/5184 [03:49<04:30, 10.37it/s, v_num=0, train_loss=0.0795]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2383/5184 [03:49<04:30, 10.37it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2387/5184 [03:49<04:29, 10.38it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2388/5184 [03:49<04:29, 10.39it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2392/5184 [03:49<04:28, 10.40it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2396/5184 [03:50<04:27, 10.41it/s, v_num=0, train_loss=0.0998]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2397/5184 [03:50<04:27, 10.42it/s, v_num=0, train_loss=0.0585]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2401/5184 [03:50<04:26, 10.43it/s, v_num=0, train_loss=0.0658]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2405/5184 [03:50<04:26, 10.44it/s, v_num=0, train_loss=0.0543]\n",
      "Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2406/5184 [03:50<04:25, 10.44it/s, v_num=0, train_loss=0.0707]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2411/5184 [03:50<04:25, 10.46it/s, v_num=0, train_loss=0.160] \n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2415/5184 [03:50<04:24, 10.47it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2416/5184 [03:50<04:24, 10.48it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2420/5184 [03:50<04:23, 10.49it/s, v_num=0, train_loss=0.0987]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2425/5184 [03:50<04:22, 10.51it/s, v_num=0, train_loss=0.0715]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2430/5184 [03:50<04:21, 10.52it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2432/5184 [03:50<04:21, 10.53it/s, v_num=0, train_loss=0.0954]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2433/5184 [03:54<04:25, 10.38it/s, v_num=0, train_loss=0.0919]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2436/5184 [03:55<04:25, 10.36it/s, v_num=0, train_loss=0.0691]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2440/5184 [03:55<04:24, 10.38it/s, v_num=0, train_loss=0.0867]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2445/5184 [03:55<04:23, 10.39it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2450/5184 [03:55<04:22, 10.41it/s, v_num=0, train_loss=0.0577]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2454/5184 [03:55<04:21, 10.42it/s, v_num=0, train_loss=0.0746]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2458/5184 [03:55<04:21, 10.43it/s, v_num=0, train_loss=0.0731]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2459/5184 [03:55<04:21, 10.44it/s, v_num=0, train_loss=0.0815]\n",
      "Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2462/5184 [03:55<04:20, 10.45it/s, v_num=0, train_loss=0.0783]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2463/5184 [03:55<04:20, 10.45it/s, v_num=0, train_loss=0.126] \n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2466/5184 [03:55<04:19, 10.46it/s, v_num=0, train_loss=0.072] \n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2467/5184 [03:55<04:19, 10.46it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2471/5184 [03:55<04:19, 10.47it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2475/5184 [03:56<04:18, 10.48it/s, v_num=0, train_loss=0.0616]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2478/5184 [03:56<04:17, 10.49it/s, v_num=0, train_loss=0.0603]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2479/5184 [03:56<04:17, 10.50it/s, v_num=0, train_loss=0.0681]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2483/5184 [03:56<04:17, 10.51it/s, v_num=0, train_loss=0.0907]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2484/5184 [03:56<04:16, 10.51it/s, v_num=0, train_loss=0.0939]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2489/5184 [03:56<04:16, 10.53it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2493/5184 [03:56<04:15, 10.54it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2494/5184 [03:56<04:15, 10.54it/s, v_num=0, train_loss=0.0648]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2496/5184 [03:56<04:14, 10.55it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2500/5184 [04:00<04:18, 10.39it/s, v_num=0, train_loss=0.0999]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2501/5184 [04:00<04:18, 10.40it/s, v_num=0, train_loss=0.0903]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2506/5184 [04:00<04:17, 10.41it/s, v_num=0, train_loss=0.0964]\n",
      "Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2510/5184 [04:00<04:16, 10.42it/s, v_num=0, train_loss=0.0946]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2515/5184 [04:00<04:15, 10.44it/s, v_num=0, train_loss=0.0732]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2519/5184 [04:00<04:14, 10.45it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2524/5184 [04:01<04:14, 10.47it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2529/5184 [04:01<04:13, 10.48it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2534/5184 [04:01<04:12, 10.50it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2538/5184 [04:01<04:11, 10.51it/s, v_num=0, train_loss=0.0731]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2539/5184 [04:01<04:11, 10.51it/s, v_num=0, train_loss=0.193] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2543/5184 [04:01<04:10, 10.53it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2547/5184 [04:01<04:10, 10.54it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2552/5184 [04:01<04:09, 10.55it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2557/5184 [04:01<04:08, 10.57it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2560/5184 [04:01<04:08, 10.58it/s, v_num=0, train_loss=0.0938]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2561/5184 [04:05<04:11, 10.42it/s, v_num=0, train_loss=0.0879]\n",
      "Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2565/5184 [04:06<04:11, 10.42it/s, v_num=0, train_loss=0.0491]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2569/5184 [04:06<04:10, 10.44it/s, v_num=0, train_loss=0.0998]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2570/5184 [04:06<04:10, 10.44it/s, v_num=0, train_loss=0.0832]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2574/5184 [04:06<04:09, 10.45it/s, v_num=0, train_loss=0.0863]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2578/5184 [04:06<04:09, 10.46it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2579/5184 [04:06<04:08, 10.46it/s, v_num=0, train_loss=0.0654]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2583/5184 [04:06<04:08, 10.48it/s, v_num=0, train_loss=0.0539]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2587/5184 [04:06<04:07, 10.49it/s, v_num=0, train_loss=0.0426]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2591/5184 [04:06<04:06, 10.50it/s, v_num=0, train_loss=0.0704]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2595/5184 [04:06<04:06, 10.51it/s, v_num=0, train_loss=0.049] \n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2596/5184 [04:06<04:06, 10.51it/s, v_num=0, train_loss=0.0862]\n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2600/5184 [04:07<04:05, 10.53it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2604/5184 [04:07<04:04, 10.54it/s, v_num=0, train_loss=0.083] \n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2609/5184 [04:07<04:04, 10.55it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2613/5184 [04:07<04:03, 10.56it/s, v_num=0, train_loss=0.0672]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2618/5184 [04:07<04:02, 10.58it/s, v_num=0, train_loss=0.0835]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2623/5184 [04:07<04:01, 10.59it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2624/5184 [04:07<04:01, 10.60it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2627/5184 [04:11<04:05, 10.43it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2628/5184 [04:11<04:04, 10.43it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2632/5184 [04:11<04:04, 10.45it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2637/5184 [04:12<04:03, 10.46it/s, v_num=0, train_loss=0.0853]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2641/5184 [04:12<04:02, 10.47it/s, v_num=0, train_loss=0.0594]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2646/5184 [04:12<04:02, 10.49it/s, v_num=0, train_loss=0.0766]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2650/5184 [04:12<04:01, 10.50it/s, v_num=0, train_loss=0.0706]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2654/5184 [04:12<04:00, 10.51it/s, v_num=0, train_loss=0.0786]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2655/5184 [04:12<04:00, 10.51it/s, v_num=0, train_loss=0.0597]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2659/5184 [04:12<03:59, 10.52it/s, v_num=0, train_loss=0.0567]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2663/5184 [04:12<03:59, 10.53it/s, v_num=0, train_loss=0.0734]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2667/5184 [04:12<03:58, 10.55it/s, v_num=0, train_loss=0.0736]\n",
      "Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2668/5184 [04:12<03:58, 10.55it/s, v_num=0, train_loss=0.193] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2672/5184 [04:13<03:57, 10.56it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2676/5184 [04:13<03:57, 10.57it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2681/5184 [04:13<03:56, 10.59it/s, v_num=0, train_loss=0.0581]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2685/5184 [04:13<03:55, 10.60it/s, v_num=0, train_loss=0.0849]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2688/5184 [04:13<03:55, 10.61it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2689/5184 [04:17<03:58, 10.45it/s, v_num=0, train_loss=0.0809]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2690/5184 [04:17<03:58, 10.45it/s, v_num=0, train_loss=0.0694]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2692/5184 [04:17<03:58, 10.45it/s, v_num=0, train_loss=0.0465]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2696/5184 [04:17<03:57, 10.47it/s, v_num=0, train_loss=0.0517]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2700/5184 [04:17<03:57, 10.48it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2701/5184 [04:17<03:56, 10.48it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2706/5184 [04:17<03:56, 10.49it/s, v_num=0, train_loss=0.190]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2710/5184 [04:17<03:55, 10.51it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2711/5184 [04:17<03:55, 10.51it/s, v_num=0, train_loss=0.0821]\n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2715/5184 [04:18<03:54, 10.52it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2719/5184 [04:18<03:54, 10.53it/s, v_num=0, train_loss=0.0941]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2723/5184 [04:18<03:53, 10.54it/s, v_num=0, train_loss=0.0823]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2727/5184 [04:18<03:52, 10.55it/s, v_num=0, train_loss=0.0721]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2731/5184 [04:18<03:52, 10.56it/s, v_num=0, train_loss=0.0735]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2735/5184 [04:18<03:51, 10.58it/s, v_num=0, train_loss=0.0401]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2736/5184 [04:18<03:51, 10.58it/s, v_num=0, train_loss=0.0697]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2740/5184 [04:18<03:50, 10.59it/s, v_num=0, train_loss=0.0856]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2741/5184 [04:18<03:50, 10.59it/s, v_num=0, train_loss=0.0462]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2745/5184 [04:18<03:50, 10.60it/s, v_num=0, train_loss=0.0964]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2750/5184 [04:18<03:49, 10.62it/s, v_num=0, train_loss=0.0691]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2752/5184 [04:19<03:48, 10.62it/s, v_num=0, train_loss=0.0868]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2755/5184 [04:23<03:52, 10.46it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2759/5184 [04:23<03:51, 10.47it/s, v_num=0, train_loss=0.0974]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2763/5184 [04:23<03:50, 10.48it/s, v_num=0, train_loss=0.0918]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2764/5184 [04:23<03:50, 10.49it/s, v_num=0, train_loss=0.0388]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2768/5184 [04:23<03:50, 10.50it/s, v_num=0, train_loss=0.0783]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2772/5184 [04:23<03:49, 10.51it/s, v_num=0, train_loss=0.0475]\n",
      "Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2773/5184 [04:23<03:49, 10.51it/s, v_num=0, train_loss=0.093] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2777/5184 [04:23<03:48, 10.52it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2781/5184 [04:24<03:48, 10.53it/s, v_num=0, train_loss=0.0458]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2785/5184 [04:24<03:47, 10.54it/s, v_num=0, train_loss=0.0914]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2786/5184 [04:24<03:47, 10.55it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2790/5184 [04:24<03:46, 10.56it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2791/5184 [04:24<03:46, 10.56it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2791/5184 [04:24<03:46, 10.56it/s, v_num=0, train_loss=0.0982]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2795/5184 [04:24<03:46, 10.57it/s, v_num=0, train_loss=0.0626]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2799/5184 [04:24<03:45, 10.58it/s, v_num=0, train_loss=0.0481]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2804/5184 [04:24<03:44, 10.59it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2808/5184 [04:24<03:44, 10.61it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2812/5184 [04:24<03:43, 10.62it/s, v_num=0, train_loss=0.0716]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2816/5184 [04:24<03:42, 10.63it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2817/5184 [04:29<03:46, 10.47it/s, v_num=0, train_loss=0.075]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2821/5184 [04:29<03:45, 10.47it/s, v_num=0, train_loss=0.0721]\n",
      "Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2825/5184 [04:29<03:45, 10.48it/s, v_num=0, train_loss=0.0765]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2826/5184 [04:29<03:44, 10.48it/s, v_num=0, train_loss=0.0552]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2830/5184 [04:29<03:44, 10.49it/s, v_num=0, train_loss=0.0705]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2834/5184 [04:29<03:43, 10.50it/s, v_num=0, train_loss=0.0482]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2838/5184 [04:29<03:43, 10.51it/s, v_num=0, train_loss=0.0462]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2842/5184 [04:30<03:42, 10.52it/s, v_num=0, train_loss=0.0713]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2846/5184 [04:30<03:41, 10.53it/s, v_num=0, train_loss=0.0524]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2850/5184 [04:30<03:41, 10.54it/s, v_num=0, train_loss=0.0938]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2854/5184 [04:30<03:40, 10.55it/s, v_num=0, train_loss=0.034] \n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2858/5184 [04:30<03:40, 10.57it/s, v_num=0, train_loss=0.0698]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2862/5184 [04:30<03:39, 10.58it/s, v_num=0, train_loss=0.0796]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2867/5184 [04:30<03:38, 10.59it/s, v_num=0, train_loss=0.0711]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2871/5184 [04:30<03:38, 10.60it/s, v_num=0, train_loss=0.0583]\n",
      "Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2875/5184 [04:30<03:37, 10.61it/s, v_num=0, train_loss=0.0941]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2879/5184 [04:31<03:37, 10.62it/s, v_num=0, train_loss=0.0787]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2880/5184 [04:31<03:36, 10.62it/s, v_num=0, train_loss=0.0716]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2882/5184 [04:35<03:40, 10.46it/s, v_num=0, train_loss=0.0602]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2885/5184 [04:35<03:39, 10.47it/s, v_num=0, train_loss=0.0884]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2886/5184 [04:35<03:39, 10.47it/s, v_num=0, train_loss=0.075] \n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2890/5184 [04:35<03:38, 10.48it/s, v_num=0, train_loss=0.095] \n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2894/5184 [04:35<03:38, 10.49it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2898/5184 [04:35<03:37, 10.50it/s, v_num=0, train_loss=0.0731]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2902/5184 [04:36<03:37, 10.51it/s, v_num=0, train_loss=0.0456]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2906/5184 [04:36<03:36, 10.52it/s, v_num=0, train_loss=0.0882]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2910/5184 [04:36<03:35, 10.53it/s, v_num=0, train_loss=0.0647]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2914/5184 [04:36<03:35, 10.54it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2915/5184 [04:36<03:35, 10.55it/s, v_num=0, train_loss=0.0613]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2919/5184 [04:36<03:34, 10.56it/s, v_num=0, train_loss=0.0621]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2923/5184 [04:36<03:33, 10.57it/s, v_num=0, train_loss=0.0732]\n",
      "Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2927/5184 [04:36<03:33, 10.58it/s, v_num=0, train_loss=0.069] \n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2932/5184 [04:36<03:32, 10.59it/s, v_num=0, train_loss=0.088] \n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2936/5184 [04:36<03:32, 10.60it/s, v_num=0, train_loss=0.0566]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2941/5184 [04:37<03:31, 10.61it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2944/5184 [04:37<03:30, 10.62it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2945/5184 [04:40<03:33, 10.50it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2947/5184 [04:40<03:33, 10.49it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2948/5184 [04:40<03:33, 10.49it/s, v_num=0, train_loss=0.161]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2953/5184 [04:41<03:32, 10.51it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2957/5184 [04:41<03:31, 10.52it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2958/5184 [04:41<03:31, 10.52it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2962/5184 [04:41<03:30, 10.53it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2963/5184 [04:41<03:30, 10.53it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2968/5184 [04:41<03:30, 10.55it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2972/5184 [04:41<03:29, 10.56it/s, v_num=0, train_loss=0.137]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2973/5184 [04:41<03:29, 10.56it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2977/5184 [04:41<03:28, 10.57it/s, v_num=0, train_loss=0.215]\n",
      "Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2978/5184 [04:41<03:28, 10.57it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2983/5184 [04:41<03:27, 10.59it/s, v_num=0, train_loss=0.195] \n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2987/5184 [04:41<03:27, 10.60it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2991/5184 [04:41<03:26, 10.61it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2995/5184 [04:42<03:26, 10.62it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2996/5184 [04:42<03:26, 10.62it/s, v_num=0, train_loss=0.146]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3001/5184 [04:42<03:25, 10.63it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3006/5184 [04:42<03:24, 10.65it/s, v_num=0, train_loss=0.0908]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3008/5184 [04:42<03:24, 10.65it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3009/5184 [04:46<03:27, 10.49it/s, v_num=0, train_loss=0.0929]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3012/5184 [04:47<03:26, 10.49it/s, v_num=0, train_loss=0.0987]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3016/5184 [04:47<03:26, 10.50it/s, v_num=0, train_loss=0.0661]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3021/5184 [04:47<03:25, 10.52it/s, v_num=0, train_loss=0.0652]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3025/5184 [04:47<03:25, 10.53it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3026/5184 [04:47<03:24, 10.53it/s, v_num=0, train_loss=0.0956]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3030/5184 [04:47<03:24, 10.54it/s, v_num=0, train_loss=0.0885]\n",
      "Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3031/5184 [04:47<03:24, 10.54it/s, v_num=0, train_loss=0.0451]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3035/5184 [04:47<03:23, 10.55it/s, v_num=0, train_loss=0.0791]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3036/5184 [04:47<03:23, 10.56it/s, v_num=0, train_loss=0.0968]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3040/5184 [04:47<03:22, 10.57it/s, v_num=0, train_loss=0.075] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3044/5184 [04:47<03:22, 10.58it/s, v_num=0, train_loss=0.0928]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3045/5184 [04:47<03:22, 10.58it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3049/5184 [04:47<03:21, 10.59it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3052/5184 [04:48<03:21, 10.60it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3053/5184 [04:48<03:21, 10.60it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3057/5184 [04:48<03:20, 10.61it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3062/5184 [04:48<03:19, 10.62it/s, v_num=0, train_loss=0.0984]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3067/5184 [04:48<03:19, 10.63it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3072/5184 [04:48<03:18, 10.65it/s, v_num=0, train_loss=0.0441]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3073/5184 [04:52<03:20, 10.52it/s, v_num=0, train_loss=0.0829]\n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3076/5184 [04:52<03:20, 10.52it/s, v_num=0, train_loss=0.203] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3080/5184 [04:52<03:19, 10.53it/s, v_num=0, train_loss=0.155] \n",
      "Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3081/5184 [04:52<03:19, 10.53it/s, v_num=0, train_loss=0.0645]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3085/5184 [04:52<03:19, 10.54it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3089/5184 [04:52<03:18, 10.55it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3090/5184 [04:52<03:18, 10.56it/s, v_num=0, train_loss=0.0787]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3094/5184 [04:52<03:17, 10.57it/s, v_num=0, train_loss=0.072] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3095/5184 [04:52<03:17, 10.57it/s, v_num=0, train_loss=0.0672]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3098/5184 [04:52<03:17, 10.58it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3102/5184 [04:53<03:16, 10.58it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3103/5184 [04:53<03:16, 10.59it/s, v_num=0, train_loss=0.0772]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3107/5184 [04:53<03:15, 10.60it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3108/5184 [04:53<03:15, 10.60it/s, v_num=0, train_loss=0.219]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3112/5184 [04:53<03:15, 10.61it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3117/5184 [04:53<03:14, 10.62it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3121/5184 [04:53<03:14, 10.63it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3122/5184 [04:53<03:13, 10.63it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3126/5184 [04:53<03:13, 10.64it/s, v_num=0, train_loss=0.128]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3127/5184 [04:53<03:13, 10.65it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3132/5184 [04:53<03:12, 10.66it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3136/5184 [04:53<03:11, 10.67it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3138/5184 [04:57<03:14, 10.54it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3139/5184 [04:57<03:14, 10.54it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3143/5184 [04:57<03:13, 10.55it/s, v_num=0, train_loss=0.157] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3147/5184 [04:58<03:12, 10.56it/s, v_num=0, train_loss=0.0496]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3150/5184 [04:58<03:12, 10.57it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3151/5184 [04:58<03:12, 10.57it/s, v_num=0, train_loss=0.090]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3155/5184 [04:58<03:11, 10.58it/s, v_num=0, train_loss=0.096]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3156/5184 [04:58<03:11, 10.58it/s, v_num=0, train_loss=0.096]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3156/5184 [04:58<03:11, 10.58it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3160/5184 [04:58<03:11, 10.59it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3165/5184 [04:58<03:10, 10.60it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3169/5184 [04:58<03:09, 10.61it/s, v_num=0, train_loss=0.0959]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3170/5184 [04:58<03:09, 10.61it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3174/5184 [04:58<03:09, 10.62it/s, v_num=0, train_loss=0.082] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3179/5184 [04:58<03:08, 10.64it/s, v_num=0, train_loss=0.062] \n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3183/5184 [04:58<03:07, 10.65it/s, v_num=0, train_loss=0.0756]\n",
      "Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3184/5184 [04:59<03:07, 10.65it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3189/5184 [04:59<03:07, 10.66it/s, v_num=0, train_loss=0.115] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3193/5184 [04:59<03:06, 10.67it/s, v_num=0, train_loss=0.0912]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3194/5184 [04:59<03:06, 10.67it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3198/5184 [04:59<03:05, 10.68it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3199/5184 [04:59<03:05, 10.69it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3200/5184 [04:59<03:05, 10.69it/s, v_num=0, train_loss=0.0928]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3201/5184 [05:03<03:07, 10.56it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3205/5184 [05:03<03:07, 10.57it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3206/5184 [05:03<03:07, 10.57it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3210/5184 [05:03<03:06, 10.58it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3214/5184 [05:03<03:06, 10.59it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3219/5184 [05:03<03:05, 10.60it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3224/5184 [05:03<03:04, 10.61it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3228/5184 [05:03<03:04, 10.62it/s, v_num=0, train_loss=0.0881]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3229/5184 [05:03<03:04, 10.62it/s, v_num=0, train_loss=0.0736]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3233/5184 [05:04<03:03, 10.63it/s, v_num=0, train_loss=0.0663]\n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3234/5184 [05:04<03:03, 10.63it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3238/5184 [05:04<03:02, 10.64it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3243/5184 [05:04<03:02, 10.66it/s, v_num=0, train_loss=0.0949]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3247/5184 [05:04<03:01, 10.67it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3252/5184 [05:04<03:00, 10.68it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3253/5184 [05:04<03:00, 10.68it/s, v_num=0, train_loss=0.0858]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3257/5184 [05:04<03:00, 10.69it/s, v_num=0, train_loss=0.0763]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3261/5184 [05:04<02:59, 10.70it/s, v_num=0, train_loss=0.0923]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3262/5184 [05:04<02:59, 10.70it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3264/5184 [05:04<02:59, 10.71it/s, v_num=0, train_loss=0.0764]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3266/5184 [05:08<03:01, 10.58it/s, v_num=0, train_loss=0.089] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3267/5184 [05:08<03:01, 10.58it/s, v_num=0, train_loss=0.0854]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3271/5184 [05:08<03:00, 10.59it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3276/5184 [05:08<02:59, 10.60it/s, v_num=0, train_loss=0.0971]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3281/5184 [05:09<02:59, 10.62it/s, v_num=0, train_loss=0.099] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3285/5184 [05:09<02:58, 10.63it/s, v_num=0, train_loss=0.0743]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3286/5184 [05:09<02:58, 10.63it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3290/5184 [05:09<02:58, 10.64it/s, v_num=0, train_loss=0.0896]\n",
      "Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3291/5184 [05:09<02:57, 10.64it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3295/5184 [05:09<02:57, 10.65it/s, v_num=0, train_loss=0.0739]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3296/5184 [05:09<02:57, 10.65it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3300/5184 [05:09<02:56, 10.66it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3304/5184 [05:09<02:56, 10.67it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3305/5184 [05:09<02:56, 10.67it/s, v_num=0, train_loss=0.0795]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3309/5184 [05:09<02:55, 10.68it/s, v_num=0, train_loss=0.0463]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3310/5184 [05:09<02:55, 10.69it/s, v_num=0, train_loss=0.0983]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3315/5184 [05:09<02:54, 10.70it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3319/5184 [05:09<02:54, 10.71it/s, v_num=0, train_loss=0.0793]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3324/5184 [05:10<02:53, 10.72it/s, v_num=0, train_loss=0.165] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3328/5184 [05:10<02:53, 10.73it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3331/5184 [05:14<02:54, 10.61it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3332/5184 [05:14<02:54, 10.61it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3336/5184 [05:14<02:54, 10.62it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3341/5184 [05:14<02:53, 10.63it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3346/5184 [05:14<02:52, 10.64it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3350/5184 [05:14<02:52, 10.65it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3351/5184 [05:14<02:52, 10.65it/s, v_num=0, train_loss=0.0624]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3355/5184 [05:14<02:51, 10.66it/s, v_num=0, train_loss=0.0849]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3356/5184 [05:14<02:51, 10.67it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3360/5184 [05:14<02:50, 10.68it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3364/5184 [05:14<02:50, 10.68it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3365/5184 [05:14<02:50, 10.69it/s, v_num=0, train_loss=0.0652]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3369/5184 [05:14<02:49, 10.70it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3370/5184 [05:14<02:49, 10.70it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3374/5184 [05:15<02:49, 10.71it/s, v_num=0, train_loss=0.0635]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3379/5184 [05:15<02:48, 10.72it/s, v_num=0, train_loss=0.0535]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3384/5184 [05:15<02:47, 10.73it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3389/5184 [05:15<02:47, 10.74it/s, v_num=0, train_loss=0.0726]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3392/5184 [05:15<02:46, 10.75it/s, v_num=0, train_loss=0.158] \n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3393/5184 [05:19<02:48, 10.63it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3394/5184 [05:19<02:48, 10.63it/s, v_num=0, train_loss=0.0441]\n",
      "Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3395/5184 [05:19<02:48, 10.63it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3399/5184 [05:19<02:47, 10.63it/s, v_num=0, train_loss=0.0433]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3403/5184 [05:19<02:47, 10.64it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3407/5184 [05:19<02:46, 10.65it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3408/5184 [05:19<02:46, 10.65it/s, v_num=0, train_loss=0.0442]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3412/5184 [05:19<02:46, 10.66it/s, v_num=0, train_loss=0.0682]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3413/5184 [05:20<02:46, 10.67it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3417/5184 [05:20<02:45, 10.67it/s, v_num=0, train_loss=0.094]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3418/5184 [05:20<02:45, 10.68it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3422/5184 [05:20<02:44, 10.69it/s, v_num=0, train_loss=0.180] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3426/5184 [05:20<02:44, 10.69it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3431/5184 [05:20<02:43, 10.71it/s, v_num=0, train_loss=0.0966]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3435/5184 [05:20<02:43, 10.72it/s, v_num=0, train_loss=0.0957]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3436/5184 [05:20<02:43, 10.72it/s, v_num=0, train_loss=0.0934]\n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3440/5184 [05:20<02:42, 10.73it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3445/5184 [05:20<02:41, 10.74it/s, v_num=0, train_loss=0.0541]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3449/5184 [05:20<02:41, 10.75it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3450/5184 [05:20<02:41, 10.75it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3454/5184 [05:21<02:40, 10.76it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3455/5184 [05:21<02:40, 10.76it/s, v_num=0, train_loss=0.0875]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3456/5184 [05:21<02:40, 10.76it/s, v_num=0, train_loss=0.062] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3457/5184 [05:24<02:42, 10.64it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3458/5184 [05:24<02:42, 10.64it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3463/5184 [05:24<02:41, 10.66it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3468/5184 [05:25<02:40, 10.67it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3472/5184 [05:25<02:40, 10.68it/s, v_num=0, train_loss=0.170] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3473/5184 [05:25<02:40, 10.68it/s, v_num=0, train_loss=0.0668]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3477/5184 [05:25<02:39, 10.69it/s, v_num=0, train_loss=0.0654]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3478/5184 [05:25<02:39, 10.69it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3482/5184 [05:25<02:39, 10.70it/s, v_num=0, train_loss=0.0916]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3483/5184 [05:25<02:38, 10.70it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3488/5184 [05:25<02:38, 10.71it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3493/5184 [05:25<02:37, 10.72it/s, v_num=0, train_loss=0.0593]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3497/5184 [05:25<02:37, 10.73it/s, v_num=0, train_loss=0.0738]\n",
      "Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3498/5184 [05:25<02:37, 10.74it/s, v_num=0, train_loss=0.216] \n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3502/5184 [05:25<02:36, 10.74it/s, v_num=0, train_loss=0.220] \n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3503/5184 [05:25<02:36, 10.75it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3507/5184 [05:26<02:35, 10.76it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3508/5184 [05:26<02:35, 10.76it/s, v_num=0, train_loss=0.192]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3513/5184 [05:26<02:35, 10.77it/s, v_num=0, train_loss=0.0742]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3518/5184 [05:26<02:34, 10.78it/s, v_num=0, train_loss=0.117] \n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3520/5184 [05:26<02:34, 10.79it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3521/5184 [05:29<02:35, 10.69it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3526/5184 [05:29<02:34, 10.70it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3527/5184 [05:29<02:34, 10.70it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3527/5184 [05:29<02:34, 10.70it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3532/5184 [05:29<02:34, 10.71it/s, v_num=0, train_loss=0.073]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3537/5184 [05:29<02:33, 10.72it/s, v_num=0, train_loss=0.159] \n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3542/5184 [05:29<02:32, 10.74it/s, v_num=0, train_loss=0.100]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3546/5184 [05:30<02:32, 10.74it/s, v_num=0, train_loss=0.0776]\n",
      "Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3551/5184 [05:30<02:31, 10.75it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3556/5184 [05:30<02:31, 10.77it/s, v_num=0, train_loss=0.0907]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 3560/5184 [05:30<02:30, 10.77it/s, v_num=0, train_loss=0.0676]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3565/5184 [05:30<02:30, 10.79it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3570/5184 [05:30<02:29, 10.80it/s, v_num=0, train_loss=0.081]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3570/5184 [05:30<02:29, 10.80it/s, v_num=0, train_loss=0.180]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3575/5184 [05:30<02:28, 10.81it/s, v_num=0, train_loss=0.162]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3580/5184 [05:30<02:28, 10.82it/s, v_num=0, train_loss=0.203] \n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3584/5184 [05:30<02:27, 10.83it/s, v_num=0, train_loss=0.229]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3585/5184 [05:34<02:29, 10.73it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3587/5184 [05:34<02:28, 10.73it/s, v_num=0, train_loss=0.246]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3591/5184 [05:34<02:28, 10.73it/s, v_num=0, train_loss=0.218]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3595/5184 [05:34<02:27, 10.74it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3600/5184 [05:34<02:27, 10.75it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3601/5184 [05:34<02:27, 10.76it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3605/5184 [05:34<02:26, 10.76it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3606/5184 [05:34<02:26, 10.77it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3610/5184 [05:35<02:26, 10.78it/s, v_num=0, train_loss=0.0996]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3615/5184 [05:35<02:25, 10.79it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3616/5184 [05:35<02:25, 10.79it/s, v_num=0, train_loss=0.0945]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3621/5184 [05:35<02:24, 10.80it/s, v_num=0, train_loss=0.143] \n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3625/5184 [05:35<02:24, 10.81it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 3626/5184 [05:35<02:24, 10.81it/s, v_num=0, train_loss=0.0895]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3631/5184 [05:35<02:23, 10.82it/s, v_num=0, train_loss=0.169] \n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3636/5184 [05:35<02:22, 10.83it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3637/5184 [05:35<02:22, 10.84it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3642/5184 [05:35<02:22, 10.85it/s, v_num=0, train_loss=0.157]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3647/5184 [05:35<02:21, 10.86it/s, v_num=0, train_loss=0.231] \n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3648/5184 [05:35<02:21, 10.86it/s, v_num=0, train_loss=0.204]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3649/5184 [05:38<02:22, 10.78it/s, v_num=0, train_loss=0.199]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3651/5184 [05:38<02:22, 10.78it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3654/5184 [05:38<02:21, 10.78it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3655/5184 [05:38<02:21, 10.78it/s, v_num=0, train_loss=0.237]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3660/5184 [05:39<02:21, 10.79it/s, v_num=0, train_loss=0.0563]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3661/5184 [05:39<02:21, 10.80it/s, v_num=0, train_loss=0.0563]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3661/5184 [05:39<02:21, 10.80it/s, v_num=0, train_loss=0.148] \n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3666/5184 [05:39<02:20, 10.81it/s, v_num=0, train_loss=0.205]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3667/5184 [05:39<02:20, 10.81it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3672/5184 [05:39<02:19, 10.82it/s, v_num=0, train_loss=0.125]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3677/5184 [05:39<02:19, 10.83it/s, v_num=0, train_loss=0.195] \n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3682/5184 [05:39<02:18, 10.84it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3686/5184 [05:39<02:18, 10.85it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3687/5184 [05:39<02:17, 10.85it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3692/5184 [05:39<02:17, 10.87it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3697/5184 [05:39<02:16, 10.88it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3702/5184 [05:40<02:16, 10.89it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3707/5184 [05:40<02:15, 10.90it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3712/5184 [05:40<02:14, 10.91it/s, v_num=0, train_loss=0.173]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3716/5184 [05:43<02:15, 10.81it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3717/5184 [05:43<02:15, 10.81it/s, v_num=0, train_loss=0.169]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3722/5184 [05:44<02:15, 10.82it/s, v_num=0, train_loss=0.221]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3727/5184 [05:44<02:14, 10.83it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3728/5184 [05:44<02:14, 10.83it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3733/5184 [05:44<02:13, 10.84it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3738/5184 [05:44<02:13, 10.85it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3743/5184 [05:44<02:12, 10.87it/s, v_num=0, train_loss=0.212] \n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3744/5184 [05:44<02:12, 10.87it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3749/5184 [05:44<02:11, 10.88it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3754/5184 [05:44<02:11, 10.89it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3759/5184 [05:44<02:10, 10.90it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3765/5184 [05:44<02:10, 10.91it/s, v_num=0, train_loss=0.243]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3770/5184 [05:45<02:09, 10.92it/s, v_num=0, train_loss=0.0727]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3775/5184 [05:45<02:08, 10.94it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3776/5184 [05:45<02:08, 10.94it/s, v_num=0, train_loss=0.115]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3777/5184 [05:48<02:09, 10.85it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3779/5184 [05:48<02:09, 10.85it/s, v_num=0, train_loss=0.0764]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3783/5184 [05:48<02:09, 10.86it/s, v_num=0, train_loss=0.0724]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3788/5184 [05:48<02:08, 10.87it/s, v_num=0, train_loss=0.0599]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3793/5184 [05:48<02:07, 10.88it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3798/5184 [05:48<02:07, 10.89it/s, v_num=0, train_loss=0.0872]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3803/5184 [05:48<02:06, 10.90it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3807/5184 [05:49<02:06, 10.91it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3808/5184 [05:49<02:06, 10.91it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3813/5184 [05:49<02:05, 10.92it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3817/5184 [05:49<02:05, 10.93it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3818/5184 [05:49<02:04, 10.93it/s, v_num=0, train_loss=0.0982]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3822/5184 [05:49<02:04, 10.94it/s, v_num=0, train_loss=0.0909]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3823/5184 [05:49<02:04, 10.94it/s, v_num=0, train_loss=0.127] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3828/5184 [05:49<02:03, 10.95it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3833/5184 [05:49<02:03, 10.96it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3838/5184 [05:49<02:02, 10.97it/s, v_num=0, train_loss=0.106] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3840/5184 [05:49<02:02, 10.98it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3842/5184 [05:53<02:03, 10.86it/s, v_num=0, train_loss=0.159]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3843/5184 [05:53<02:03, 10.87it/s, v_num=0, train_loss=0.0961]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3847/5184 [05:53<02:02, 10.87it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3848/5184 [05:53<02:02, 10.88it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3852/5184 [05:53<02:02, 10.88it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3853/5184 [05:53<02:02, 10.89it/s, v_num=0, train_loss=0.101]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3857/5184 [05:54<02:01, 10.89it/s, v_num=0, train_loss=0.116]\n",
      "Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3862/5184 [05:54<02:01, 10.91it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3867/5184 [05:54<02:00, 10.92it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3872/5184 [05:54<02:00, 10.93it/s, v_num=0, train_loss=0.182] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3877/5184 [05:54<01:59, 10.94it/s, v_num=0, train_loss=0.167]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3882/5184 [05:54<01:58, 10.95it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3887/5184 [05:54<01:58, 10.96it/s, v_num=0, train_loss=0.137] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3892/5184 [05:54<01:57, 10.97it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3897/5184 [05:54<01:57, 10.98it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3901/5184 [05:55<01:56, 10.99it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3902/5184 [05:55<01:56, 10.99it/s, v_num=0, train_loss=0.0763]\n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3904/5184 [05:55<01:56, 10.99it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3907/5184 [05:58<01:57, 10.91it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3911/5184 [05:58<01:56, 10.92it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3915/5184 [05:58<01:56, 10.92it/s, v_num=0, train_loss=0.0648]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3920/5184 [05:58<01:55, 10.93it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3925/5184 [05:58<01:55, 10.95it/s, v_num=0, train_loss=0.0736]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3930/5184 [05:58<01:54, 10.96it/s, v_num=0, train_loss=0.0994]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3935/5184 [05:58<01:53, 10.97it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3940/5184 [05:58<01:53, 10.98it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3945/5184 [05:59<01:52, 10.99it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3946/5184 [05:59<01:52, 10.99it/s, v_num=0, train_loss=0.188]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3950/5184 [05:59<01:52, 11.00it/s, v_num=0, train_loss=0.0891]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3951/5184 [05:59<01:52, 11.00it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3956/5184 [05:59<01:51, 11.01it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3961/5184 [05:59<01:50, 11.02it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3962/5184 [05:59<01:50, 11.02it/s, v_num=0, train_loss=0.0969]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3967/5184 [05:59<01:50, 11.03it/s, v_num=0, train_loss=0.233] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3968/5184 [05:59<01:50, 11.03it/s, v_num=0, train_loss=0.0796]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3970/5184 [06:02<01:50, 10.94it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3973/5184 [06:03<01:50, 10.94it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3974/5184 [06:03<01:50, 10.94it/s, v_num=0, train_loss=0.208]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3979/5184 [06:03<01:50, 10.95it/s, v_num=0, train_loss=0.0734]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3984/5184 [06:03<01:49, 10.96it/s, v_num=0, train_loss=0.242] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3989/5184 [06:03<01:48, 10.97it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3994/5184 [06:03<01:48, 10.98it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3999/5184 [06:03<01:47, 10.99it/s, v_num=0, train_loss=0.0985]\n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4004/5184 [06:03<01:47, 11.00it/s, v_num=0, train_loss=0.226] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4009/5184 [06:03<01:46, 11.01it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4014/5184 [06:04<01:46, 11.02it/s, v_num=0, train_loss=0.199] \n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4019/5184 [06:04<01:45, 11.03it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4020/5184 [06:04<01:45, 11.04it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4025/5184 [06:04<01:44, 11.05it/s, v_num=0, train_loss=0.248]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4030/5184 [06:04<01:44, 11.06it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4032/5184 [06:04<01:44, 11.06it/s, v_num=0, train_loss=0.200]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4034/5184 [06:07<01:44, 10.97it/s, v_num=0, train_loss=0.222] \n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4039/5184 [06:07<01:44, 10.98it/s, v_num=0, train_loss=0.106]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4044/5184 [06:07<01:43, 10.99it/s, v_num=0, train_loss=0.243]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4049/5184 [06:08<01:43, 11.00it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4054/5184 [06:08<01:42, 11.01it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4058/5184 [06:08<01:42, 11.02it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4063/5184 [06:08<01:41, 11.03it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4067/5184 [06:08<01:41, 11.04it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4072/5184 [06:08<01:40, 11.05it/s, v_num=0, train_loss=0.113]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4077/5184 [06:08<01:40, 11.06it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4081/5184 [06:08<01:39, 11.06it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4082/5184 [06:08<01:39, 11.07it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4087/5184 [06:09<01:39, 11.08it/s, v_num=0, train_loss=0.099] \n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4091/5184 [06:09<01:38, 11.08it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4092/5184 [06:09<01:38, 11.09it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4096/5184 [06:09<01:38, 11.09it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4099/5184 [06:12<01:38, 11.00it/s, v_num=0, train_loss=0.184]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4103/5184 [06:12<01:38, 11.01it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4108/5184 [06:12<01:37, 11.01it/s, v_num=0, train_loss=0.0898]\n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4113/5184 [06:13<01:37, 11.02it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4118/5184 [06:13<01:36, 11.03it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4123/5184 [06:13<01:36, 11.04it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4128/5184 [06:13<01:35, 11.05it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4133/5184 [06:13<01:34, 11.06it/s, v_num=0, train_loss=0.0926]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4138/5184 [06:13<01:34, 11.07it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4143/5184 [06:13<01:33, 11.08it/s, v_num=0, train_loss=0.087]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4148/5184 [06:13<01:33, 11.09it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4149/5184 [06:13<01:33, 11.10it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4154/5184 [06:14<01:32, 11.11it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4159/5184 [06:14<01:32, 11.12it/s, v_num=0, train_loss=0.0675]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4160/5184 [06:14<01:32, 11.12it/s, v_num=0, train_loss=0.142] \n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4162/5184 [06:17<01:32, 11.02it/s, v_num=0, train_loss=0.0669]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4163/5184 [06:17<01:32, 11.02it/s, v_num=0, train_loss=0.119] \n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4167/5184 [06:17<01:32, 11.03it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4168/5184 [06:17<01:32, 11.03it/s, v_num=0, train_loss=0.0922]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4172/5184 [06:17<01:31, 11.04it/s, v_num=0, train_loss=0.0642]\n",
      "Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4173/5184 [06:17<01:31, 11.04it/s, v_num=0, train_loss=0.105] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4178/5184 [06:17<01:31, 11.05it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4182/5184 [06:18<01:30, 11.06it/s, v_num=0, train_loss=0.0852]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4183/5184 [06:18<01:30, 11.06it/s, v_num=0, train_loss=0.108] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4188/5184 [06:18<01:29, 11.07it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4192/5184 [06:18<01:29, 11.08it/s, v_num=0, train_loss=0.178] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4193/5184 [06:18<01:29, 11.08it/s, v_num=0, train_loss=0.0596]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4197/5184 [06:18<01:28, 11.09it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4198/5184 [06:18<01:28, 11.09it/s, v_num=0, train_loss=0.173]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4202/5184 [06:18<01:28, 11.10it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4203/5184 [06:18<01:28, 11.10it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4207/5184 [06:18<01:27, 11.11it/s, v_num=0, train_loss=0.109] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4208/5184 [06:18<01:27, 11.11it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4213/5184 [06:18<01:27, 11.12it/s, v_num=0, train_loss=0.0947]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4218/5184 [06:18<01:26, 11.13it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4223/5184 [06:19<01:26, 11.14it/s, v_num=0, train_loss=0.0997]\n",
      "Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4224/5184 [06:19<01:26, 11.14it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4225/5184 [06:22<01:26, 11.06it/s, v_num=0, train_loss=0.211]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4227/5184 [06:22<01:26, 11.06it/s, v_num=0, train_loss=0.228]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4231/5184 [06:22<01:26, 11.07it/s, v_num=0, train_loss=0.261]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4236/5184 [06:22<01:25, 11.08it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4237/5184 [06:22<01:25, 11.08it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4242/5184 [06:22<01:24, 11.09it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4247/5184 [06:22<01:24, 11.10it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4248/5184 [06:22<01:24, 11.10it/s, v_num=0, train_loss=0.127]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4253/5184 [06:22<01:23, 11.11it/s, v_num=0, train_loss=0.190]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4258/5184 [06:22<01:23, 11.12it/s, v_num=0, train_loss=0.262]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4263/5184 [06:23<01:22, 11.13it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4264/5184 [06:23<01:22, 11.13it/s, v_num=0, train_loss=0.208]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4269/5184 [06:23<01:22, 11.14it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4274/5184 [06:23<01:21, 11.15it/s, v_num=0, train_loss=0.219] \n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4280/5184 [06:23<01:20, 11.16it/s, v_num=0, train_loss=0.182]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4285/5184 [06:23<01:20, 11.17it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4288/5184 [06:23<01:20, 11.18it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4289/5184 [06:26<01:20, 11.09it/s, v_num=0, train_loss=0.203]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4291/5184 [06:27<01:20, 11.08it/s, v_num=0, train_loss=0.0458]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4295/5184 [06:27<01:20, 11.08it/s, v_num=0, train_loss=0.0709]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4299/5184 [06:27<01:19, 11.09it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4303/5184 [06:27<01:19, 11.10it/s, v_num=0, train_loss=0.0754]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4307/5184 [06:27<01:18, 11.10it/s, v_num=0, train_loss=0.084] \n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4311/5184 [06:27<01:18, 11.11it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4315/5184 [06:28<01:18, 11.12it/s, v_num=0, train_loss=0.0611]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4316/5184 [06:28<01:18, 11.12it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4320/5184 [06:28<01:17, 11.13it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4324/5184 [06:28<01:17, 11.13it/s, v_num=0, train_loss=0.0916]\n",
      "Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4328/5184 [06:28<01:16, 11.14it/s, v_num=0, train_loss=0.0772]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4332/5184 [06:28<01:16, 11.15it/s, v_num=0, train_loss=0.138] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4333/5184 [06:28<01:16, 11.15it/s, v_num=0, train_loss=0.0716]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4337/5184 [06:28<01:15, 11.16it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4342/5184 [06:28<01:15, 11.17it/s, v_num=0, train_loss=0.0678]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4346/5184 [06:28<01:14, 11.17it/s, v_num=0, train_loss=0.0486]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4347/5184 [06:28<01:14, 11.18it/s, v_num=0, train_loss=0.0609]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4352/5184 [06:29<01:14, 11.19it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4355/5184 [06:32<01:14, 11.09it/s, v_num=0, train_loss=0.197] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4360/5184 [06:32<01:14, 11.10it/s, v_num=0, train_loss=0.134] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4364/5184 [06:32<01:13, 11.10it/s, v_num=0, train_loss=0.131]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4365/5184 [06:33<01:13, 11.11it/s, v_num=0, train_loss=0.0873]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4369/5184 [06:33<01:13, 11.11it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4370/5184 [06:33<01:13, 11.12it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4374/5184 [06:33<01:12, 11.12it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4375/5184 [06:33<01:12, 11.13it/s, v_num=0, train_loss=0.0949]\n",
      "Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4380/5184 [06:33<01:12, 11.13it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4384/5184 [06:33<01:11, 11.14it/s, v_num=0, train_loss=0.0739]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4389/5184 [06:33<01:11, 11.15it/s, v_num=0, train_loss=0.0978]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4394/5184 [06:33<01:10, 11.16it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4398/5184 [06:33<01:10, 11.17it/s, v_num=0, train_loss=0.103] \n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4399/5184 [06:33<01:10, 11.17it/s, v_num=0, train_loss=0.119]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4403/5184 [06:33<01:09, 11.18it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4404/5184 [06:33<01:09, 11.18it/s, v_num=0, train_loss=0.135]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4409/5184 [06:34<01:09, 11.19it/s, v_num=0, train_loss=0.118]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4414/5184 [06:34<01:08, 11.20it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4416/5184 [06:34<01:08, 11.20it/s, v_num=0, train_loss=0.130]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4417/5184 [06:36<01:08, 11.13it/s, v_num=0, train_loss=0.0873]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4418/5184 [06:37<01:08, 11.12it/s, v_num=0, train_loss=0.0873]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4418/5184 [06:37<01:08, 11.12it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4423/5184 [06:37<01:08, 11.13it/s, v_num=0, train_loss=0.0934]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4427/5184 [06:37<01:07, 11.14it/s, v_num=0, train_loss=0.112] \n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4428/5184 [06:37<01:07, 11.14it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4432/5184 [06:37<01:07, 11.15it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4433/5184 [06:37<01:07, 11.15it/s, v_num=0, train_loss=0.215]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4437/5184 [06:37<01:06, 11.16it/s, v_num=0, train_loss=0.170]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4438/5184 [06:37<01:06, 11.16it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4442/5184 [06:37<01:06, 11.17it/s, v_num=0, train_loss=0.0758]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4443/5184 [06:37<01:06, 11.17it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4447/5184 [06:37<01:05, 11.17it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4448/5184 [06:37<01:05, 11.18it/s, v_num=0, train_loss=0.0791]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4452/5184 [06:38<01:05, 11.18it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4457/5184 [06:38<01:04, 11.19it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4461/5184 [06:38<01:04, 11.20it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4462/5184 [06:38<01:04, 11.20it/s, v_num=0, train_loss=0.102]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4467/5184 [06:38<01:03, 11.21it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4472/5184 [06:38<01:03, 11.22it/s, v_num=0, train_loss=0.168] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4476/5184 [06:38<01:03, 11.23it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4477/5184 [06:38<01:02, 11.23it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4480/5184 [06:38<01:02, 11.23it/s, v_num=0, train_loss=0.098] \n",
      "Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4481/5184 [06:42<01:03, 11.13it/s, v_num=0, train_loss=0.107]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4485/5184 [06:42<01:02, 11.14it/s, v_num=0, train_loss=0.073] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4489/5184 [06:42<01:02, 11.14it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4494/5184 [06:42<01:01, 11.15it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4499/5184 [06:43<01:01, 11.16it/s, v_num=0, train_loss=0.0827]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4504/5184 [06:43<01:00, 11.17it/s, v_num=0, train_loss=0.172] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4508/5184 [06:43<01:00, 11.18it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4512/5184 [06:43<01:00, 11.19it/s, v_num=0, train_loss=0.196]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4513/5184 [06:43<00:59, 11.19it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4517/5184 [06:43<00:59, 11.19it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4522/5184 [06:43<00:59, 11.20it/s, v_num=0, train_loss=0.0857]\n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4527/5184 [06:43<00:58, 11.21it/s, v_num=0, train_loss=0.156] \n",
      "Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4532/5184 [06:43<00:58, 11.22it/s, v_num=0, train_loss=0.0656]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4537/5184 [06:43<00:57, 11.23it/s, v_num=0, train_loss=0.111] \n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4542/5184 [06:44<00:57, 11.24it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4544/5184 [06:44<00:56, 11.24it/s, v_num=0, train_loss=0.0701]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4547/5184 [06:47<00:57, 11.16it/s, v_num=0, train_loss=0.144] \n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4548/5184 [06:47<00:56, 11.17it/s, v_num=0, train_loss=0.122]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4553/5184 [06:47<00:56, 11.17it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4557/5184 [06:47<00:56, 11.18it/s, v_num=0, train_loss=0.0976]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4562/5184 [06:47<00:55, 11.19it/s, v_num=0, train_loss=0.0955]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4567/5184 [06:47<00:55, 11.20it/s, v_num=0, train_loss=0.0841]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4571/5184 [06:47<00:54, 11.21it/s, v_num=0, train_loss=0.124] \n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4576/5184 [06:48<00:54, 11.22it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4581/5184 [06:48<00:53, 11.22it/s, v_num=0, train_loss=0.220]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4582/5184 [06:48<00:53, 11.23it/s, v_num=0, train_loss=0.176]\n",
      "Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4587/5184 [06:48<00:53, 11.24it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4592/5184 [06:48<00:52, 11.24it/s, v_num=0, train_loss=0.187]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4596/5184 [06:48<00:52, 11.25it/s, v_num=0, train_loss=0.0915]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4597/5184 [06:48<00:52, 11.25it/s, v_num=0, train_loss=0.221] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4601/5184 [06:48<00:51, 11.26it/s, v_num=0, train_loss=0.144]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4606/5184 [06:48<00:51, 11.27it/s, v_num=0, train_loss=0.135] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4607/5184 [06:48<00:51, 11.27it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4608/5184 [06:48<00:51, 11.27it/s, v_num=0, train_loss=0.158]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4610/5184 [06:52<00:51, 11.18it/s, v_num=0, train_loss=0.189]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4614/5184 [06:52<00:50, 11.18it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4618/5184 [06:52<00:50, 11.19it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4619/5184 [06:52<00:50, 11.19it/s, v_num=0, train_loss=0.110] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4624/5184 [06:52<00:49, 11.20it/s, v_num=0, train_loss=0.198] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4628/5184 [06:52<00:49, 11.21it/s, v_num=0, train_loss=0.0978]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4632/5184 [06:53<00:49, 11.22it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4633/5184 [06:53<00:49, 11.22it/s, v_num=0, train_loss=0.0785]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4637/5184 [06:53<00:48, 11.22it/s, v_num=0, train_loss=0.0789]\n",
      "Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4638/5184 [06:53<00:48, 11.23it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4642/5184 [06:53<00:48, 11.23it/s, v_num=0, train_loss=0.0989]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4647/5184 [06:53<00:47, 11.24it/s, v_num=0, train_loss=0.0892]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4651/5184 [06:53<00:47, 11.25it/s, v_num=0, train_loss=0.092] \n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4652/5184 [06:53<00:47, 11.25it/s, v_num=0, train_loss=0.150]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4656/5184 [06:53<00:46, 11.26it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4657/5184 [06:53<00:46, 11.26it/s, v_num=0, train_loss=0.124]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4662/5184 [06:53<00:46, 11.27it/s, v_num=0, train_loss=0.0925]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4667/5184 [06:53<00:45, 11.28it/s, v_num=0, train_loss=0.199] \n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4672/5184 [06:53<00:45, 11.29it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4676/5184 [06:57<00:45, 11.20it/s, v_num=0, train_loss=0.166] \n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4680/5184 [06:57<00:44, 11.21it/s, v_num=0, train_loss=0.151] \n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4681/5184 [06:57<00:44, 11.21it/s, v_num=0, train_loss=0.076]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4685/5184 [06:57<00:44, 11.22it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4686/5184 [06:57<00:44, 11.22it/s, v_num=0, train_loss=0.104]\n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4690/5184 [06:57<00:43, 11.23it/s, v_num=0, train_loss=0.206] \n",
      "Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4691/5184 [06:57<00:43, 11.23it/s, v_num=0, train_loss=0.0942]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4695/5184 [06:57<00:43, 11.24it/s, v_num=0, train_loss=0.118] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4696/5184 [06:57<00:43, 11.24it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4700/5184 [06:57<00:43, 11.25it/s, v_num=0, train_loss=0.140] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4701/5184 [06:57<00:42, 11.25it/s, v_num=0, train_loss=0.140]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4701/5184 [06:57<00:42, 11.25it/s, v_num=0, train_loss=0.0977]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4705/5184 [06:58<00:42, 11.25it/s, v_num=0, train_loss=0.120] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4706/5184 [06:58<00:42, 11.26it/s, v_num=0, train_loss=0.0741]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4710/5184 [06:58<00:42, 11.26it/s, v_num=0, train_loss=0.202] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4711/5184 [06:58<00:41, 11.26it/s, v_num=0, train_loss=0.0462]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4715/5184 [06:58<00:41, 11.27it/s, v_num=0, train_loss=0.0943]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4716/5184 [06:58<00:41, 11.27it/s, v_num=0, train_loss=0.192] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4720/5184 [06:58<00:41, 11.28it/s, v_num=0, train_loss=0.154] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4724/5184 [06:58<00:40, 11.29it/s, v_num=0, train_loss=0.193] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4725/5184 [06:58<00:40, 11.29it/s, v_num=0, train_loss=0.117]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4730/5184 [06:58<00:40, 11.30it/s, v_num=0, train_loss=0.184] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4734/5184 [06:58<00:39, 11.30it/s, v_num=0, train_loss=0.0943]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4736/5184 [06:58<00:39, 11.31it/s, v_num=0, train_loss=0.200] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4737/5184 [07:02<00:39, 11.21it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4741/5184 [07:02<00:39, 11.22it/s, v_num=0, train_loss=0.181] \n",
      "Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4742/5184 [07:02<00:39, 11.22it/s, v_num=0, train_loss=0.0872]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4746/5184 [07:02<00:39, 11.22it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4747/5184 [07:02<00:38, 11.23it/s, v_num=0, train_loss=0.126]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4751/5184 [07:02<00:38, 11.23it/s, v_num=0, train_loss=0.171] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4756/5184 [07:03<00:38, 11.24it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4761/5184 [07:03<00:37, 11.25it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4766/5184 [07:03<00:37, 11.26it/s, v_num=0, train_loss=0.122] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4771/5184 [07:03<00:36, 11.27it/s, v_num=0, train_loss=0.0364]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4776/5184 [07:03<00:36, 11.28it/s, v_num=0, train_loss=0.162] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4780/5184 [07:03<00:35, 11.28it/s, v_num=0, train_loss=0.150] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4784/5184 [07:03<00:35, 11.29it/s, v_num=0, train_loss=0.133] \n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4785/5184 [07:03<00:35, 11.29it/s, v_num=0, train_loss=0.109]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4790/5184 [07:03<00:34, 11.30it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4795/5184 [07:04<00:34, 11.31it/s, v_num=0, train_loss=0.146] \n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4796/5184 [07:04<00:34, 11.31it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4800/5184 [07:04<00:33, 11.32it/s, v_num=0, train_loss=0.202] \n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4802/5184 [07:07<00:33, 11.24it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4807/5184 [07:07<00:33, 11.25it/s, v_num=0, train_loss=0.183]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4812/5184 [07:07<00:33, 11.26it/s, v_num=0, train_loss=0.0821]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4817/5184 [07:07<00:32, 11.27it/s, v_num=0, train_loss=0.186] \n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4822/5184 [07:07<00:32, 11.28it/s, v_num=0, train_loss=0.207]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4826/5184 [07:07<00:31, 11.28it/s, v_num=0, train_loss=0.155]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4827/5184 [07:07<00:31, 11.28it/s, v_num=0, train_loss=0.227]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4832/5184 [07:07<00:31, 11.29it/s, v_num=0, train_loss=0.133]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4837/5184 [07:08<00:30, 11.30it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4842/5184 [07:08<00:30, 11.31it/s, v_num=0, train_loss=0.166]\n",
      "Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4847/5184 [07:08<00:29, 11.32it/s, v_num=0, train_loss=0.181]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4852/5184 [07:08<00:29, 11.33it/s, v_num=0, train_loss=0.089]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4852/5184 [07:08<00:29, 11.33it/s, v_num=0, train_loss=0.186]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4856/5184 [07:08<00:28, 11.33it/s, v_num=0, train_loss=0.139] \n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 4857/5184 [07:08<00:28, 11.34it/s, v_num=0, train_loss=0.147]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4862/5184 [07:08<00:28, 11.34it/s, v_num=0, train_loss=0.165]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4864/5184 [07:08<00:28, 11.35it/s, v_num=0, train_loss=0.105]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4865/5184 [07:11<00:28, 11.26it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4866/5184 [07:12<00:28, 11.26it/s, v_num=0, train_loss=0.0611]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4870/5184 [07:12<00:27, 11.27it/s, v_num=0, train_loss=0.0472]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4874/5184 [07:12<00:27, 11.27it/s, v_num=0, train_loss=0.121] \n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4875/5184 [07:12<00:27, 11.28it/s, v_num=0, train_loss=0.111]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4880/5184 [07:12<00:26, 11.28it/s, v_num=0, train_loss=0.0973]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4885/5184 [07:12<00:26, 11.29it/s, v_num=0, train_loss=0.125] \n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4890/5184 [07:12<00:26, 11.30it/s, v_num=0, train_loss=0.087]\n",
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4895/5184 [07:12<00:25, 11.31it/s, v_num=0, train_loss=0.103]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4900/5184 [07:12<00:25, 11.32it/s, v_num=0, train_loss=0.101] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4905/5184 [07:13<00:24, 11.33it/s, v_num=0, train_loss=0.0908]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4909/5184 [07:13<00:24, 11.33it/s, v_num=0, train_loss=0.0941]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4910/5184 [07:13<00:24, 11.34it/s, v_num=0, train_loss=0.163] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4915/5184 [07:13<00:23, 11.34it/s, v_num=0, train_loss=0.120]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4919/5184 [07:13<00:23, 11.35it/s, v_num=0, train_loss=0.164] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4924/5184 [07:13<00:22, 11.36it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4925/5184 [07:13<00:22, 11.36it/s, v_num=0, train_loss=0.0745]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4928/5184 [07:13<00:22, 11.37it/s, v_num=0, train_loss=0.0893]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4929/5184 [07:17<00:22, 11.28it/s, v_num=0, train_loss=0.161] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4934/5184 [07:17<00:22, 11.28it/s, v_num=0, train_loss=0.132] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4939/5184 [07:17<00:21, 11.29it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4943/5184 [07:17<00:21, 11.30it/s, v_num=0, train_loss=0.0859]\n",
      "Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4947/5184 [07:17<00:20, 11.31it/s, v_num=0, train_loss=0.123] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4952/5184 [07:17<00:20, 11.31it/s, v_num=0, train_loss=0.0838]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4956/5184 [07:17<00:20, 11.32it/s, v_num=0, train_loss=0.0503]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4957/5184 [07:17<00:20, 11.32it/s, v_num=0, train_loss=0.141] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4961/5184 [07:17<00:19, 11.33it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4962/5184 [07:17<00:19, 11.33it/s, v_num=0, train_loss=0.0981]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4966/5184 [07:18<00:19, 11.34it/s, v_num=0, train_loss=0.0765]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4967/5184 [07:18<00:19, 11.34it/s, v_num=0, train_loss=0.224] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4971/5184 [07:18<00:18, 11.35it/s, v_num=0, train_loss=0.129] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4976/5184 [07:18<00:18, 11.35it/s, v_num=0, train_loss=0.0705]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4981/5184 [07:18<00:17, 11.36it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4986/5184 [07:18<00:17, 11.37it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4990/5184 [07:18<00:17, 11.38it/s, v_num=0, train_loss=0.185]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4992/5184 [07:18<00:16, 11.38it/s, v_num=0, train_loss=0.0943]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4993/5184 [07:22<00:16, 11.29it/s, v_num=0, train_loss=0.183] \n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4995/5184 [07:22<00:16, 11.28it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5000/5184 [07:22<00:16, 11.29it/s, v_num=0, train_loss=0.107] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5005/5184 [07:22<00:15, 11.30it/s, v_num=0, train_loss=0.147] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5010/5184 [07:23<00:15, 11.31it/s, v_num=0, train_loss=0.0731]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5014/5184 [07:23<00:15, 11.32it/s, v_num=0, train_loss=0.191] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5015/5184 [07:23<00:14, 11.32it/s, v_num=0, train_loss=0.197]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5019/5184 [07:23<00:14, 11.32it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5024/5184 [07:23<00:14, 11.33it/s, v_num=0, train_loss=0.0901]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5029/5184 [07:23<00:13, 11.34it/s, v_num=0, train_loss=0.131] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5033/5184 [07:23<00:13, 11.35it/s, v_num=0, train_loss=0.113] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5038/5184 [07:23<00:12, 11.35it/s, v_num=0, train_loss=0.128] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5042/5184 [07:23<00:12, 11.36it/s, v_num=0, train_loss=0.093]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5043/5184 [07:23<00:12, 11.36it/s, v_num=0, train_loss=0.136]\n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5048/5184 [07:23<00:11, 11.37it/s, v_num=0, train_loss=0.130] \n",
      "Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5053/5184 [07:24<00:11, 11.38it/s, v_num=0, train_loss=0.112]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5056/5184 [07:24<00:11, 11.38it/s, v_num=0, train_loss=0.104] \n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5057/5184 [07:27<00:11, 11.30it/s, v_num=0, train_loss=0.123]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5060/5184 [07:27<00:10, 11.30it/s, v_num=0, train_loss=0.136] \n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5064/5184 [07:27<00:10, 11.31it/s, v_num=0, train_loss=0.134]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5069/5184 [07:27<00:10, 11.32it/s, v_num=0, train_loss=0.139]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5074/5184 [07:28<00:09, 11.33it/s, v_num=0, train_loss=0.152]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5079/5184 [07:28<00:09, 11.33it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5080/5184 [07:28<00:09, 11.34it/s, v_num=0, train_loss=0.171]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5080/5184 [07:28<00:09, 11.34it/s, v_num=0, train_loss=0.0933]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5085/5184 [07:28<00:08, 11.34it/s, v_num=0, train_loss=0.167] \n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5089/5184 [07:28<00:08, 11.35it/s, v_num=0, train_loss=0.148]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5090/5184 [07:28<00:08, 11.35it/s, v_num=0, train_loss=0.0679]\n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5095/5184 [07:28<00:07, 11.36it/s, v_num=0, train_loss=0.223] \n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5100/5184 [07:28<00:07, 11.37it/s, v_num=0, train_loss=0.102] \n",
      "Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5105/5184 [07:28<00:06, 11.38it/s, v_num=0, train_loss=0.145]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5110/5184 [07:28<00:06, 11.39it/s, v_num=0, train_loss=0.0909]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5115/5184 [07:28<00:06, 11.39it/s, v_num=0, train_loss=0.224] \n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5120/5184 [07:29<00:05, 11.40it/s, v_num=0, train_loss=0.100]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5123/5184 [07:32<00:05, 11.32it/s, v_num=0, train_loss=0.0772]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5128/5184 [07:32<00:04, 11.33it/s, v_num=0, train_loss=0.210] \n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5133/5184 [07:32<00:04, 11.34it/s, v_num=0, train_loss=0.110]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5138/5184 [07:32<00:04, 11.35it/s, v_num=0, train_loss=0.149] \n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5139/5184 [07:32<00:03, 11.35it/s, v_num=0, train_loss=0.174]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5144/5184 [07:32<00:03, 11.36it/s, v_num=0, train_loss=0.133]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5149/5184 [07:33<00:03, 11.37it/s, v_num=0, train_loss=0.151]\n",
      "Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5154/5184 [07:33<00:02, 11.37it/s, v_num=0, train_loss=0.089]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5159/5184 [07:33<00:02, 11.38it/s, v_num=0, train_loss=0.164]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5164/5184 [07:33<00:01, 11.39it/s, v_num=0, train_loss=0.0992]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5169/5184 [07:33<00:01, 11.40it/s, v_num=0, train_loss=0.116] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5174/5184 [07:33<00:00, 11.41it/s, v_num=0, train_loss=0.121]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5175/5184 [07:33<00:00, 11.41it/s, v_num=0, train_loss=0.153]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5180/5184 [07:33<00:00, 11.42it/s, v_num=0, train_loss=0.0444]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5184/5184 [07:33<00:00, 11.42it/s, v_num=0, train_loss=0.114] \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5184/5184 [07:34<00:00, 11.42it/s, v_num=0, train_loss=0.114]\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5184/5184 [07:34<00:00, 11.42it/s, v_num=0, train_loss=0.114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-10-21_05-38-12/TorchTrainer_22390_00000_0_2025-10-21_05-38-12/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=1146525)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = RayTrainRunner(\n",
    "    LinearClassifier,  # replace with your own model\n",
    "    Dcl,  # replace with your own Dataset\n",
    "    [\"num_genes\", \"num_classes\"],  # change according to what you need for your model\n",
    "    cell_line_metadata_cb,  # include data you need for your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7c91208-19de-4fdb-a684-b73d9dacd2c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting thread_per_worker to half of the available CPUs capped at 4\n",
      "Using 1 workers with {'CPU': 4} each\n",
      "=========Length of val_split 0 length of test_split 0 length of train_split 327\n",
      "=========Length of after dropping remainder val_split 0 length of test_split 0 length of train_split 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:38:12,374\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting time: 25.91 seconds\n",
      "Spawning Ray worker and initiating distributed training\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:12 (running for 00:00:00.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:17 (running for 00:00:05.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:22 (running for 00:00:10.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:27 (running for 00:00:15.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:32 (running for 00:00:20.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:37 (running for 00:00:25.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:42 (running for 00:00:30.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:47 (running for 00:00:35.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:52 (running for 00:00:40.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:38:57 (running for 00:00:45.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:02 (running for 00:00:50.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:07 (running for 00:00:55.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:12 (running for 00:01:00.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:17 (running for 00:01:05.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:22 (running for 00:01:10.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:27 (running for 00:01:15.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:32 (running for 00:01:20.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:38 (running for 00:01:25.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:43 (running for 00:01:30.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:48 (running for 00:01:35.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:53 (running for 00:01:40.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:39:58 (running for 00:01:45.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:03 (running for 00:01:50.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:08 (running for 00:01:55.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:13 (running for 00:02:00.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:18 (running for 00:02:05.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:23 (running for 00:02:10.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:28 (running for 00:02:15.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:33 (running for 00:02:20.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:38 (running for 00:02:25.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:43 (running for 00:02:30.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:48 (running for 00:02:35.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:53 (running for 00:02:41.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:40:58 (running for 00:02:46.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:03 (running for 00:02:51.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:08 (running for 00:02:56.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:13 (running for 00:03:01.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:18 (running for 00:03:06.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:23 (running for 00:03:11.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:28 (running for 00:03:16.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:33 (running for 00:03:21.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:38 (running for 00:03:26.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:43 (running for 00:03:31.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:48 (running for 00:03:36.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:53 (running for 00:03:41.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:41:58 (running for 00:03:46.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:03 (running for 00:03:51.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:08 (running for 00:03:56.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:13 (running for 00:04:01.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:18 (running for 00:04:06.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:23 (running for 00:04:11.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:28 (running for 00:04:16.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:34 (running for 00:04:21.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:39 (running for 00:04:26.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:44 (running for 00:04:31.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:49 (running for 00:04:36.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:54 (running for 00:04:41.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:42:59 (running for 00:04:46.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:04 (running for 00:04:51.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:09 (running for 00:04:56.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:14 (running for 00:05:01.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:19 (running for 00:05:06.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:24 (running for 00:05:11.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:29 (running for 00:05:17.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:34 (running for 00:05:22.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:39 (running for 00:05:27.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:44 (running for 00:05:32.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:49 (running for 00:05:37.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:54 (running for 00:05:42.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:43:59 (running for 00:05:47.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:04 (running for 00:05:52.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:09 (running for 00:05:57.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:14 (running for 00:06:02.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:19 (running for 00:06:07.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:24 (running for 00:06:12.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:29 (running for 00:06:17.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:34 (running for 00:06:22.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:39 (running for 00:06:27.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:44 (running for 00:06:32.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:49 (running for 00:06:37.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:44:54 (running for 00:06:42.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:00 (running for 00:06:47.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:05 (running for 00:06:52.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:10 (running for 00:06:57.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:15 (running for 00:07:02.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:20 (running for 00:07:07.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:25 (running for 00:07:12.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:30 (running for 00:07:17.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:35 (running for 00:07:22.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:40 (running for 00:07:27.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:45 (running for 00:07:32.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:50 (running for 00:07:37.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:45:55 (running for 00:07:43.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:46:00 (running for 00:07:48.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:46:05 (running for 00:07:53.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:46:10 (running for 00:07:58.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:46:15 (running for 00:08:03.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-10-21 05:46:20 (running for 00:08:08.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:46:21,348\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/dtran/protoplast_results/TorchTrainer_2025-10-21_05-38-12' in 0.0109s.\n",
      "2025-10-21 05:46:21,353\tINFO tune.py:1041 -- Total run time: 488.98 seconds (488.95 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-10-21 05:46:21 (running for 00:08:08.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-10-21_05-37-36_926688_1117002/artifacts/2025-10-21_05-38-12/TorchTrainer_2025-10-21_05-38-12/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "CPU times: user 27.8 s, sys: 4.83 s, total: 32.7 s\n",
      "Wall time: 8min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(\n",
    "    file_paths,\n",
    "    batch_size,  # 2000\n",
    "    test_size,  # 0.0\n",
    "    val_size,  # 0.0\n",
    ")\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da75f6e-35ae-4a94-b022-e59051975e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10368000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5184 * 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1673142-f945-49db-8db4-89a743edd35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 10487057 Ã— 62710 backed at '/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad'\n",
       "    obs: 'sample', 'gene_count', 'tscp_count', 'mread_count', 'drugname_drugconc', 'drug', 'cell_line', 'sublibrary', 'BARCODE', 'pcnt_mito', 'S_score', 'G2M_score', 'phase', 'pass_filter', 'cell_name', 'plate'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check plate 12\n",
    "adata = ad.read_h5ad(\n",
    "    '/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad',\n",
    "    backed=\"r\"\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5908594b-3504-48ae-af48-b7e3d67a2aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119057"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10487057 - 5184 * 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0469c71-b9fd-46d7-8236-5b5668f2dcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
