{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "MJUe",
      "metadata": {},
      "source": [
        "# Perturbation Models for Single-Cell Data with PROTOplast"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vblA",
      "metadata": {},
      "source": [
        "This notebook showcases **perturbation models** for the **Tahoe-100M** dataset, focusing on predicting gene expression changes under drug perturbations. We demonstrate two approaches: a statistical baseline and a neural embedding model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28a3cbd",
      "metadata": {},
      "source": [
        "**Download the Tahoe-100M `h5ad` files**\n",
        "- The Tahoe-100M dataset can be downloaded in `h5ad` format from the **Arc Institute Google Cloud Storage**. For step-by-step instructions, see the [official tutorial](https://github.com/ArcInstitute/arc-virtual-cell-atlas/blob/main/tahoe-100M/README.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bkHC",
      "metadata": {},
      "source": [
        "**Set up**\n",
        "- Set up the training environment for single-cell RNA sequencing (scRNA-seq) data using PROTOplast together with PyTorch Lightning and Ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "lEQa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2713 Applied AnnDataFileManager patch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/hdd1/dung/protoplast-ml-example/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-09-24 11:33:18,450\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
            "2025-09-24 11:33:18,548\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2713 Applied AnnDataFileManager patch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 11:33:18,588\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        }
      ],
      "source": [
        "import anndata\n",
        "import numpy as np\n",
        "import torch\n",
        "from protoplast.scrna.anndata.torch_dataloader import DistributedAnnDataset, cell_line_metadata_cb\n",
        "from protoplast.scrna.anndata.trainer import RayTrainRunner\n",
        "\n",
        "# models from state\n",
        "from state.tx.models.embed_sum import EmbedSumPerturbationModel\n",
        "from state.tx.models.perturb_mean import PerturbMeanPerturbationModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb6e3f3",
      "metadata": {},
      "source": [
        "## 1. Load the Tahoe 100-M Dataset (`h5ad`)\n",
        "- `file_paths`: here, only Plate 12 from Tahoe-100M (The largest file: 35 GB) is used as a demo. To add more plates, append their `.h5ad` file paths to the list, separated by commas\n",
        "- `thread_per_worker`: number of threads allocated per worker\n",
        "- `batch_size`: number of samples per training batch\n",
        "- `test_size`: fraction of data reserved for testing\n",
        "- `val_size`: fraction of data reserved for validation (use `0.0` if no validation set is needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Xref",
      "metadata": {},
      "outputs": [],
      "source": [
        "file_paths = [\"/mnt/hdd2/tan/tahoe100m/plate12_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad\"]\n",
        "thread_per_worker = 2\n",
        "batch_size = 2000\n",
        "test_size = 0.0\n",
        "val_size = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SFPL",
      "metadata": {
        "marimo": {
          "config": {
            "hide_code": true
          }
        }
      },
      "source": [
        "## 2. Perturbation Mean\n",
        "**PerturbMeanPerturbationModel** (from STATE) is a *statistical baseline* that predicts perturbed expression by combining a control baseline (global or per-sample) with a perturbation-specific offset averaged across cell types.\n",
        "- **Inputs**\n",
        "    - Perturbation identifier\n",
        "    - Cell type (cell line in Tahoe-100M)\n",
        "    - Perturbed counts or embeddings\n",
        "    - (Optional) control embedding\n",
        "- **Output**\n",
        "    - Predicted gene expression profile (or latent embedding, depending on configuration)\n",
        "Note: This model is not trained so no learnable weights, no validation data). Its predictions come purely from statistics of the training dataset. \n",
        "**Source code:** [perturb_mean.py](https://github.com/ArcInstitute/state/blob/b6d26731e41d78c8c789d6973fe3d7db7853e9ad/src/state/tx/models/perturb_mean.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BYtC",
      "metadata": {},
      "source": [
        "### Metadata Callback\n",
        "The `perturbmean_metadata_cb` function prepares metadata for the **Perturbation Mean** model.  \n",
        "- It converts drug and cell line columns to categorical values, sets input/output dimensions, hidden size, perturbation dimension, and training hyperparameters.  \n",
        "- It also stores gene names, perturbation names, and cell types, while designating `DMSO_TF` as the control, `X` as the embedding key, and `gene` as the output space.\n",
        "- `perturbmean_metadata_cb` prepares metadata for the Perturbation Mean model. It casts drug and cell line columns to categorical, sets input/output dimensions, hidden size, and perturbation dimension, and defines training hyperparameters. It also records gene names, perturbation names, and cell types, while specifying \"DMSO_TF\" as the control, \"X\" as the embedding key, and \"gene\" as the output space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "RGSE",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 23 \u03bcs, sys: 0 ns, total: 23 \u03bcs\n",
            "Wall time: 43.4 \u03bcs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "def perturbmean_metadata_cb(ad: anndata.AnnData, metadata: dict):\n",
        "    ad.obs[\"drug\"] = ad.obs[\"drug\"].astype(\"category\")\n",
        "    ad.obs[\"cell_line\"] = ad.obs[\"cell_line\"].astype(\"category\")\n",
        "\n",
        "    metadata[\"input_dim\"] = ad.var.shape[0]\n",
        "    metadata[\"output_dim\"] = ad.var.shape[0]\n",
        "    metadata[\"hidden_dim\"] = 0  # hidden_dim: Not used here, but required by base-class signature.\n",
        "    metadata[\"pert_dim\"] = ad.obs[\"drug\"].astype(str).nunique()\n",
        "    metadata[\"lr\"] = 1e-3\n",
        "\n",
        "    metadata[\"gene_names\"] = ad.var_names.tolist()\n",
        "    metadata[\"pert_names\"] = ad.obs[\"drug\"].cat.categories.tolist()\n",
        "    metadata[\"cell_types\"] = ad.obs[\"cell_line\"].cat.categories.tolist()\n",
        "    metadata[\"control_pert\"] = \"DMSO_TF\"\n",
        "    metadata[\"embed_key\"] = \"X\"\n",
        "    metadata[\"output_space\"] = \"gene\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kclp",
      "metadata": {},
      "source": [
        "### Perturbation Dataset for Training (PerturbAnnDataset)\n",
        "`PerturbAnnDataset` prepares batches for the **Perturbation Mean** model. It loads expression data, collects `drug` and `cell_line` metadata, and returns a dictionary containing perturbation names, cell types, and the corresponding expression features (used both as counts and embeddings) for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "emfo",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 149 \u03bcs, sys: 0 ns, total: 149 \u03bcs\n",
            "Wall time: 170 \u03bcs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "class PerturbAnnDataset(DistributedAnnDataset):\n",
        "    def transform(self, start: int, end: int):\n",
        "        X = super().transform(start, end)\n",
        "\n",
        "        # Metadata froms self.ad\n",
        "        pert_names = self.ad.obs[\"drug\"].iloc[start:end].astype(str).to_list()\n",
        "        cell_lines = self.ad.obs[\"cell_line\"].iloc[start:end].astype(str).to_list()\n",
        "\n",
        "        return {\n",
        "            \"pert_name\": pert_names,\n",
        "            \"cell_type\": cell_lines,\n",
        "            \"pert_cell_counts\": X,\n",
        "            \"pert_cell_emb\": X,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hstk",
      "metadata": {},
      "source": [
        "### Extending STATE Models\n",
        "The **STATE** framework provides baseline model classes such as `PerturbMeanPerturbationModel`, which can be imported and used directly.\n",
        "To customize behavior, you can **extend an existing class** and override only the methods that need modification.  \n",
        "In the example below, we subclass `PerturbMeanPerturbationModel` and redefine the `forward()` method. Rather than relying on the per-cell `ctrl_cell_emb`, the model predicts using only the **global basal vector** combined with the corresponding perturbation offset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "nWHF",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 135 \u03bcs, sys: 0 ns, total: 135 \u03bcs\n",
            "Wall time: 156 \u03bcs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "class PerturbMeanGlobalModel(PerturbMeanPerturbationModel):\n",
        "    \"\"\"\n",
        "    Extended class of PerturbMeanPerturbationModel where prediction ignores\n",
        "    per-cell control embedding and uses only global basal + offset.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, batch: dict) -> torch.Tensor:\n",
        "        B = len(batch[\"pert_name\"])\n",
        "        device = self.dummy_param.device\n",
        "        pred_out = torch.zeros((B, self.output_dim), device=device)\n",
        "\n",
        "        for i in range(B):\n",
        "            p_name = str(batch[\"pert_name\"][i])\n",
        "            offset_vec = self.pert_mean_offsets.get(p_name)\n",
        "            if offset_vec is None:\n",
        "                offset_vec = torch.zeros(self.output_dim, device=device)\n",
        "\n",
        "            # Use global basal instead of batch[\"ctrl_cell_emb\"]\n",
        "            pred_out[i] = self.global_basal.to(device) + offset_vec.to(device)\n",
        "\n",
        "        return pred_out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af0e38aa",
      "metadata": {},
      "source": [
        "### Training the model\n",
        "- Collect statistics (`on_fit_start`)\n",
        "    - Compute control means per cell type\n",
        "    - Compute perturbation deltas\n",
        "    - Average deltas across cell types \u2192 perturbation offsets\n",
        "    - Compute global basal = mean of all control means.\n",
        "- Forward: for each sample, `prediction = global_basal + offset[perturbation]`\n",
        "- Training: no parameters are learned; only logs MSE loss vs. ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "iLit",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 11:33:26,414\tINFO worker.py:1951 -- Started a local Ray instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 232 ms, sys: 331 ms, total: 564 ms\n",
            "Wall time: 2.81 s\n",
            "\u001b[36m(TrainTrainable pid=1209221)\u001b[0m \u2713 Applied AnnDataFileManager patch\n",
            "\u001b[36m(TrainTrainable pid=1209221)\u001b[0m \u2713 Applied AnnDataFileManager patch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
            "\u001b[36m(TorchTrainer pid=1209221)\u001b[0m Started distributed worker processes: \n",
            "\u001b[36m(TorchTrainer pid=1209221)\u001b[0m - (node_id=3f1e363fcefb582b194b252798310b8d931ee304e5f7ccca2792aa00, ip=192.168.1.226, pid=1209389) world_rank=0, local_rank=0, node_rank=0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \u2713 Applied AnnDataFileManager patch\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \u2713 Applied AnnDataFileManager patch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m =========Starting the training on 0 with num threads: 2=========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m   | Name         | Type    | Params | Mode \n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m -------------------------------------------------\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 0 | loss_fn      | MSELoss | 0      | train\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m   | other params | n/a     | 1      | n/a  \n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m -------------------------------------------------\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 1         Trainable params\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 1         Total params\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 0.000     Total estimated model params size (MB)\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 1         Modules in train mode\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00<00:00,  2.88it/s]\n",
            "                                                                           \n",
            "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s] \n",
            "Epoch 0:   0%|          | 1/4192 [00:22<26:32:38,  0.04it/s, v_num=0, train_loss=1.080]\n",
            "Epoch 0:   0%|          | 2/4192 [00:23<13:48:53,  0.08it/s, v_num=0, train_loss=0.983]\n",
            ".\n",
            ".\n",
            ".\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 4190/4192 [23:06<00:00,  3.02it/s, v_num=0, train_loss=0.564]\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 4191/4192 [23:07<00:00,  3.02it/s, v_num=0, train_loss=0.577]\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [23:07<00:00,  3.02it/s, v_num=0, train_loss=0.953]\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "Validation:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            ".\n",
            ".\n",
            ".\n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1020/1024 [05:37<00:01,  3.02it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1021/1024 [05:38<00:00,  3.02it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1022/1024 [05:38<00:00,  3.02it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1023/1024 [05:38<00:00,  3.02it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m \n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1024/1024 [05:39<00:00,  3.02it/s]\u001b[A\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [29:09<00:00,  2.40it/s, v_num=0, train_loss=0.953]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-09-24_11-33-51/TorchTrainer_58516_00000_0_2025-09-24_11-33-51/checkpoint_000000)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [29:09<00:00,  2.40it/s, v_num=0, train_loss=0.953]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [29:09<00:00,  2.40it/s, v_num=0, train_loss=0.953]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1209389)\u001b[0m [rank0]:[W924 12:13:08.881254821 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "PerturbMeanPerturbationModel_trainer = RayTrainRunner(\n",
        "    PerturbMeanGlobalModel,\n",
        "    PerturbAnnDataset,\n",
        "    [\n",
        "        \"input_dim\",\n",
        "        \"output_dim\",\n",
        "        \"hidden_dim\",\n",
        "        \"pert_dim\",\n",
        "        \"lr\",\n",
        "        \"control_pert\",  # \"DMSO_TF\"\n",
        "        \"embed_key\",\n",
        "        \"output_space\",  # \"gene\"\n",
        "    ],\n",
        "    perturbmean_metadata_cb,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae11ae35",
      "metadata": {},
      "source": [
        "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12 GiB)**, **96 CPUs**, and **125 GiB RAM**, running `PerturbMeanPerturbationModel_trainer.train()` completed in approximately **40 minutes**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ZHCJ",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 1 workers with {'CPU': 2} each\n",
            "=========Length of val_split 65 length of test_split 0 length of train_split 262\n",
            "=========Length of after dropping remainder val_split 64 length of test_split 0 length of train_split 262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 11:33:51,717\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data splitting time: 24.04 seconds\n",
            "Spawning Ray worker and initiating distributed training\n",
            "== Status ==\n",
            "Current time: 2025-09-24 11:33:51 (running for 00:00:00.18)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_11-33-24_769318_1202711/artifacts/2025-09-24_11-33-51/TorchTrainer_2025-09-24_11-33-51/driver_artifacts\n",
            "Number of trials: 1/1 (1 PENDING)\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2025-09-24 11:34:02 (running for 00:00:10.29)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_11-33-24_769318_1202711/artifacts/2025-09-24_11-33-51/TorchTrainer_2025-09-24_11-33-51/driver_artifacts\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2025-09-24 12:13:05 (running for 00:39:14.00)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_11-33-24_769318_1202711/artifacts/2025-09-24_11-33-51/TorchTrainer_2025-09-24_11-33-51/driver_artifacts\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 12:13:07,400\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/dtran/protoplast_results/TorchTrainer_2025-09-24_11-33-51' in 0.1191s.\n",
            "2025-09-24 12:13:07,405\tINFO tune.py:1041 -- Total run time: 2355.69 seconds (2355.48 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2025-09-24 12:13:07 (running for 00:39:15.60)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_11-33-24_769318_1202711/artifacts/2025-09-24_11-33-51/TorchTrainer_2025-09-24_11-33-51/driver_artifacts\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "\n",
            "\n",
            "CPU times: user 56.8 s, sys: 14.4 s, total: 1min 11s\n",
            "Wall time: 39min 39s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Result(\n",
              "  metrics={'train_loss': 0.9527178406715393, 'val_loss': 0.6070448756217957, 'epoch': 0, 'step': 4192},\n",
              "  path='/home/dtran/protoplast_results/TorchTrainer_2025-09-24_11-33-51/TorchTrainer_58516_00000_0_2025-09-24_11-33-51',\n",
              "  filesystem='local',\n",
              "  checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-09-24_11-33-51/TorchTrainer_58516_00000_0_2025-09-24_11-33-51/checkpoint_000000)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "PerturbMeanPerturbationModel_trainer.train(\n",
        "    file_paths,\n",
        "    batch_size,  # 2000\n",
        "    test_size,  # 0.0\n",
        "    val_size,  # 0.2\n",
        "    thread_per_worker=thread_per_worker,  # 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fb929268-60a8-4650-89a2-f906e17e0abc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ROlb",
      "metadata": {},
      "source": [
        "## 3. EmbedSum\n",
        "The **EmbedSumPerturbationModel** (part of the STATE framework) is a neural embedding model that predicts gene expression under perturbations.  \n",
        "It works by combining a **control (basal) cell state** with a **learned perturbation embedding**.  \n",
        "**Inputs**\n",
        "  - Control (basal) expression counts or embedding  \n",
        "  - Perturbation one-hot vector  \n",
        "\n",
        "**Output**\n",
        "  - Predicted gene expression profile  \n",
        "**Source code:** [embed_sum.py](https://github.com/ArcInstitute/state/blob/b6d26731e41d78c8c789d6973fe3d7db7853e9ad/src/state/tx/models/embed_sum.py#L7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qnkX",
      "metadata": {},
      "source": [
        "### Metadata Callback\n",
        "The `embedsum_metadata_cb` function prepares metadata for the `EmbedSumPerturbationModel`. It sets the input and output dimensions (equal to the **number of genes**), defines the perturbation dimension based on the unique drugs in the dataset, and specifies training parameters such as hidden layer size and the control perturbation (`DMSO_TF`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "TqIu",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 18 \u03bcs, sys: 4 \u03bcs, total: 22 \u03bcs\n",
            "Wall time: 34.3 \u03bcs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "def embedsum_metadata_cb(ad: anndata.AnnData, metadata: dict):\n",
        "    cell_line_metadata_cb(ad, metadata)\n",
        "    metadata[\"input_dim\"] = ad.var.shape[0]\n",
        "    metadata[\"output_dim\"] = ad.var.shape[0]\n",
        "\n",
        "    uniq_drugs = sorted(ad.obs[\"drug\"].astype(str).unique().tolist())\n",
        "    metadata[\"pert_dim\"] = len(uniq_drugs)\n",
        "\n",
        "    metadata[\"hidden_dim\"] = 10  # here kept small for testing\n",
        "    metadata[\"control_pert\"] = \"DMSO_TF\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vxnm",
      "metadata": {},
      "source": [
        "### EmbedSumAnnDataset\n",
        "The `EmbedSumAnnDataset` class extends `DistributedAnnDataset` and prepares batches for the `EmbedSumPerturbationModel`. It enriches each batch with drug embeddings, metadata, and control information needed for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "DnEU",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 144 \u03bcs, sys: 0 ns, total: 144 \u03bcs\n",
            "Wall time: 158 \u03bcs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "class EmbedSumAnnDataset(DistributedAnnDataset):\n",
        "    control_drug = \"DMSO_TF\"\n",
        "\n",
        "    def transform(self, start: int, end: int):\n",
        "        # Loads gene expression (X) and converts it into a tensor (target_gene_expr).\n",
        "        X = super().transform(start, end)\n",
        "        target_gene_expr = torch.as_tensor(X, dtype=torch.float32)\n",
        "        device = target_gene_expr.device\n",
        "\n",
        "        # Collects metadata: perturbation names (drug) and cell line labels\n",
        "        pert_names = self.ad.obs[\"drug\"].iloc[start:end].astype(str).to_list()\n",
        "        cell_lines = self.ad.obs[\"cell_line\"].iloc[start:end].astype(str).to_list()\n",
        "\n",
        "        # Create drug index mapping\n",
        "        if not hasattr(self, \"_drug_to_idx\"):\n",
        "            drug_names = sorted(self.ad.obs[\"drug\"].astype(str).unique())\n",
        "            self._drug_to_idx = {d: i for i, d in enumerate(drug_names)}\n",
        "            self._num_drugs = len(drug_names)\n",
        "\n",
        "        # encodes drugs as one-hot embeddings\n",
        "        idxs = [self._drug_to_idx.get(p, 0) for p in pert_names]\n",
        "        pert_emb = torch.nn.functional.one_hot(torch.tensor(idxs, device=device), num_classes=self._num_drugs).float()\n",
        "\n",
        "        # Computes a global control mean expression vector from cells treated with DMSO_TF\n",
        "        if not hasattr(self, \"_ctrl_global\"):\n",
        "            mask = self.ad.obs[\"drug\"] == self.control_drug\n",
        "            if mask.sum() == 0:\n",
        "                ctrl_vec = np.zeros(self.ad.shape[1], dtype=np.float32)\n",
        "            else:\n",
        "                ctrl_vec = np.asarray(self.ad[mask].X.mean(axis=0)).ravel().astype(np.float32)\n",
        "            self._ctrl_global = torch.from_numpy(ctrl_vec)\n",
        "\n",
        "        ctrl_cell_emb = self._ctrl_global.to(device).unsqueeze(0).expand(len(pert_names), -1)\n",
        "\n",
        "        # Returns a dictionary containing embeddings, control features, target expression, and metadata for perturbation training\n",
        "        return {\n",
        "            \"pert_emb\": pert_emb,\n",
        "            \"ctrl_cell_emb\": ctrl_cell_emb,\n",
        "            \"target_gene_expr\": target_gene_expr,\n",
        "            \"pert_cell_emb\": target_gene_expr,\n",
        "            \"pert_name\": pert_names,\n",
        "            \"cell_type\": cell_lines,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ulZA",
      "metadata": {},
      "source": [
        "### Training the EmbedSumPerturbationModel\n",
        "- It pairs the model with the custom `EmbedSumAnnDataset` and passes in required arguments (dimensions, learning rate, control perturbation, embedding key, and output space) via `embedsum_metadata_cb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ecfG",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 12:14:53,176\tINFO worker.py:1951 -- Started a local Ray instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 112 ms, sys: 301 ms, total: 412 ms\n",
            "Wall time: 3.66 s\n",
            "\u001b[36m(TrainTrainable pid=1251740)\u001b[0m \u2713 Applied AnnDataFileManager patch\n",
            "\u001b[36m(TrainTrainable pid=1251740)\u001b[0m \u2713 Applied AnnDataFileManager patch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
            "\u001b[36m(TorchTrainer pid=1251740)\u001b[0m Started distributed worker processes: \n",
            "\u001b[36m(TorchTrainer pid=1251740)\u001b[0m - (node_id=76088a489aa8c92b9eeb053e2cee79abba9656a0d134181ab362cea8, ip=192.168.1.226, pid=1252096) world_rank=0, local_rank=0, node_rank=0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \u2713 Applied AnnDataFileManager patch\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \u2713 Applied AnnDataFileManager patch\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m =========Starting the training on 0 with num threads: 2=========\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m   | Name          | Type       | Params | Mode \n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m -----------------------------------------------------\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 0 | loss_fn       | MSELoss    | 0      | train\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 1 | pert_encoder  | Sequential | 1.1 K  | train\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 2 | basal_encoder | Sequential | 627 K  | train\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 3 | project_out   | Sequential | 689 K  | train\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m -----------------------------------------------------\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 1.3 M     Trainable params\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 1.3 M     Total params\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 5.273     Total estimated model params size (MB)\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 16        Modules in train mode\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00<00:00,  1.70it/s]\n",
            "                                                                           \n",
            "Epoch 0:   0%|          | 0/4192 [00:00<?, ?it/s] \n",
            "Epoch 0:   0%|          | 1/4192 [00:43<50:46:34,  0.02it/s, v_num=0]\n",
            ".\n",
            ".\n",
            ".\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 4190/4192 [26:49<00:00,  2.60it/s, v_num=0]\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 4191/4192 [26:49<00:00,  2.60it/s, v_num=0]\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [26:50<00:00,  2.60it/s, v_num=0]\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \n",
            "Validation:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 1/1024 [00:00<00:07, 136.59it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \n",
            ".\n",
            ".\n",
            ".\n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1022/1024 [06:19<00:00,  2.69it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1023/1024 [06:19<00:00,  2.69it/s]\u001b[A\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m \n",
            "Validation DataLoader 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1024/1024 [06:19<00:00,  2.69it/s]\u001b[A\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [33:31<00:00,  2.08it/s, v_num=0]       \u001b[A\n",
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [33:32<00:00,  2.08it/s, v_num=0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-09-24_12-15-18/TorchTrainer_22951_00000_0_2025-09-24_12-15-18/checkpoint_000000)\n",
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m `Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4192/4192 [33:32<00:00,  2.08it/s, v_num=0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(RayTrainWorker pid=1252096)\u001b[0m [rank0]:[W924 12:49:54.699038949 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "EmbedSumPerturbationModel_trainer = RayTrainRunner(\n",
        "    EmbedSumPerturbationModel,\n",
        "    EmbedSumAnnDataset,\n",
        "    [\n",
        "        \"input_dim\",\n",
        "        \"output_dim\",\n",
        "        \"hidden_dim\",\n",
        "        \"pert_dim\",\n",
        "        \"lr\",\n",
        "        \"control_pert\",  # \"DMSO_TF\"\n",
        "        \"embed_key\",\n",
        "        \"output_space\",  # \"gene\"\n",
        "    ],\n",
        "    embedsum_metadata_cb,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77ff4544",
      "metadata": {},
      "source": [
        "On a machine with **1 GPU (NVIDIA GeForce RTX 3080 - 12 GiB)**, **96 CPUs**, and **125 GiB RAM**, running `EmbedSumPerturbationModel_trainer.train()` completed in approximately **35 minutes**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Pvdt",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 1 workers with {'CPU': 2} each\n",
            "=========Length of val_split 65 length of test_split 0 length of train_split 262\n",
            "=========Length of after dropping remainder val_split 64 length of test_split 0 length of train_split 262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 12:15:18,559\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data splitting time: 24.34 seconds\n",
            "Spawning Ray worker and initiating distributed training\n",
            "== Status ==\n",
            "Current time: 2025-09-24 12:15:18 (running for 00:00:00.12)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 0/96 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_12-14-50_582135_1202711/artifacts/2025-09-24_12-15-18/TorchTrainer_2025-09-24_12-15-18/driver_artifacts\n",
            "Number of trials: 1/1 (1 PENDING)\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2025-09-24 12:15:28 (running for 00:00:10.24)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_12-14-50_582135_1202711/artifacts/2025-09-24_12-15-18/TorchTrainer_2025-09-24_12-15-18/driver_artifacts\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2025-09-24 12:49:52 (running for 00:34:33.77)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_12-14-50_582135_1202711/artifacts/2025-09-24_12-15-18/TorchTrainer_2025-09-24_12-15-18/driver_artifacts\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-24 12:49:52,903\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/dtran/protoplast_results/TorchTrainer_2025-09-24_12-15-18' in 0.0066s.\n",
            "2025-09-24 12:49:52,908\tINFO tune.py:1041 -- Total run time: 2074.35 seconds (2074.32 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2025-09-24 12:49:52 (running for 00:34:34.33)\n",
            "Using FIFO scheduling algorithm.\n",
            "Logical resource usage: 3.0/96 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
            "Result logdir: /tmp/ray/session_2025-09-24_12-14-50_582135_1202711/artifacts/2025-09-24_12-15-18/TorchTrainer_2025-09-24_12-15-18/driver_artifacts\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "\n",
            "\n",
            "CPU times: user 50.9 s, sys: 10.9 s, total: 1min 1s\n",
            "Wall time: 34min 58s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Result(\n",
              "  metrics={'train_loss': 1.076431155204773, 'val_loss': 0.628422200679779, 'epoch': 0, 'step': 4192},\n",
              "  path='/home/dtran/protoplast_results/TorchTrainer_2025-09-24_12-15-18/TorchTrainer_22951_00000_0_2025-09-24_12-15-18',\n",
              "  filesystem='local',\n",
              "  checkpoint=Checkpoint(filesystem=local, path=/home/dtran/protoplast_results/TorchTrainer_2025-09-24_12-15-18/TorchTrainer_22951_00000_0_2025-09-24_12-15-18/checkpoint_000000)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "*** SIGTERM received at time=1758718221 on cpu 9 ***\n",
            "PC: @     0x73f02e32a072  (unknown)  epoll_wait\n",
            "    @     0x73f02e245330  (unknown)  (unknown)\n",
            "    @     0x5a1f48e9565a  (unknown)  select_epoll_poll_impl\n",
            "[2025-09-24 12:50:21,507 E 1202711 1202711] logging.cc:474: *** SIGTERM received at time=1758718221 on cpu 9 ***\n",
            "[2025-09-24 12:50:21,507 E 1202711 1202711] logging.cc:474: PC: @     0x73f02e32a072  (unknown)  epoll_wait\n",
            "[2025-09-24 12:50:21,508 E 1202711 1202711] logging.cc:474:     @     0x73f02e245330  (unknown)  (unknown)\n",
            "[2025-09-24 12:50:21,508 E 1202711 1202711] logging.cc:474:     @     0x5a1f48e9565a  (unknown)  select_epoll_poll_impl\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "EmbedSumPerturbationModel_trainer.train(\n",
        "    file_paths,\n",
        "    batch_size,  # 2000\n",
        "    test_size,  # 0.0\n",
        "    val_size,  # 0.2\n",
        "    thread_per_worker=thread_per_worker,  # 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6af2a3-ec4d-4b19-a839-5c179067b846",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (protoplast-ml-example)",
      "language": "python",
      "name": "protoplast-ml-example"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
